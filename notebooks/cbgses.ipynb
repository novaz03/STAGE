{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cd420-24ae-471a-8a3c-5a50003bc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1897120-51a9-4aa2-be0d-da6c99011816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "tt_bg_FL = pd.read_excel(\"bg_fl_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f51bd9-8220-4e13-80b0-d2450a738f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_bg_FL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2532c54-4c8e-4ce9-ab79-df632ca9c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_tt_bg_FL = pd.read_csv(\"fl_bg_ses_geom.csv\",delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546d6165-107e-47d9-90c7-ded368318add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13350, 3)\n",
      "          GEOID NAME                                           geometry\n",
      "0  120860001303    3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...\n",
      "1  121030268141    1  MULTIPOLYGON (((-82.70074 28.03389, -82.69772 ...\n",
      "2  120570065041    1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...\n",
      "3  121270803003    3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...\n",
      "4  120710501064    4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Read the file you just wrote in R\n",
    "ses_gdf = gpd.read_file(\"fl_bg.geojson\")\n",
    "\n",
    "# Inspect\n",
    "print(ses_gdf.shape)        # should be (13350, 3) if you had 2 attribute fields + geometry\n",
    "print(ses_gdf.head())\n",
    "\n",
    "# Quick plot\n",
    "ses_gdf.plot(figsize=(8,8), edgecolor=\"black\", linewidth=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52dbb91-8ab0-462a-a5bf-0c267fad25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  # Assuming these might be used later from original imports\n",
    "from peft import PeftModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12044a6b-952c-4631-a8a1-166f2b4a06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG = {\n",
    "    # File Paths\n",
    "    \"HEX_FILE_PATH\": \"Hex_tesse_raw.parquet\",\n",
    "    \"POI_FILE_PATH\": \"Hull_FL_poi_vec_subset.csv\",\n",
    "    \"CHECKPOINT_PATH\": \"bottleneck_mlp_newdata.pth\",\n",
    "    \"OUTPUT_PATH\": \"POI_encoded_embeddings.parquet\",\n",
    "    \n",
    "    # Coordinate Reference Systems\n",
    "    \"CRS_GEOGRAPHIC\": \"EPSG:4326\",\n",
    "    \"CRS_PROJECTED\": \"EPSG:5070\",  # Using an equal-area projection for the US\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    \"LATENT_DIM\": 64,\n",
    "    \"HIDDEN_DIM\": 256,\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"EPOCHS\": 40,\n",
    "    \n",
    "    # System Configuration\n",
    "    \"DEVICE\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"NUM_WORKERS\": 4,\n",
    "}\n",
    "\n",
    "# ─── PyTorch Model Definition ────────────────────────────────────────────────\n",
    "\n",
    "class BottleneckMLP(nn.Module):\n",
    "    \"\"\"A Bottleneck Multi-Layer Perceptron for dimensionality reduction and classification.\"\"\"\n",
    "    def __init__(self, in_dim, hid_dim, lat_dim, n_cls):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.LeakyReLU(0.01, inplace=True),\n",
    "            nn.Linear(hid_dim, lat_dim),\n",
    "            nn.LeakyReLU(0.01, inplace=True)\n",
    "        )\n",
    "        self.head = nn.Linear(lat_dim, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.head(z)\n",
    "        return z, logits\n",
    "\n",
    "# ─── Data Loading and Preprocessing Functions ────────────────────────────────\n",
    "\n",
    "def load_hexagon_data(file_path, crs):\n",
    "    \"\"\"Loads and preprocesses the hexagon GeoDataFrame.\"\"\"\n",
    "    logging.info(f\"Loading hexagon data from {file_path}...\")\n",
    "    hex_gdf = pd.read_parquet(file_path)\n",
    "    hex_gdf = hex_gdf.reset_index(drop=True)\n",
    "    hex_gdf[\"hex_id\"] = hex_gdf.index.astype(str)\n",
    "    hex_gdf[\"geometry\"] = gpd.GeoSeries.from_wkb(hex_gdf[\"geometry\"])\n",
    "    hex_gdf = gpd.GeoDataFrame(hex_gdf, geometry=\"geometry\", crs=crs)\n",
    "    logging.info(f\"Hexagon data loaded with {len(hex_gdf)} hexagons.\")\n",
    "    return hex_gdf\n",
    "\n",
    "def load_poi_data(file_path, crs):\n",
    "    \"\"\"Loads and preprocesses the POI GeoDataFrame.\"\"\"\n",
    "    logging.info(f\"Loading POI data from {file_path}...\")\n",
    "    table = pv.read_csv(\n",
    "        file_path,\n",
    "        read_options=ReadOptions(block_size=1 << 20),\n",
    "        parse_options=ParseOptions(delimiter=\",\", quote_char='\"', newlines_in_values=True)\n",
    "    )\n",
    "    df = table.to_pandas()\n",
    "    df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads)\n",
    "    poi_gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n",
    "    logging.info(f\"POI data loaded with {len(poi_gdf)} points.\")\n",
    "    return poi_gdf\n",
    "\n",
    "def parse_vector_column(series: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Parses a string representation of vectors into a stacked NumPy array.\"\"\"\n",
    "    logging.info(\"Parsing string vectors into NumPy array...\")\n",
    "    def parse_vec(s: str) -> np.ndarray:\n",
    "        if isinstance(s, (list, np.ndarray)):\n",
    "            return np.array(s, dtype=np.float32)\n",
    "        return np.fromstring(s.strip(\"[]\"), sep=\" \", dtype=np.float32)\n",
    "    \n",
    "    vecs = np.stack(series.map(parse_vec).values)\n",
    "    return vecs\n",
    "\n",
    "# ─── Model Training and Inference Functions ──────────────────────────────────\n",
    "\n",
    "def train_or_load_model(config, loader, n_classes, class_labels):\n",
    "    \"\"\"Instantiates the model and optimizer, then loads from checkpoint or trains.\"\"\"\n",
    "    logging.info(\"Initializing model, optimizer, and criterion...\")\n",
    "    model = BottleneckMLP(\n",
    "        in_dim=loader.dataset.tensors[0].shape[1],\n",
    "        hid_dim=config[\"HIDDEN_DIM\"],\n",
    "        lat_dim=config[\"LATENT_DIM\"],\n",
    "        n_cls=n_classes\n",
    "    ).to(config[\"DEVICE\"])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if os.path.exists(config[\"CHECKPOINT_PATH\"]):\n",
    "        logging.info(f\"Loading pretrained model from {config['CHECKPOINT_PATH']}\")\n",
    "        ckpt = torch.load(config[\"CHECKPOINT_PATH\"], map_location=config[\"DEVICE\"])\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        logging.info(\"No checkpoint found—starting training from scratch.\")\n",
    "        for epoch in range(1, config[\"EPOCHS\"] + 1):\n",
    "            model.train()\n",
    "            loop = tqdm(loader, desc=f\"Epoch {epoch}/{config['EPOCHS']}\", unit=\"batch\")\n",
    "            total_loss = 0.0\n",
    "            for xb, yb in loop:\n",
    "                xb, yb = xb.to(config[\"DEVICE\"]), yb.to(config[\"DEVICE\"])\n",
    "                optimizer.zero_grad()\n",
    "                _, logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * xb.size(0)\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            avg_loss = total_loss / len(loader.dataset)\n",
    "            print(f\"→ Epoch {epoch:2d}: avg loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        logging.info(f\"Training complete—saving checkpoint to {config['CHECKPOINT_PATH']}\")\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"classes\": class_labels\n",
    "        }, config[\"CHECKPOINT_PATH\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def encode_features(model, loader, device):\n",
    "    \"\"\"Runs inference to generate latent embeddings for the input data.\"\"\"\n",
    "    logging.info(\"Encoding features to generate latent vectors (Z)...\")\n",
    "    model.eval()\n",
    "    all_z = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in tqdm(loader, desc=\"Encoding\"):\n",
    "            xb = xb.to(device)\n",
    "            z = model.encoder(xb)\n",
    "            all_z.append(z.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(all_z)\n",
    "\n",
    "# ─── Geospatial Processing Function ──────────────────────────────────────────\n",
    "\n",
    "def assign_pois_to_hexagons(poi_gdf, hex_gdf):\n",
    "    \"\"\"Reprojects and performs a nearest-neighbor join to assign POIs to hexagons.\"\"\"\n",
    "    logging.info(\"Reprojecting GeoDataFrames to equal-area CRS for accurate nearest-neighbor search...\")\n",
    "    poi_proj = poi_gdf.to_crs(epsg=CONFIG[\"CRS_PROJECTED\"])\n",
    "    hex_proj = hex_gdf.to_crs(epsg=CONFIG[\"CRS_PROJECTED\"])\n",
    "\n",
    "    logging.info(\"Assigning POIs to nearest hexagon...\")\n",
    "    joined_gdf = gpd.sjoin_nearest(\n",
    "        poi_proj,\n",
    "        hex_proj[[\"hex_id\", \"geometry\"]],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Join completed. Matched points: {joined_gdf['hex_id'].notna().sum()}/{len(poi_gdf)}\")\n",
    "    \n",
    "    # Reproject final result back to geographic coordinates\n",
    "    joined_gdf = joined_gdf.to_crs(epsg=CONFIG[\"CRS_GEOGRAPHIC\"])\n",
    "    return joined_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00b89ba-8a9f-48eb-b4ef-7e2125435db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_gdf = load_hexagon_data(\"Hex_tesse_raw.parquet\",\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35134c8c-9b15-4852-99c6-63dad1b9d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                geometry hex_id\n",
      "0      POLYGON ((-88.55028 30.36403, -88.54055 30.359...      0\n",
      "1      POLYGON ((-88.55028 30.37372, -88.55028 30.364...      1\n",
      "2      POLYGON ((-88.55028 30.3931, -88.54055 30.3882...      2\n",
      "3      POLYGON ((-88.55028 30.40278, -88.55028 30.393...      3\n",
      "4      POLYGON ((-88.55028 30.42215, -88.54055 30.417...      4\n",
      "...                                                  ...    ...\n",
      "67963  POLYGON ((-79.95377 26.33337, -79.95377 26.343...  67963\n",
      "67964  POLYGON ((-79.95377 26.36356, -79.95377 26.373...  67964\n",
      "67965  POLYGON ((-79.94405 26.37865, -79.94405 26.388...  67965\n",
      "67966  POLYGON ((-79.94405 26.38871, -79.95377 26.393...  67966\n",
      "67967  POLYGON ((-79.95377 26.42391, -79.95377 26.433...  67967\n",
      "\n",
      "[67968 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    hex_gdf = hex_gdf.drop(columns=\"hexid\")\n",
    "except Exception as e:\n",
    "    print(\"deleted\")\n",
    "print(hex_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e61296-8d2a-4b3f-a18e-ea95f7833406",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf = ses_gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7b245-6626-47c3-ad8c-02b86bbfefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14609ddd-a2f9-41bc-84fb-53eeb5bbb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "hex_gdf.boundary.plot(ax=ax, linewidth=0.05, edgecolor=\"gray\",alpha=0.5)\n",
    "states = gpd.read_file('cb_2018_us_state_500k.shp')\n",
    "#state_plot = states.to_crs(epsg=3857)\n",
    "states[states.STUSPS == \"FL\"].boundary.plot(\n",
    "    ax=ax, linewidth=1, color=\"black\"\n",
    ")\n",
    "ses_gdf.plot(ax=ax,cmap = \"tab20\", alpha = 0.9)\n",
    "xmin, ymin, xmax, ymax = (-82.5, 27.9, -82.3, 28.1)  # example in EPSG:3857 coords\n",
    "\n",
    "# 6) Create an inset axes for the zoom\n",
    "axins = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"lower left\", borderpad=1)\n",
    "axins.set_xlim(xmin, xmax)\n",
    "axins.set_ylim(ymin, ymax)\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"red\", lw=1)\n",
    "hex_gdf.boundary.plot(ax=axins, linewidth=0.1, edgecolor=\"black\",alpha=0.9)\n",
    "#ax.axes(False)\n",
    "states[states.STUSPS == \"FL\"].boundary.plot(\n",
    "    ax=axins, linewidth=1, color=\"black\"\n",
    ")\n",
    "ses_gdf.plot(ax=axins,cmap = \"tab20\", alpha = 0.9)\n",
    "plt.savefig(\"hex_tess_ses.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa105bbd-d9f4-4502-b347-c014bfaef893",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_parquet(\"POI_encoded_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963b2bce-c3ea-4f0d-af32-7c20ab29e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Expand the `z` list/array into its own DataFrame of shape (N, D)\n",
    "#    so each dimension becomes a column z0, z1, ..., z{D-1}\n",
    "z_expanded = pd.DataFrame(\n",
    "    gdf[\"z\"].tolist(),\n",
    "    index=gdf.index\n",
    ")\n",
    "z_expanded.columns = [f\"z{i}\" for i in range(z_expanded.shape[1])]\n",
    "\n",
    "# 3) Combine back with the labels\n",
    "df_expanded = pd.concat([gdf[\"label_pair\"], z_expanded], axis=1)\n",
    "\n",
    "# 4) Group by label_pair and take the mean → this is your “center” per class\n",
    "centers_df = df_expanded.groupby(\"label_pair\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24663f09-505d-4799-81b5-9fbd8d3529a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>geometry</th>\n",
       "      <th>hex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120860001303</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121030268141</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120570065041</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121270803003</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120710501064</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>120710104151</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.06879 26.56344, -82.06437 ...</td>\n",
       "      <td>13345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>120990075043</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.09112 26.33261, -80.08951 ...</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>120310144132</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((-81.55911 30.18003, -81.55849 ...</td>\n",
       "      <td>13347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13348</th>\n",
       "      <td>120190307061</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-81.71425 30.08813, -81.71339 ...</td>\n",
       "      <td>13348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>120174504011</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.52519 29.02283, -82.52312 ...</td>\n",
       "      <td>13349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13350 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GEOID NAME                                           geometry  \\\n",
       "0      120860001303    3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...   \n",
       "1      121030268141    1  MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...   \n",
       "2      120570065041    1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...   \n",
       "3      121270803003    3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...   \n",
       "4      120710501064    4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...   \n",
       "...             ...  ...                                                ...   \n",
       "13345  120710104151    1  MULTIPOLYGON (((-82.06879 26.56344, -82.06437 ...   \n",
       "13346  120990075043    3  MULTIPOLYGON (((-80.09112 26.33261, -80.08951 ...   \n",
       "13347  120310144132    2  MULTIPOLYGON (((-81.55911 30.18003, -81.55849 ...   \n",
       "13348  120190307061    1  MULTIPOLYGON (((-81.71425 30.08813, -81.71339 ...   \n",
       "13349  120174504011    1  MULTIPOLYGON (((-82.52519 29.02283, -82.52312 ...   \n",
       "\n",
       "       hex_id  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  \n",
       "...       ...  \n",
       "13345   13345  \n",
       "13346   13346  \n",
       "13347   13347  \n",
       "13348   13348  \n",
       "13349   13349  \n",
       "\n",
       "[13350 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ses_gdf = ses_gdf.reset_index(drop=True)\n",
    "\n",
    "# 2) copy that index into your new hex_id column\n",
    "ses_gdf[\"hex_id\"] = ses_gdf.index\n",
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb00715-af42-4fd0-80f4-9c77140fcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47a02ce-e439-43a4-9e37-a0af27a5a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                label_pair  \\\n",
      "0        Activities Related to Real Estate[sep]Resident...   \n",
      "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
      "3              Offices of Dentists[sep]Offices of Dentists   \n",
      "4        Museums, Historical Sites, and Similar Institu...   \n",
      "...                                                    ...   \n",
      "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
      "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "\n",
      "                                                         z  \\\n",
      "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
      "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
      "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
      "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
      "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
      "...                                                    ...   \n",
      "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
      "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
      "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
      "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
      "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
      "\n",
      "                           geometry  \\\n",
      "0        POINT (-82.52482 27.94908)   \n",
      "1        POINT (-81.38077 30.19916)   \n",
      "2         POINT (-81.76929 24.5666)   \n",
      "3        POINT (-81.68255 30.20312)   \n",
      "4        POINT (-81.84711 26.64202)   \n",
      "...                             ...   \n",
      "1548012  POINT (-81.42641 29.78401)   \n",
      "1548013  POINT (-81.07024 29.21795)   \n",
      "1548014  POINT (-81.32279 29.04255)   \n",
      "1548015  POINT (-81.01938 29.24983)   \n",
      "1548016  POINT (-80.98888 29.14597)   \n",
      "\n",
      "                                                  cat_name  cat_count  weight  \\\n",
      "0                        Activities Related to Real Estate         24     576   \n",
      "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
      "3                                      Offices of Dentists         70    4900   \n",
      "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
      "...                                                    ...        ...     ...   \n",
      "1548012                            Home Furnishings Stores          1       1   \n",
      "1548013                              Urban Transit Systems         16     256   \n",
      "1548014                              Urban Transit Systems          8      64   \n",
      "1548015                              Urban Transit Systems         30     900   \n",
      "1548016                              Urban Transit Systems         33    1089   \n",
      "\n",
      "         hex_id_right  \n",
      "0              9375.0  \n",
      "1              2887.0  \n",
      "2              7375.0  \n",
      "3             10516.0  \n",
      "4              5089.0  \n",
      "...               ...  \n",
      "1548012       12446.0  \n",
      "1548013        1150.0  \n",
      "1548014       10826.0  \n",
      "1548015        4902.0  \n",
      "1548016        9483.0  \n",
      "\n",
      "[1678168 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#ses_gdf.to_crs(ESPG:5070)\n",
    "gdf = gdf.to_crs(ses_gdf.crs)\n",
    "#gdf = gdf.drop(columns=[\"hex_id\"])\n",
    "# 2) keep only the hex_id + geometry in the hex‐grid\n",
    "hexes = ses_gdf[[\"hex_id\", \"geometry\"]]\n",
    "\n",
    "# 3) spatial join: for each point, find the hex whose polygon it lies within\n",
    "#    – predicate=\"within\" for GeoPandas ≥ 0.10, or op=\"within\" for older versions\n",
    "joined = gpd.sjoin(\n",
    "    gdf,\n",
    "    hexes,\n",
    "    how=\"left\",          # keep all points, even those that fall outside\n",
    "    #predicate=\"within\"   # use \"op='within'\" if your GeoPandas is <0.10\n",
    ")\n",
    "\n",
    "# 4) clean up the result: drop the auto‐added index_right column\n",
    "joined = joined.drop(columns=[\"hex_id_left\",\"index_right\"])\n",
    "\n",
    "# now `joined` has all of your original point columns **plus** a `hex_id` column\n",
    "print(joined)\n",
    "joined = joined.rename(columns={\"hex_id_right\":\"hex_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75a7d2c-92ed-48d7-b3fd-0654ff0db909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "                                                label_pair  \\\n",
      "0        Activities Related to Real Estate[sep]Resident...   \n",
      "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
      "3              Offices of Dentists[sep]Offices of Dentists   \n",
      "4        Museums, Historical Sites, and Similar Institu...   \n",
      "...                                                    ...   \n",
      "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
      "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "\n",
      "                                                         z  \\\n",
      "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
      "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
      "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
      "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
      "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
      "...                                                    ...   \n",
      "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
      "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
      "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
      "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
      "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
      "\n",
      "                           geometry  \\\n",
      "0        POINT (-82.52482 27.94908)   \n",
      "1        POINT (-81.38077 30.19916)   \n",
      "2         POINT (-81.76929 24.5666)   \n",
      "3        POINT (-81.68255 30.20312)   \n",
      "4        POINT (-81.84711 26.64202)   \n",
      "...                             ...   \n",
      "1548012  POINT (-81.42641 29.78401)   \n",
      "1548013  POINT (-81.07024 29.21795)   \n",
      "1548014  POINT (-81.32279 29.04255)   \n",
      "1548015  POINT (-81.01938 29.24983)   \n",
      "1548016  POINT (-80.98888 29.14597)   \n",
      "\n",
      "                                                  cat_name  cat_count  weight  \\\n",
      "0                        Activities Related to Real Estate         24     576   \n",
      "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
      "3                                      Offices of Dentists         70    4900   \n",
      "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
      "...                                                    ...        ...     ...   \n",
      "1548012                            Home Furnishings Stores          1       1   \n",
      "1548013                              Urban Transit Systems         16     256   \n",
      "1548014                              Urban Transit Systems          8      64   \n",
      "1548015                              Urban Transit Systems         30     900   \n",
      "1548016                              Urban Transit Systems         33    1089   \n",
      "\n",
      "          hex_id  \n",
      "0         9375.0  \n",
      "1         2887.0  \n",
      "2         7375.0  \n",
      "3        10516.0  \n",
      "4         5089.0  \n",
      "...          ...  \n",
      "1548012  12446.0  \n",
      "1548013   1150.0  \n",
      "1548014  10826.0  \n",
      "1548015   4902.0  \n",
      "1548016   9483.0  \n",
      "\n",
      "[1590667 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sum(joined[\"hex_id\"].isna())/len(joined))\n",
    "joined = joined.dropna(subset=[\"hex_id\"])\n",
    "joined.to_crs(\"EPSG:4326\")\n",
    "print(joined)\n",
    "#joined[\"hex_id\"] = joined[\"hex_id\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accc464d-7b3d-4290-ac7e-394787419225",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vecs = (\n",
    "    joined\n",
    "    .groupby('hex_id')['z']\n",
    "    .agg(lambda arrs: np.mean(np.stack(arrs.values), axis=0))\n",
    ")\n",
    "# mean_vecs is a Series: index=hex_id, value=np.ndarray(1152,)\n",
    "\n",
    "# 2a) merge into hex_gdf\n",
    "ses_gdf = ses_gdf.merge(\n",
    "    mean_vecs.rename('vec_mean'),\n",
    "    left_on='hex_id',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff83f48-50d6-4377-81f9-2f636cd4b00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13350, 308)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME_x</th>\n",
       "      <th>geometry</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>vec_mean_x</th>\n",
       "      <th>vec_mean_y</th>\n",
       "      <th>NAME_y</th>\n",
       "      <th>Total:</th>\n",
       "      <th>Total: Under .50</th>\n",
       "      <th>Total: .50 to .99</th>\n",
       "      <th>...</th>\n",
       "      <th>Total: With an Internet subscription Broadband of any type</th>\n",
       "      <th>Total: With an Internet subscription Cellular data plan</th>\n",
       "      <th>Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Broadband such as cable, fiber optic or DSL</th>\n",
       "      <th>Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Satellite Internet service</th>\n",
       "      <th>Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Other service with no other type of Internet subscription</th>\n",
       "      <th>Total: Internet access without a subscription</th>\n",
       "      <th>Total: No Internet access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120860001303</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[33.6305, 35.814537, 14.019923, 40.46885, 28.7...</td>\n",
       "      <td>[33.6305, 35.814537, 14.019923, 40.46885, 28.7...</td>\n",
       "      <td>Block Group 3; Census Tract 1.30; Miami-Dade C...</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121030268141</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[28.050043, 36.334988, 19.818258, 34.684147, 3...</td>\n",
       "      <td>[28.050043, 36.334988, 19.818258, 34.684147, 3...</td>\n",
       "      <td>Block Group 1; Census Tract 268.14; Pinellas C...</td>\n",
       "      <td>992</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>429</td>\n",
       "      <td>392</td>\n",
       "      <td>46</td>\n",
       "      <td>375</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120570065041</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[37.87849, 41.17299, 24.685835, 38.813133, 35....</td>\n",
       "      <td>[37.87849, 41.17299, 24.685835, 38.813133, 35....</td>\n",
       "      <td>Block Group 1; Census Tract 65.04; Hillsboroug...</td>\n",
       "      <td>411</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121270803003</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[46.378544, 34.71072, 28.458584, 43.096386, 30...</td>\n",
       "      <td>[46.378544, 34.71072, 28.458584, 43.096386, 30...</td>\n",
       "      <td>Block Group 3; Census Tract 803; Volusia Count...</td>\n",
       "      <td>1024</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>465</td>\n",
       "      <td>346</td>\n",
       "      <td>18</td>\n",
       "      <td>400</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120710501064</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[39.790993, 35.508392, 29.290495, 40.39536, 39...</td>\n",
       "      <td>[39.790993, 35.508392, 29.290495, 40.39536, 39...</td>\n",
       "      <td>Block Group 4; Census Tract 501.06; Lee County...</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>350</td>\n",
       "      <td>334</td>\n",
       "      <td>33</td>\n",
       "      <td>317</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID NAME_x                                           geometry  \\\n",
       "0  120860001303      3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...   \n",
       "1  121030268141      1  MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...   \n",
       "2  120570065041      1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...   \n",
       "3  121270803003      3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...   \n",
       "4  120710501064      4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...   \n",
       "\n",
       "   hex_id                                         vec_mean_x  \\\n",
       "0       0  [33.6305, 35.814537, 14.019923, 40.46885, 28.7...   \n",
       "1       1  [28.050043, 36.334988, 19.818258, 34.684147, 3...   \n",
       "2       2  [37.87849, 41.17299, 24.685835, 38.813133, 35....   \n",
       "3       3  [46.378544, 34.71072, 28.458584, 43.096386, 30...   \n",
       "4       4  [39.790993, 35.508392, 29.290495, 40.39536, 39...   \n",
       "\n",
       "                                          vec_mean_y  \\\n",
       "0  [33.6305, 35.814537, 14.019923, 40.46885, 28.7...   \n",
       "1  [28.050043, 36.334988, 19.818258, 34.684147, 3...   \n",
       "2  [37.87849, 41.17299, 24.685835, 38.813133, 35....   \n",
       "3  [46.378544, 34.71072, 28.458584, 43.096386, 30...   \n",
       "4  [39.790993, 35.508392, 29.290495, 40.39536, 39...   \n",
       "\n",
       "                                              NAME_y  Total:  \\\n",
       "0  Block Group 3; Census Tract 1.30; Miami-Dade C...     279   \n",
       "1  Block Group 1; Census Tract 268.14; Pinellas C...     992   \n",
       "2  Block Group 1; Census Tract 65.04; Hillsboroug...     411   \n",
       "3  Block Group 3; Census Tract 803; Volusia Count...    1024   \n",
       "4  Block Group 4; Census Tract 501.06; Lee County...     582   \n",
       "\n",
       "   Total: Under .50  Total: .50 to .99  ...  \\\n",
       "0                 0                 42  ...   \n",
       "1                16                 19  ...   \n",
       "2                17                 55  ...   \n",
       "3                69                  2  ...   \n",
       "4                 0                 40  ...   \n",
       "\n",
       "   Total: With an Internet subscription Broadband of any type  \\\n",
       "0                                                183            \n",
       "1                                                429            \n",
       "2                                                198            \n",
       "3                                                465            \n",
       "4                                                350            \n",
       "\n",
       "   Total: With an Internet subscription Cellular data plan  \\\n",
       "0                                                183         \n",
       "1                                                392         \n",
       "2                                                177         \n",
       "3                                                346         \n",
       "4                                                334         \n",
       "\n",
       "   Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                 46                                                                        \n",
       "2                                                  2                                                                        \n",
       "3                                                 18                                                                        \n",
       "4                                                 33                                                                        \n",
       "\n",
       "   Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
       "0                                                160                                  \n",
       "1                                                375                                  \n",
       "2                                                166                                  \n",
       "3                                                400                                  \n",
       "4                                                317                                  \n",
       "\n",
       "   Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                                                                          \n",
       "1                                                 29                                                                                                                          \n",
       "2                                                 21                                                                                                                          \n",
       "3                                                119                                                                                                                          \n",
       "4                                                 16                                                                                                                          \n",
       "\n",
       "   Total: With an Internet subscription Satellite Internet service  \\\n",
       "0                                                 33                 \n",
       "1                                                  0                 \n",
       "2                                                 28                 \n",
       "3                                                 11                 \n",
       "4                                                  0                 \n",
       "\n",
       "   Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
       "0                                                  0                                                \n",
       "1                                                  8                                                \n",
       "2                                                  0                                                \n",
       "3                                                  0                                                \n",
       "4                                                  0                                                \n",
       "\n",
       "   Total: Internet access without a subscription  Total: No Internet access  \n",
       "0                                             14                          0  \n",
       "1                                              0                          5  \n",
       "2                                             11                         52  \n",
       "3                                             60                        139  \n",
       "4                                             35                         17  \n",
       "\n",
       "[5 rows x 308 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_bg_FL[\"GEOID\"] = tt_bg_FL[\"GEOID\"].astype(str)\n",
    "\n",
    "# (optional) also ensure ses_gdf.GEOID is string\n",
    "ses_gdf[\"GEOID\"] = ses_gdf[\"GEOID\"].astype(str)\n",
    "\n",
    "# 3) now do the merge\n",
    "merged = ses_gdf.merge(\n",
    "    tt_bg_FL,\n",
    "    on=\"GEOID\",\n",
    "    how=\"left\"   # or \"inner\" if you only want matching IDs\n",
    ")\n",
    "\n",
    "# 4) merged is still a GeoDataFrame with geometry + your new columns\n",
    "print(merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490fe94-e498-40c0-97df-ecfda5997af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Suppose df is your original GeoDataFrame with 307 cols:\n",
    "df = merged.copy()\n",
    "\n",
    "# 1) Pick off the columns you want to exempt (by name or by position)\n",
    "exempt = list(df.columns[:7])   # e.g. first four columns\n",
    "to_impute = df.columns.difference(exempt)\n",
    "\n",
    "# 2) Fit & transform only the “to_impute” slice\n",
    "imp = IterativeImputer(random_state=0)\n",
    "imputed_vals = imp.fit_transform(df[to_impute])\n",
    "\n",
    "# 3) Rebuild a new DataFrame for the imputed part\n",
    "df_imp = pd.DataFrame(imputed_vals,\n",
    "                      columns=to_impute,\n",
    "                      index=df.index)\n",
    "\n",
    "# 4) Concatenate the exempted + imputed parts, preserving original order\n",
    "df_final = pd.concat([df[exempt], df_imp], axis=1)[df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae60d38-c44b-495f-a685-b227db221416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(\"imputed_ses.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c93b6035-01cf-41fd-b601-ce4d10d43129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_parquet(\"imputed_ses.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c55682-506b-43d0-a21e-9a6a91b112d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7976d1fb-b31c-4f27-be1c-b026f64d0d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_1281/588510722.py:11: FutureWarning: `idVariable` is deprecated and will be removed in future. Use `ids` instead.\n",
      "  wq = Queen.from_dataframe(\n",
      "/storage1/fs1/nlin/Active/sizhe/sizhe/envs/geospatial/lib/python3.12/site-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 10 disconnected components.\n",
      " There are 6 islands with ids: 6126, 9175, 9234, 10256, 11174, 11374.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example neighbors for one cell: [(0, [4164, 8852, 3276, 3229, 12463]), (1, [12610, 3145, 10207, 10205, 3183]), (2, [6353, 9719, 7245, 766, 5711])]\n",
      "10 components total\n",
      "Singleton islands: [6126, 9175, 9234, 10256, 11174, 11374]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from libpysal.weights import Queen\n",
    "import networkx as nx\n",
    "\n",
    "# 1) (Optional) make sure your geometries are in a planar CRS\n",
    "#    Queen contiguity only makes sense in projected (not geographic) coordinates:\n",
    "merged = merged.to_crs(epsg=3857)\n",
    "\n",
    "# 2) build a Queen‐contiguity weight object,\n",
    "#    telling PySAL which column holds the unique ID (here “hex_id”) and which holds the geometry:\n",
    "wq = Queen.from_dataframe(\n",
    "    merged,\n",
    "    idVariable=\"hex_id\",\n",
    "    geom_col=\"geometry\"\n",
    ")\n",
    "\n",
    "# 3) if you want the raw neighbor lists:\n",
    "#    wq.neighbors is a dict: { hex_id_1: [nbr1, nbr2,…], hex_id_2: […], … }\n",
    "print(\"example neighbors for one cell:\", list(wq.neighbors.items())[:3])\n",
    "\n",
    "# 4) to turn that into a NetworkX graph:\n",
    "G = wq.to_networkx()\n",
    "\n",
    "# 5) now you can check connectivity exactly as before\n",
    "comps = list(nx.connected_components(G))\n",
    "print(f\"{len(comps)} components total\")\n",
    "islands = [c.pop() for c in comps if len(c)==1]\n",
    "print(\"Singleton islands:\", islands)\n",
    "merged['centroid'] = merged.geometry.centroid\n",
    "centroids = merged.set_index('hex_id')['centroid']\n",
    "\n",
    "# 2) for each island, find its nearest neighbour and add an edge\n",
    "for iso in islands:\n",
    "    # distances to all other centroids\n",
    "    dists = centroids.distance(centroids.loc[iso]).drop(index=iso)\n",
    "    nearest = dists.idxmin()\n",
    "    G.add_edge(iso, nearest)\n",
    "\n",
    "comps   = list(nx.connected_components(G))\n",
    "islands = [next(iter(c)) for c in comps if len(c) == 1]\n",
    "\n",
    "# 2) compute centroids (once)\n",
    "merged = merged.to_crs(epsg=3857)\n",
    "merged['centroid'] = merged.geometry.centroid\n",
    "centroids = merged.set_index('hex_id')['centroid']\n",
    "\n",
    "# 3) stitch each singleton onto its nearest neighbor:\n",
    "for iso in islands:\n",
    "    dists   = centroids.distance(centroids.loc[iso]).drop(index=iso)\n",
    "    nearest = dists.idxmin()\n",
    "    G.add_edge(iso, nearest)\n",
    "\n",
    "# 4) now recompute & sort your components\n",
    "comps = list(nx.connected_components(G))\n",
    "comps = sorted(comps, key=len, reverse=True)\n",
    "main_comp = list(comps[0])\n",
    "\n",
    "# 5) bridge every other component into the main one\n",
    "for comp in comps[1:]:\n",
    "    comp = list(comp)\n",
    "    best_pair = None\n",
    "    best_dist = float('inf')\n",
    "    for hid in comp:\n",
    "        dists = centroids.loc[main_comp].distance(centroids.loc[hid])\n",
    "        j     = dists.idxmin()\n",
    "        d     = dists.min()\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_pair = (hid, j)\n",
    "    # now best_pair is guaranteed to be a 2‑tuple\n",
    "    G.add_edge(*best_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9dd22-27f5-4183-9d34-5468213409e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = list(nx.connected_components(G))\n",
    "len(comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d157d-803c-4a15-92c3-8c64c8c29045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ses_graph.pickle\",\"wb\") as f:\n",
    "    pickle.dump(G,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca8c0a6-8d24-4a42-b1ae-18e9f45ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ses_graph.pickle\",\"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767a135-ea60-4de8-b339-c0654f781216",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = \"models/ses.emb\"\n",
    "EMBEDDING_MODEL_FILENAME = \"models/ses_model_embeddings.model\"\n",
    "# Load model after Node2Vec.save\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=128, num_walks=16, workers=10)  # Use temp_folder for big graphs\n",
    "model = node2vec.fit(vector_size=64, window=16, min_count=3, workers=8)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n",
    "\n",
    "# Save model for later use\n",
    "model.save(EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656de50-3b0c-4958-bc8e-a02f194821d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!    pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d330c-1704-4c42-87fd-abdaf869926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y k-means-constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db187164-0a5f-4e3e-b775-d97a1854cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y gensim\n",
    "!pip install --no-cache-dir --force-reinstall \"gensim==4.3.3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d1d86-36d6-4910-b3e3-bd6202d65fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "print(sys.version)\n",
    "print(\"numpy:\", np.__version__)\n",
    "# import gensim  # will fail right now, that's the point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb14b2a-fbd3-482c-bb8e-bb1828ce573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = \"models/ses.emb\"\n",
    "EMBEDDING_MODEL_FILENAME = \"models/ses_model_embeddings.model\"\n",
    "# Load model after Node2Vec.save\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "vec_model = Word2Vec.load(EMBEDDING_MODEL_FILENAME)\n",
    "embeddings = {node: vec_model.wv[node] for node in G.nodes()}\n",
    "emb_dataframe = pd.DataFrame.from_dict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef012d5d-938f-4063-9a69-0bb41b740eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = emb_dataframe.to_numpy().T   # shape (N, D)\n",
    "\n",
    "# 2) turn each row into a Python list\n",
    "vec_lists = vecs.tolist()           # [ [float,…,float], … ]\n",
    "\n",
    "# 3) assign by position (assuming hex_gdf is already sorted by hex_id 0…N-1)\n",
    "ses_gdf['graph_embedding'] = vec_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630cb64-7efe-425c-b590-a8896fa21bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbf28b96-e349-4323-8c2f-7f1a56c41416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage1/fs1/nlin/Active/sizhe/sizhe/envs/geospatial/lib/python3.12/site-packages/peft/peft_model.py:565: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "# 4) Move to GPU/CPU and set eval mode:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 1) Where you saved your LoRA adapters after training:\n",
    "CHECKPOINT = \"/storage1/fs1/nlin/Active/sizhe/FO_DATA/checkpoint-dir/checkpoint-551\"\n",
    "\n",
    "# 2) Load the tokenizer from that folder (it contains tokenizer.json + vocab.txt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "base_name = \"google/gemma-3-1b-it\"     # <— exactly what you passed in your training script\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-3-1b-it\",\n",
    "    attn_implementation=\"eager\"\n",
    ").to(device)\n",
    "\n",
    "# 3) Now graft the adapter weights:\n",
    "llm_model = PeftModel.from_pretrained(base, CHECKPOINT,strict=False)\n",
    "\n",
    "\n",
    "#llm_model.to(device).eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15342185-40d4-46ae-8c89-f0c3d4a4a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    texts: a Python list of strings (each may contain literal \"[sep]\").\n",
    "    example: [\"[Museums, Historical Sites,...<sep>Museums, Historical Sites<sep>Natural History museum]\",...]\n",
    "    In the format of [<category><sep><subcategory><sep><name>]\n",
    "    Returns: a GPU tensor of shape (len(texts), hidden_size) containing the\n",
    "             final‐token embedding for each string.\n",
    "    \"\"\"\n",
    "    # 2.1) Clean & force everything to str, replacing None/NaN with \"\"\n",
    "    clean_texts=[]\n",
    "    for t in texts:\n",
    "        if t is None:\n",
    "            clean_texts.append(\"\")\n",
    "        else:\n",
    "            clean_texts.append(str(t))\n",
    "    sep = tokenizer.sep_token  # e.g. \"[SEP]\" for BERT‐style; whatever your tokenizer.sep_token is\n",
    "    clean_texts = [t.replace(\"[sep]\", sep) for t in clean_texts]\n",
    "    \n",
    "    # 2.3) Batch‐tokenize all strings onto GPU\n",
    "    enc = tokenizer(\n",
    "        clean_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_token_type_ids=False,\n",
    "    ).to(device)\n",
    "    #print(\"Batch input_ids are on:\", enc.input_ids.device)\n",
    "    # Now enc.input_ids and enc.attention_mask live on GPU.\n",
    "\n",
    "    # 2.4) Forward‐pass (no gradients) to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = llm_model.base_model(\n",
    "            input_ids=enc.input_ids,\n",
    "            attention_mask=enc.attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        # `outputs.hidden_states` is a tuple of length (num_layers+1);\n",
    "        # each element has shape (batch_size, seq_len, hidden_size).\n",
    "        last_hidden = outputs.hidden_states[-1]  # (batch_size, seq_len, hidden_size) on GPU\n",
    "\n",
    "    # 2.5) For each sequence, pick out the final non‐pad token embedding\n",
    "    seq_lens = enc.attention_mask.sum(dim=1) - 1  # (batch_size,) on GPU, index of last non-pad\n",
    "    batch_size, hidden_size = last_hidden.size(0), last_hidden.size(2)\n",
    "\n",
    "    # Gather the embedding at position (i, seq_lens[i], :)\n",
    "    final_embs = last_hidden[torch.arange(batch_size), seq_lens, :]  # (batch_size, hidden_size) on GPU\n",
    "    #print((final_embs))\n",
    "    return final_embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ff2419f-79bc-42ba-a15f-a1e0dfa41d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 1152]) cuda:0\n",
      "tensor([[[ 1.4538, -8.0599,  0.6345,  ..., -0.2421,  0.9947,  0.2485]]],\n",
      "       device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "null_emb   = embed_texts([\"<null_val>[sep]<null_val>\"]) \n",
    "# null_emb is already a tensor\n",
    "print(type(null_emb), null_emb.shape, null_emb.device)\n",
    "\n",
    "# add the batch‐dim, cast & move to DEVICE\n",
    "null_tensor = null_emb.float().unsqueeze(0).to(DEVICE)\n",
    "print(null_tensor, null_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc2a7a44-af28-4112-9044-1f8d8ea17379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckMLP(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (head): Linear(in_features=64, out_features=751, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ckpt = torch.load(\"bottleneck_mlp_newdata.pth\",map_location = \"cuda\",weights_only=False)\n",
    "\n",
    "raw_classes = ckpt.get(\"classes\", None)\n",
    "# Determine number of classes\n",
    "n_old = len(raw_classes) if raw_classes is not None else ckpt[\"model_state_dict\"][\"head.bias\"].shape[0]\n",
    "\n",
    "# Convert classes to Python list\n",
    "if raw_classes is None:\n",
    "    classes = [f\"class_{{i}}\" for i in range(n_old)]\n",
    "elif isinstance(raw_classes, np.ndarray):\n",
    "    classes = raw_classes.tolist()\n",
    "else:\n",
    "    classes = list(raw_classes)\n",
    "# Recreate and load your original BottleneckMLP\n",
    "class BottleneckMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, lat_dim, n_cls):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, lat_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(lat_dim, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.head(z)\n",
    "        return z, logits\n",
    "\n",
    "# Extract dims from checkpoint\n",
    "in_dim     = ckpt[\"model_state_dict\"][\"encoder.0.weight\"].shape[1]\n",
    "hid_dim    = ckpt[\"model_state_dict\"][\"encoder.0.weight\"].shape[0]\n",
    "lat_dim    = ckpt[\"model_state_dict\"][\"encoder.2.weight\"].shape[0]\n",
    "\n",
    "# Instantiate and load weights\n",
    "bottleneck_model = BottleneckMLP(in_dim, hid_dim, lat_dim, n_old).to(device)\n",
    "bottleneck_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "bottleneck_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "513325d2-d77b-4dd3-af72-354941db61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "# 2) grab the weight‐row (and optional bias)\n",
    "with torch.no_grad():\n",
    "    w_cls = bottleneck_model.head.weight[idx]     # torch.Tensor of shape (latent_dim,)\n",
    "    b_cls = bottleneck_model.head.bias[idx]       # scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d799955f-7c28-4fee-b150-26596336542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_pair</th>\n",
       "      <th>z</th>\n",
       "      <th>geometry</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>cat_count</th>\n",
       "      <th>weight</th>\n",
       "      <th>hex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activities Related to Real Estate[sep]Resident...</td>\n",
       "      <td>[61.499184, 25.730932, 28.544409, 16.33576, 38...</td>\n",
       "      <td>POINT (-82.52482 27.94908)</td>\n",
       "      <td>Activities Related to Real Estate</td>\n",
       "      <td>24</td>\n",
       "      <td>576</td>\n",
       "      <td>33561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offices of Real Estate Agents and Brokers[sep]...</td>\n",
       "      <td>[10.239435, 8.276576, 44.785103, 72.61034, 19....</td>\n",
       "      <td>POINT (-81.38077 30.19916)</td>\n",
       "      <td>Offices of Real Estate Agents and Brokers</td>\n",
       "      <td>107</td>\n",
       "      <td>11449</td>\n",
       "      <td>52159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sporting Goods, Hobby, and Musical Instrument ...</td>\n",
       "      <td>[23.133112, 20.673256, 16.964842, 24.288828, 2...</td>\n",
       "      <td>POINT (-81.76929 24.5666)</td>\n",
       "      <td>Sporting Goods, Hobby, and Musical Instrument ...</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>44888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offices of Dentists[sep]Offices of Dentists</td>\n",
       "      <td>[21.774567, 62.81708, 77.10956, 94.822975, 61....</td>\n",
       "      <td>POINT (-81.68255 30.20312)</td>\n",
       "      <td>Offices of Dentists</td>\n",
       "      <td>70</td>\n",
       "      <td>4900</td>\n",
       "      <td>46628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Museums, Historical Sites, and Similar Institu...</td>\n",
       "      <td>[48.68053, 51.811516, -0.24616693, 46.184406, ...</td>\n",
       "      <td>POINT (-81.84711 26.64202)</td>\n",
       "      <td>Museums, Historical Sites, and Similar Institu...</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>43514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548012</th>\n",
       "      <td>Home Furnishings Stores[sep]All Other Home Fur...</td>\n",
       "      <td>[33.14433, -0.046613265, 46.66763, 36.16918, 2...</td>\n",
       "      <td>POINT (-81.42641 29.78401)</td>\n",
       "      <td>Home Furnishings Stores</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548013</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[10.560505, 53.101013, 18.382906, 5.375622, 64...</td>\n",
       "      <td>POINT (-81.07024 29.21795)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>56590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548014</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[5.115786, 64.99983, 25.311647, 19.811197, 78....</td>\n",
       "      <td>POINT (-81.32279 29.04255)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>52995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548015</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[13.166652, 72.90378, 16.78043, -0.050964173, ...</td>\n",
       "      <td>POINT (-81.01938 29.24983)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>57118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548016</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[-0.007572128, 67.07022, -0.05944693, 4.877822...</td>\n",
       "      <td>POINT (-80.98888 29.14597)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>33</td>\n",
       "      <td>1089</td>\n",
       "      <td>57647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1678168 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                label_pair  \\\n",
       "0        Activities Related to Real Estate[sep]Resident...   \n",
       "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
       "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
       "3              Offices of Dentists[sep]Offices of Dentists   \n",
       "4        Museums, Historical Sites, and Similar Institu...   \n",
       "...                                                    ...   \n",
       "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
       "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "\n",
       "                                                         z  \\\n",
       "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
       "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
       "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
       "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
       "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
       "...                                                    ...   \n",
       "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
       "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
       "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
       "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
       "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
       "\n",
       "                           geometry  \\\n",
       "0        POINT (-82.52482 27.94908)   \n",
       "1        POINT (-81.38077 30.19916)   \n",
       "2         POINT (-81.76929 24.5666)   \n",
       "3        POINT (-81.68255 30.20312)   \n",
       "4        POINT (-81.84711 26.64202)   \n",
       "...                             ...   \n",
       "1548012  POINT (-81.42641 29.78401)   \n",
       "1548013  POINT (-81.07024 29.21795)   \n",
       "1548014  POINT (-81.32279 29.04255)   \n",
       "1548015  POINT (-81.01938 29.24983)   \n",
       "1548016  POINT (-80.98888 29.14597)   \n",
       "\n",
       "                                                  cat_name  cat_count  weight  \\\n",
       "0                        Activities Related to Real Estate         24     576   \n",
       "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
       "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
       "3                                      Offices of Dentists         70    4900   \n",
       "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
       "...                                                    ...        ...     ...   \n",
       "1548012                            Home Furnishings Stores          1       1   \n",
       "1548013                              Urban Transit Systems         16     256   \n",
       "1548014                              Urban Transit Systems          8      64   \n",
       "1548015                              Urban Transit Systems         30     900   \n",
       "1548016                              Urban Transit Systems         33    1089   \n",
       "\n",
       "        hex_id  \n",
       "0        33561  \n",
       "1        52159  \n",
       "2        44888  \n",
       "3        46628  \n",
       "4        43514  \n",
       "...        ...  \n",
       "1548012  51477  \n",
       "1548013  56590  \n",
       "1548014  52995  \n",
       "1548015  57118  \n",
       "1548016  57647  \n",
       "\n",
       "[1678168 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a250c7-1f4d-4d20-a17a-6e1188765df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_vec(x):\n",
    "    # detect the NaN (it's a float)\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return (w_cls+b_cls).cpu().detach().numpy()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#ses_gdf['vec_mean'] = ses_gdf['vec_mean'].apply(fill_vec)\n",
    "\n",
    "\n",
    "#hex_gdf['vec_max'] = hex_gdf['vec_max'].apply(fill_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b919cf-c6af-49af-b0ff-173c83e75918",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c331c1fd-16ab-46dd-aee4-36bf27d7c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"point_gdf_raw.pickle\",\"rb\") as f:\n",
    "    point_gdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95879bfe-2c37-4197-9341-f2cd5ebdac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf = gpd.read_parquet(\"simulated_traj_points.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd438a72-9923-4558-971a-e3f4d6ad0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "377d6b12-3aa3-4e53-9288-8fc578355dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_2673/3162613191.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted_avg = ( joined .groupby('hex_id') .apply(lambda df: (np.stack(df['z'].values) * df['weight'].values[:, None]).sum(axis=0) / df['weight'].sum() ) )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# 1) extract just the category name (before “[sep]”) \n",
    "joined = joined.copy()\n",
    "joined['cat_name'] = joined['label_pair'].str.split(r'\\[sep\\]').str[0] \n",
    "# 2) compute the count per (hex_id, cat_name) and square it \n",
    "joined['cat_count'] = joined.groupby(['hex_id','cat_name'])['z'].transform('count') \n",
    "joined['weight'] = joined['cat_count'] ** 2 \n",
    "# 4) (optional) weighted‐average instead of sum \n",
    "weighted_avg = ( joined .groupby('hex_id') .apply(lambda df: (np.stack(df['z'].values) * df['weight'].values[:, None]).sum(axis=0) / df['weight'].sum() ) )\n",
    "\n",
    "# 5) merge back into your hex_gdf \n",
    "ses_gdf = ses_gdf.merge( weighted_avg.rename('vec_weighted_avg'), left_on='hex_id', right_index=True, how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "299851ce-0e6a-4583-9e97-6c7182190d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf['vec_weighted_avg'] = ses_gdf['vec_weighted_avg'].apply(fill_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd0330-99e3-4c1d-81f8-e5ce127eda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2e0ea77-2704-48b8-802a-f1b0617ca63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = ses_gdf.merge(merged, on=\"hex_id\", how=\"left\",suffixes=(None,\"_y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68f025c5-85b7-4361-91c9-5c3648bd2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.loc[:, ~new_df.columns.str.endswith(\"_y\")]   # drop all right duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d2291-f9fa-4d2b-9678-fd97efa1911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08221c88-2b96-48a4-8d08-25f019d2e713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   traj_id  pt_idx  \\\n",
      "0        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       1   \n",
      "1        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       3   \n",
      "2        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       5   \n",
      "3        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      20   \n",
      "4        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      21   \n",
      "...                                                    ...     ...   \n",
      "1677305  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     130   \n",
      "1677306  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     133   \n",
      "1677307  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     134   \n",
      "1677308  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     140   \n",
      "1677309  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     141   \n",
      "\n",
      "                           geometry  index_right         GEOID NAME  hex_id  \\\n",
      "0        POINT (-81.79671 24.54831)         9176  120879724002    2    9176   \n",
      "1        POINT (-81.79674 24.54832)         9176  120879724002    2    9176   \n",
      "2        POINT (-81.79665 24.54831)         9176  120879724002    2    9176   \n",
      "3        POINT (-81.94936 26.45101)         8345  120710601021    1    8345   \n",
      "4         POINT (-81.9493 26.45101)         8345  120710601021    1    8345   \n",
      "...                             ...          ...           ...  ...     ...   \n",
      "1677305  POINT (-81.50477 29.94249)        11002  121090209054    4   11002   \n",
      "1677306        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677307        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677308  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "1677309  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "\n",
      "                                                vec_mean_x  \\\n",
      "0        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "1        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "2        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "3        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "4        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "...                                                    ...   \n",
      "1677305  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677306  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677307  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677308  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677309  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "\n",
      "                                           graph_embedding  \\\n",
      "0        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "1        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "2        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "3        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "4        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "...                                                    ...   \n",
      "1677305  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677306  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677307  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677308  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677309  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "\n",
      "                                          vec_weighted_avg  ...  \\\n",
      "0        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "1        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "2        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "3        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "4        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "...                                                    ...  ...   \n",
      "1677305  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677306  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677307  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677308  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677309  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan  \\\n",
      "0                                                      170         \n",
      "1                                                      170         \n",
      "2                                                      170         \n",
      "3                                                      151         \n",
      "4                                                      151         \n",
      "...                                                    ...         \n",
      "1677305                                                775         \n",
      "1677306                                               2033         \n",
      "1677307                                               2033         \n",
      "1677308                                                775         \n",
      "1677309                                                775         \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                        \n",
      "1                                                        0                                                                        \n",
      "2                                                        0                                                                        \n",
      "3                                                       21                                                                        \n",
      "4                                                       21                                                                        \n",
      "...                                                    ...                                                                        \n",
      "1677305                                                 19                                                                        \n",
      "1677306                                                267                                                                        \n",
      "1677307                                                267                                                                        \n",
      "1677308                                                 19                                                                        \n",
      "1677309                                                 19                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
      "0                                                      197                                  \n",
      "1                                                      197                                  \n",
      "2                                                      197                                  \n",
      "3                                                      130                                  \n",
      "4                                                      130                                  \n",
      "...                                                    ...                                  \n",
      "1677305                                                722                                  \n",
      "1677306                                               1850                                  \n",
      "1677307                                               1850                                  \n",
      "1677308                                                722                                  \n",
      "1677309                                                722                                  \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
      "0                                                       46                                                                                                                          \n",
      "1                                                       46                                                                                                                          \n",
      "2                                                       46                                                                                                                          \n",
      "3                                                        0                                                                                                                          \n",
      "4                                                        0                                                                                                                          \n",
      "...                                                    ...                                                                                                                          \n",
      "1677305                                                 12                                                                                                                          \n",
      "1677306                                                 84                                                                                                                          \n",
      "1677307                                                 84                                                                                                                          \n",
      "1677308                                                 12                                                                                                                          \n",
      "1677309                                                 12                                                                                                                          \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service  \\\n",
      "0                                                       19                 \n",
      "1                                                       19                 \n",
      "2                                                       19                 \n",
      "3                                                        0                 \n",
      "4                                                        0                 \n",
      "...                                                    ...                 \n",
      "1677305                                                 64                 \n",
      "1677306                                                135                 \n",
      "1677307                                                135                 \n",
      "1677308                                                 64                 \n",
      "1677309                                                 64                 \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                                        \n",
      "1                                                        0                                                                                        \n",
      "2                                                        0                                                                                        \n",
      "3                                                        0                                                                                        \n",
      "4                                                        0                                                                                        \n",
      "...                                                    ...                                                                                        \n",
      "1677305                                                  0                                                                                        \n",
      "1677306                                                 51                                                                                        \n",
      "1677307                                                 51                                                                                        \n",
      "1677308                                                  0                                                                                        \n",
      "1677309                                                  0                                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                \n",
      "1                                                        0                                                \n",
      "2                                                        0                                                \n",
      "3                                                        0                                                \n",
      "4                                                        0                                                \n",
      "...                                                    ...                                                \n",
      "1677305                                                  0                                                \n",
      "1677306                                                  0                                                \n",
      "1677307                                                  0                                                \n",
      "1677308                                                  0                                                \n",
      "1677309                                                  0                                                \n",
      "\n",
      "         Total: Internet access without a subscription  \\\n",
      "0                                                   24   \n",
      "1                                                   24   \n",
      "2                                                   24   \n",
      "3                                                    0   \n",
      "4                                                    0   \n",
      "...                                                ...   \n",
      "1677305                                              0   \n",
      "1677306                                              0   \n",
      "1677307                                              0   \n",
      "1677308                                              0   \n",
      "1677309                                              0   \n",
      "\n",
      "         Total: No Internet access                        centroid  \n",
      "0                               64  POINT (1453140.506 277480.406)  \n",
      "1                               64  POINT (1453140.506 277480.406)  \n",
      "2                               64  POINT (1453140.506 277480.406)  \n",
      "3                               11   POINT (1407206.808 481749.98)  \n",
      "4                               11   POINT (1407206.808 481749.98)  \n",
      "...                            ...                             ...  \n",
      "1677305                         97   POINT (1392576.532 868512.68)  \n",
      "1677306                         20  POINT (1384276.061 882178.015)  \n",
      "1677307                         20  POINT (1384276.061 882178.015)  \n",
      "1677308                         97   POINT (1392576.532 868512.68)  \n",
      "1677309                         97   POINT (1392576.532 868512.68)  \n",
      "\n",
      "[1677317 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "point_buffer = point_gdf.to_crs(epsg=5070)\n",
    "ses_buffer = new_df.to_crs(epsg=5070)\n",
    "ses_buffer[\"centroid\"] = ses_buffer.centroid\n",
    "ses_gdf = ses_buffer.to_crs(epsg=4326)\n",
    "\n",
    "joined_nearest_ll = gpd.sjoin_nearest(\n",
    "    point_buffer[[\"traj_id\", \"pt_idx\", \"geometry\"]],  # keep only the columns we care about\n",
    "    ses_buffer.loc[:, ses_buffer.columns != 'NAME_x'],\n",
    "    how=\"left\"           # keep all points; hex attributes will be NaN if a point is unmatche\n",
    ")\n",
    "joined_nearest = joined_nearest_ll.to_crs(epsg=4326)\n",
    "print(joined_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41337ed5-63ed-4227-8feb-580cc0926c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n",
      "                                                   traj_id  pt_idx  \\\n",
      "0        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       1   \n",
      "1        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       3   \n",
      "2        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       5   \n",
      "3        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      20   \n",
      "4        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      21   \n",
      "...                                                    ...     ...   \n",
      "1677305  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     130   \n",
      "1677306  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     133   \n",
      "1677307  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     134   \n",
      "1677308  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     140   \n",
      "1677309  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     141   \n",
      "\n",
      "                           geometry  index_right         GEOID NAME  hex_id  \\\n",
      "0        POINT (-81.79671 24.54831)         9176  120879724002    2    9176   \n",
      "1        POINT (-81.79674 24.54832)         9176  120879724002    2    9176   \n",
      "2        POINT (-81.79665 24.54831)         9176  120879724002    2    9176   \n",
      "3        POINT (-81.94936 26.45101)         8345  120710601021    1    8345   \n",
      "4         POINT (-81.9493 26.45101)         8345  120710601021    1    8345   \n",
      "...                             ...          ...           ...  ...     ...   \n",
      "1677305  POINT (-81.50477 29.94249)        11002  121090209054    4   11002   \n",
      "1677306        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677307        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677308  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "1677309  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "\n",
      "                                                vec_mean_x  \\\n",
      "0        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "1        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "2        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "3        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "4        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "...                                                    ...   \n",
      "1677305  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677306  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677307  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677308  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677309  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "\n",
      "                                           graph_embedding  \\\n",
      "0        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "1        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "2        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "3        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "4        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "...                                                    ...   \n",
      "1677305  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677306  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677307  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677308  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677309  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "\n",
      "                                          vec_weighted_avg  ...  \\\n",
      "0        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "1        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "2        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "3        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "4        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "...                                                    ...  ...   \n",
      "1677305  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677306  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677307  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677308  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677309  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan  \\\n",
      "0                                                      170         \n",
      "1                                                      170         \n",
      "2                                                      170         \n",
      "3                                                      151         \n",
      "4                                                      151         \n",
      "...                                                    ...         \n",
      "1677305                                                775         \n",
      "1677306                                               2033         \n",
      "1677307                                               2033         \n",
      "1677308                                                775         \n",
      "1677309                                                775         \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                        \n",
      "1                                                        0                                                                        \n",
      "2                                                        0                                                                        \n",
      "3                                                       21                                                                        \n",
      "4                                                       21                                                                        \n",
      "...                                                    ...                                                                        \n",
      "1677305                                                 19                                                                        \n",
      "1677306                                                267                                                                        \n",
      "1677307                                                267                                                                        \n",
      "1677308                                                 19                                                                        \n",
      "1677309                                                 19                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
      "0                                                      197                                  \n",
      "1                                                      197                                  \n",
      "2                                                      197                                  \n",
      "3                                                      130                                  \n",
      "4                                                      130                                  \n",
      "...                                                    ...                                  \n",
      "1677305                                                722                                  \n",
      "1677306                                               1850                                  \n",
      "1677307                                               1850                                  \n",
      "1677308                                                722                                  \n",
      "1677309                                                722                                  \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
      "0                                                       46                                                                                                                          \n",
      "1                                                       46                                                                                                                          \n",
      "2                                                       46                                                                                                                          \n",
      "3                                                        0                                                                                                                          \n",
      "4                                                        0                                                                                                                          \n",
      "...                                                    ...                                                                                                                          \n",
      "1677305                                                 12                                                                                                                          \n",
      "1677306                                                 84                                                                                                                          \n",
      "1677307                                                 84                                                                                                                          \n",
      "1677308                                                 12                                                                                                                          \n",
      "1677309                                                 12                                                                                                                          \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service  \\\n",
      "0                                                       19                 \n",
      "1                                                       19                 \n",
      "2                                                       19                 \n",
      "3                                                        0                 \n",
      "4                                                        0                 \n",
      "...                                                    ...                 \n",
      "1677305                                                 64                 \n",
      "1677306                                                135                 \n",
      "1677307                                                135                 \n",
      "1677308                                                 64                 \n",
      "1677309                                                 64                 \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                                        \n",
      "1                                                        0                                                                                        \n",
      "2                                                        0                                                                                        \n",
      "3                                                        0                                                                                        \n",
      "4                                                        0                                                                                        \n",
      "...                                                    ...                                                                                        \n",
      "1677305                                                  0                                                                                        \n",
      "1677306                                                 51                                                                                        \n",
      "1677307                                                 51                                                                                        \n",
      "1677308                                                  0                                                                                        \n",
      "1677309                                                  0                                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                \n",
      "1                                                        0                                                \n",
      "2                                                        0                                                \n",
      "3                                                        0                                                \n",
      "4                                                        0                                                \n",
      "...                                                    ...                                                \n",
      "1677305                                                  0                                                \n",
      "1677306                                                  0                                                \n",
      "1677307                                                  0                                                \n",
      "1677308                                                  0                                                \n",
      "1677309                                                  0                                                \n",
      "\n",
      "         Total: Internet access without a subscription  \\\n",
      "0                                                   24   \n",
      "1                                                   24   \n",
      "2                                                   24   \n",
      "3                                                    0   \n",
      "4                                                    0   \n",
      "...                                                ...   \n",
      "1677305                                              0   \n",
      "1677306                                              0   \n",
      "1677307                                              0   \n",
      "1677308                                              0   \n",
      "1677309                                              0   \n",
      "\n",
      "         Total: No Internet access                        centroid  \n",
      "0                               64  POINT (1453140.506 277480.406)  \n",
      "1                               64  POINT (1453140.506 277480.406)  \n",
      "2                               64  POINT (1453140.506 277480.406)  \n",
      "3                               11   POINT (1407206.808 481749.98)  \n",
      "4                               11   POINT (1407206.808 481749.98)  \n",
      "...                            ...                             ...  \n",
      "1677305                         97   POINT (1392576.532 868512.68)  \n",
      "1677306                         20  POINT (1384276.061 882178.015)  \n",
      "1677307                         20  POINT (1384276.061 882178.015)  \n",
      "1677308                         97   POINT (1392576.532 868512.68)  \n",
      "1677309                         97   POINT (1392576.532 868512.68)  \n",
      "\n",
      "[1677310 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "clean_joined = joined_nearest.drop_duplicates(subset=[\"traj_id\", \"pt_idx\"])\n",
    "print(clean_joined.crs)\n",
    "\n",
    "print(clean_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb138ab1-8a2b-4b11-a2f4-349d9a506084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d1903-6a37-4e87-8e0d-65f64cb48a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined.vec_weighted_avg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2a150-40c0-47dd-aca1-467fbc157bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "373d28eb-de49-4e85-8747-cdfb3d1275ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_joined.copy()\n",
    "feature_dict = {}\n",
    "timeidx_dict = {}\n",
    "df[\"vec_weighted_avg\"] = df[\"vec_weighted_avg\"].apply(fill_vec)\n",
    "FIXED_LEN=143\n",
    "for traj_id, group in df.groupby('traj_id'):\n",
    "    grp = group.sort_values('pt_idx')\n",
    "    embs = np.stack(grp['graph_embedding'].values)    # (L, E)\n",
    "    vecs = np.stack(grp['vec_weighted_avg'].values)   # (L, V)\n",
    "    feature_dict[traj_id] = np.concatenate([embs, vecs], axis=1)  # (L, E+V)\n",
    "    # time indices must be integers in [0..FIXED_LEN-1]\n",
    "    # if pt_idx is 1-based you may want pt_idx-1; also clamp to FIXED_LEN-1\n",
    "    times = grp['pt_idx'].to_numpy().astype(int) - 1      \n",
    "    times = np.clip(times, 0, FIXED_LEN-1)\n",
    "    timeidx_dict[traj_id] = times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b5a459-4796-4a53-953e-cd239525a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajDatasetWithTimes(Dataset):\n",
    "    def __init__(self, feature_dict, timeidx_dict):\n",
    "        self.ids       = list(feature_dict.keys())\n",
    "        self.features  = feature_dict\n",
    "        self.times     = timeidx_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        traj_id = self.ids[i]\n",
    "        feat    = torch.from_numpy(self.features[traj_id]).float()  # (L, D)\n",
    "        times   = torch.from_numpy(self.times[traj_id]).long()     # (L,)\n",
    "        return feat, times, i, traj_id\n",
    "\n",
    "# 3) Custom collate that scatters each sample into its true time slots\n",
    "def collate_fn_time(batch):\n",
    "    B = len(batch)\n",
    "    feats, times_list, idxs = zip(*batch)\n",
    "    D = feats[0].size(1)\n",
    "\n",
    "    padded   = torch.zeros(B, FIXED_LEN, D, dtype=torch.float)\n",
    "    pad_mask = torch.ones (B, FIXED_LEN,    dtype=torch.bool)\n",
    "\n",
    "    for i, (feat, times) in enumerate(zip(feats, times_list)):\n",
    "        valid     = times < FIXED_LEN\n",
    "        t_idx     = times[valid]\n",
    "        f_vec     = feat[valid]         # shape (L_valid, D)\n",
    "        padded[i, t_idx]   = f_vec\n",
    "        pad_mask[i, t_idx] = False\n",
    "\n",
    "    idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "    return padded, pad_mask, idxs\n",
    "\n",
    "# 4) Build loaders\n",
    "\n",
    "\n",
    "# ─── Positional Encoding ────────────────────────────────────────────────────────\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                        -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]  # broadcast-add\n",
    "\n",
    "\n",
    "# ─── DEC Loss Components ───────────────────────────────────────────────────────\n",
    "def student_t_distribution(z, centers, alpha=1.0):\n",
    "    diff = z.unsqueeze(1) - centers.unsqueeze(0)\n",
    "    dist2 = diff.pow(2).sum(-1)\n",
    "    num = (1 + dist2/alpha).pow(-(alpha+1)/2)\n",
    "    return num / num.sum(1, keepdim=True)\n",
    "\n",
    "def target_distribution(q):\n",
    "    weight = q.pow(2) / q.sum(0, keepdim=True)\n",
    "    return (weight / weight.sum(1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2faa5509-a944-405f-9574-a873760f1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# ---- Positional encoding with 24h time-of-day ----\n",
    "class PositionalEncodingTimeOfDay(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 500, hod_harmonics: int = 1):\n",
    "        \"\"\"\n",
    "        d_model: model dimension\n",
    "        max_len: max sequence length for absolute PE\n",
    "        hod_harmonics: number of 24h harmonics (1 => sin/cos; 2+ adds higher freq)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Absolute sinusoidal PE (as you had)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float)\n",
    "            * (-(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)  # (1, max_len, d_model)\n",
    "\n",
    "        # 24h cyclic features -> project to d_model, then add\n",
    "        self.hod_harmonics = int(hod_harmonics)\n",
    "        self.hod_proj = nn.Linear(2 * self.hod_harmonics, d_model, bias=False)\n",
    "        # learnable gate so the model can scale this signal\n",
    "        self.hod_scale = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _hours_from_start(self, B, L, device, start_hour):\n",
    "        idx = torch.arange(L, device=device).view(1, L)  # 0..L-1\n",
    "        if isinstance(start_hour, int):\n",
    "            start = torch.full((B, 1), start_hour, device=device, dtype=torch.long)\n",
    "        else:\n",
    "            start = torch.as_tensor(start_hour, device=device).view(B, 1).long()\n",
    "        return (start + idx) % 24  # (B, L)\n",
    "\n",
    "    def forward(self, x, *, hours: torch.Tensor = None, start_hour=None):\n",
    "        \"\"\"\n",
    "        x: (B, L, d_model)\n",
    "        hours: optional (B, L) int tensor in [0..23]\n",
    "        start_hour: optional int or (B,) tensor; used if `hours` is None\n",
    "        \"\"\"\n",
    "        B, L, D = x.shape\n",
    "\n",
    "        # absolute PE\n",
    "        out = x + self.pe[:, :L]\n",
    "\n",
    "        # time-of-day PE\n",
    "        if hours is None:\n",
    "            if start_hour is None:\n",
    "                raise ValueError(\"Provide `hours` (B,L ints 0..23) or `start_hour` (int or (B,) tensor).\")\n",
    "            hours = self._hours_from_start(B, L, x.device, start_hour)\n",
    "        else:\n",
    "            hours = torch.as_tensor(hours, device=x.device).long()\n",
    "            if hours.shape != (B, L):\n",
    "                raise ValueError(f\"`hours` must be (B, L), got {hours.shape}\")\n",
    "\n",
    "        phase = 2 * math.pi * (hours.float() / 24.0)  # (B, L)\n",
    "        feats = []\n",
    "        for m in range(1, self.hod_harmonics + 1):\n",
    "            feats.append(torch.sin(m * phase))\n",
    "            feats.append(torch.cos(m * phase))\n",
    "        hod = torch.stack(feats, dim=-1)              # (B, L, 2*M)\n",
    "        hod = self.hod_proj(hod) * self.hod_scale     # (B, L, d_model)\n",
    "\n",
    "        return out + hod\n",
    "\n",
    "\n",
    "# ---- Your model, modified to accept hours/start_hour and lengths ----\n",
    "class TrajTransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=16, num_layers=3, dropout=0.1,\n",
    "                 max_len=500, hod_harmonics=1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # replace with time-of-day aware PE\n",
    "        self.pos_enc = PositionalEncodingTimeOfDay(d_model, max_len=max_len,\n",
    "                                                   hod_harmonics=hod_harmonics)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward=512, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model, nhead, dim_feedforward=512, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def _make_padding_mask(self, lengths, L, device):\n",
    "        # True where we want to MASK (i.e., padding positions)\n",
    "        if lengths is None:\n",
    "            return None\n",
    "        lengths = torch.as_tensor(lengths, device=device).long()  # (B,)\n",
    "        idx = torch.arange(L, device=device).unsqueeze(0)         # (1, L)\n",
    "        return (idx >= lengths.unsqueeze(1))                      # (B, L) boolean\n",
    "\n",
    "    def forward(self, x, lengths=None, src_key_padding_mask=None,\n",
    "                hours: torch.Tensor = None, start_hour=None):\n",
    "        \"\"\"\n",
    "        x: (B, L, D_in)\n",
    "        lengths: optional (B,) true lengths (for masks)\n",
    "        hours: optional (B, L) integers 0..23 (time-of-day for each token)\n",
    "        start_hour: optional int or (B,) if `hours` not provided\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # masks\n",
    "        if src_key_padding_mask is None:\n",
    "            src_key_padding_mask = self._make_padding_mask(lengths, L, device)\n",
    "\n",
    "        # ---- Encoder path\n",
    "        src_emb = self.input_proj(x)  # (B, L, d_model)\n",
    "        src_emb = self.pos_enc(src_emb, hours=hours, start_hour=start_hour)  # add abs + 24h\n",
    "        memory = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # ---- Decoder input: zeros + SAME positions & hours (we reconstruct x at same steps)\n",
    "        tgt_emb = torch.zeros(B, L, memory.size(-1), device=device)\n",
    "        # pass the same hours/start_hour so decoder “knows” positions and day phase, too\n",
    "        tgt_emb = self.pos_enc(tgt_emb, hours=hours, start_hour=start_hour)\n",
    "\n",
    "        # If you have padding, use the same mask for tgt and memory padding mask\n",
    "        output_seq = self.decoder(tgt_emb, memory,\n",
    "                                  tgt_key_padding_mask=src_key_padding_mask,\n",
    "                                  memory_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        recon = self.output_layer(output_seq)  # (B, L, input_dim)\n",
    "        z = memory.mean(dim=1)                 # (B, d_model) latent embedding\n",
    "        return recon, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eb5a488-12cb-4b86-99c0-415f03f9f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "FIXED_LEN = 143\n",
    "\n",
    "class TrajDatasetWithTimes(Dataset):\n",
    "    def __init__(self, feature_dict, timeidx_dict):\n",
    "        self.ids       = list(feature_dict.keys())\n",
    "        self.features  = feature_dict\n",
    "        self.times     = timeidx_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        traj_id = self.ids[i]\n",
    "        feat    = torch.from_numpy(self.features[traj_id]).float()  # (L, D) may contain NaNs\n",
    "        times   = torch.from_numpy(self.times[traj_id]).long()      # (L,)\n",
    "        return feat, times, i, traj_id\n",
    "\n",
    "\n",
    "def make_collate_fn_time(fixed_len=143, start_hour=0, fill_value=0.0):\n",
    "    def collate_fn_time(batch):\n",
    "        B = len(batch)\n",
    "        feats, times_list, idxs, traj_ids = zip(*batch)\n",
    "        D = feats[0].size(1)\n",
    "\n",
    "        padded   = torch.full((B, fixed_len, D), fill_value, dtype=torch.float)\n",
    "        pad_mask = torch.ones (B, fixed_len,      dtype=torch.bool)\n",
    "        obs_mask = torch.zeros(B, fixed_len, D,   dtype=torch.bool)\n",
    "\n",
    "        for i, (feat, times) in enumerate(zip(feats, times_list)):\n",
    "            # 1) keep only indices within range\n",
    "            valid = (times >= 0) & (times < fixed_len)\n",
    "            t = times[valid]           # (N,)\n",
    "            f = feat[valid]            # (N, D)\n",
    "\n",
    "            if t.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            # 2) per-row observed flags and NaN-safe features\n",
    "            obs_row   = torch.isfinite(f).to(f.dtype)         # (N, D) 1.0 where observed\n",
    "            f_clean   = torch.nan_to_num(f, nan=0.0)          # (N, D)\n",
    "\n",
    "            # 3) aggregate duplicates by unique time index\n",
    "            uniq, inv = torch.unique(t, return_inverse=True)  # uniq: (M,), inv: (N,)\n",
    "            M = uniq.numel()\n",
    "\n",
    "            # sum of values per (uniq time, feature)\n",
    "            sum_feat = torch.zeros(M, D, dtype=f.dtype)\n",
    "            sum_feat.index_add_(0, inv, f_clean)\n",
    "\n",
    "            # count of observed entries per (uniq time, feature)\n",
    "            cnt_feat = torch.zeros(M, D, dtype=f.dtype)\n",
    "            cnt_feat.index_add_(0, inv, obs_row)\n",
    "\n",
    "            # mean over observed entries (stay 0 where count==0)\n",
    "            mean_feat = sum_feat / cnt_feat.clamp_min(1.0)    # (M, D)\n",
    "            obs_u     = cnt_feat > 0                           # (M, D) bool\n",
    "\n",
    "            # 4) write once per unique index (no overlapping writes)\n",
    "            padded[i, uniq]   = mean_feat\n",
    "            obs_mask[i, uniq] = obs_u\n",
    "            pad_mask[i, uniq] = False\n",
    "\n",
    "        # hours-of-day (independent storage; safe even if later modified)\n",
    "        hours_row = (torch.arange(fixed_len) + int(start_hour)) % 24  # (fixed_len,)\n",
    "        hours = hours_row.unsqueeze(0).repeat(B, 1).long()            # (B, L)\n",
    "\n",
    "        idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "        return padded, pad_mask, obs_mask, hours, idxs, list(traj_ids)\n",
    "    return collate_fn_time\n",
    "\n",
    "\n",
    "# ---- Build loader ----\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = TrajDatasetWithTimes(feature_dict, timeidx_dict)\n",
    "\n",
    "collate_fn = make_collate_fn_time(fixed_len=FIXED_LEN, start_hour=0)  # all sequences start at 0–1 AM\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,                 # better for SGD\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=(DEVICE.type == 'cuda'),\n",
    "    # num_workers=4,              # enable if your environment supports it\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29676d93-9cfc-47b7-bc8d-c815a2c55791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92ccde80-af02-4e97-98c1-0534b70784da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_2014/2710695643.py:58: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Assumes:\n",
    "#  - TrajDatasetWithTimes + make_collate_fn_time defined as in your last message\n",
    "#  - TrajTransformerAutoencoder uses the time-of-day PE (accepts hours=... or start_hour=...)\n",
    "#  - feature_dict, timeidx_dict already built\n",
    "\n",
    "# -------------------- SPLIT --------------------\n",
    "dataset = TrajDatasetWithTimes(feature_dict, timeidx_dict)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "all_idx = np.arange(len(dataset))\n",
    "rng.shuffle(all_idx)\n",
    "\n",
    "n = len(all_idx)\n",
    "n_train = int(0.80 * n)\n",
    "n_val   = int(0.10 * n)\n",
    "idx_train = all_idx[:n_train]\n",
    "idx_val   = all_idx[n_train:n_train+n_val]\n",
    "idx_test  = all_idx[n_train+n_val:]\n",
    "\n",
    "train_ds = Subset(dataset, idx_train)\n",
    "val_ds   = Subset(dataset, idx_val)\n",
    "test_ds  = Subset(dataset, idx_test)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "collate_fn = make_collate_fn_time(fixed_len=143, start_hour=0)\n",
    "\n",
    "BS = 128\n",
    "train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BS, shuffle=False,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BS, shuffle=False,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "model = TrajTransformerAutoencoder(\n",
    "    input_dim=128, d_model=64, nhead=8, num_layers=4, dropout=0.1,\n",
    "    max_len=143, hod_harmonics=1\n",
    ").to(DEVICE)\n",
    "\n",
    "# -------------------- TRAINING CONFIG --------------------\n",
    "num_epochs       = 1000\n",
    "warmup_epochs    = 100\n",
    "lambda_l2_target = 1.0\n",
    "patience         = 30\n",
    "checkpoint_path  = \"./models/best_model_tod_2.pth\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "opt       = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epochs)\n",
    "use_amp   = (DEVICE.type == \"cuda\")\n",
    "scaler    = GradScaler(enabled=use_amp)\n",
    "max_grad  = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7b76c1c-ef28-476c-8d10-c2d434a9c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== helpers (MSE path) ====================================================\n",
    "@torch.no_grad()\n",
    "def estimate_feature_stats(loader, device):\n",
    "    \"\"\"Per-feature mean/std over observed, non-padded entries only.\"\"\"\n",
    "    sum_, sumsq, count = None, None, None\n",
    "    for x, pad_mask, obs_mask, *_ in loader:\n",
    "        x        = x.to(device)                  # (B,L,D)\n",
    "        pad_mask = pad_mask.to(device).bool()    # (B,L)\n",
    "        obs_mask = obs_mask.to(device).bool()    # (B,L,D)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)   # (B,L,D)\n",
    "        v = valid.float()\n",
    "        if sum_ is None:\n",
    "            D = x.size(-1)\n",
    "            sum_  = torch.zeros(D, device=device)\n",
    "            sumsq = torch.zeros(D, device=device)\n",
    "            count = torch.zeros(D, device=device)\n",
    "        sum_  += (x * v).sum(dim=(0,1))\n",
    "        sumsq += ((x * x) * v).sum(dim=(0,1))\n",
    "        count += v.sum(dim=(0,1))\n",
    "    mean = sum_ / count.clamp_min(1.0)\n",
    "    var  = (sumsq / count.clamp_min(1.0)) - mean.pow(2)\n",
    "    std  = var.clamp_min(1e-6).sqrt()\n",
    "    return mean.detach(), std.detach()\n",
    "def standardize_batch(x, obs_mask, mean, std, pad_mask=None):\n",
    "    \"\"\"Return (x_in_for_model, x_std_target) in standardized units.\"\"\"\n",
    "    x_std = (x - mean.view(1,1,-1)) / std.view(1,1,-1)\n",
    "    x_in  = x_std.masked_fill(~obs_mask, 0.0)\n",
    "    if pad_mask is not None:\n",
    "        x_in = x_in.masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "    return x_in, x_std\n",
    "\n",
    "def masked_mse(recon, x_std_target, pad_mask, obs_mask):\n",
    "    valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "    diff  = (recon - x_std_target)[valid]\n",
    "    return (diff * diff).mean()\n",
    "\n",
    "def masked_huber(recon, x_std_target, pad_mask, obs_mask, delta=1.0):\n",
    "    valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "    diff  = (recon - x_std_target)[valid]\n",
    "    absd  = diff.abs()\n",
    "    quad  = torch.minimum(absd, torch.tensor(delta, device=diff.device))\n",
    "    return (0.5 * quad.pow(2) + delta * (absd - quad)).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"Standardized MSE over observed & non-padded entries.\"\"\"\n",
    "    model.eval()\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "        recon, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (recon - x_std_tgt)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"MSE in ORIGINAL units; inputs preprocessed same as training (std + zeros).\"\"\"\n",
    "    model.eval()\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_in, _ = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "        recon_std, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        recon = recon_std * feat_std.view(1,1,-1) + feat_mean.view(1,1,-1)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (recon - x)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_null_zero(loader, device, feat_mean, feat_std):\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        pred  = torch.zeros_like(x_std)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (pred - x_std)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "837a5c90-b42a-4283-8e18-6d9ab3da3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume] Loaded checkpoint from './models/best_model_tod_3.pth' at epoch 303, best_val=0.123534\n",
      "🧪 Test MSE (std): 0.123172   |  Test MSE (orig): 5.906412\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# ---- build your model exactly as before ----\n",
    "DEVICE   = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "use_amp  = (DEVICE.type == 'cuda')\n",
    "model    = TrajTransformerAutoencoder(input_dim=128, d_model=64, nhead=8, num_layers=4, dropout=0.15).to(DEVICE)\n",
    "\n",
    "# ---- optimizer / scheduler (same hyperparams as before) ----\n",
    "num_epochs = 1000\n",
    "opt        = optim.Adam(model.parameters(), lr=5e-4, weight_decay=2e-5)\n",
    "scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epochs)\n",
    "scaler     = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "checkpoint_path = \"./models/best_model_tod_3.pth\"\n",
    "#checkpoint_path  = \"./models/best_model_tod_finetune_2_simulation.pth\"\n",
    "def _move_opt_state_to_device(optimizer, device):\n",
    "    # Adam stores running stats as tensors; move them to the active device.\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "def resume_or_init(checkpoint_path, model, opt, scheduler=None, scaler=None, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Returns: start_epoch, best_val, feat_mean, feat_std\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    best_val    = float('inf')\n",
    "    feat_mean = None\n",
    "    feat_std  = None\n",
    "\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        # Model weights (allow non-strict in case you added buffers/PE params)\n",
    "        missing, unexpected = model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
    "        if missing or unexpected:\n",
    "            print(f\"[resume] missing keys: {missing}\\n[resume] unexpected keys: {unexpected}\")\n",
    "\n",
    "        # Optimizer / scheduler / scaler\n",
    "        if 'optimizer_state_dict' in ckpt:\n",
    "            opt.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "            _move_opt_state_to_device(opt, device)\n",
    "        if scheduler is not None and 'scheduler_state_dict' in ckpt:\n",
    "            scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n",
    "        if scaler is not None and 'scaler_state_dict' in ckpt:\n",
    "            try:\n",
    "                scaler.load_state_dict(ckpt['scaler_state_dict'])\n",
    "            except Exception:\n",
    "                pass  # scaler might not have been saved previously\n",
    "\n",
    "        # Epoch & metrics (support old/new key names)\n",
    "        start_epoch = int(ckpt.get('epoch', -1)) + 1\n",
    "        best_val    = float(ckpt.get('best_val_mse', ckpt.get('best_train_loss', float('inf'))))\n",
    "\n",
    "        # Feature standardization (if saved)\n",
    "        if 'feat_mean' in ckpt and 'feat_std' in ckpt:\n",
    "            feat_mean = ckpt['feat_mean'].to(device)\n",
    "            feat_std  = ckpt['feat_std'].to(device)\n",
    "\n",
    "        print(f\"[resume] Loaded checkpoint from '{checkpoint_path}' at epoch {start_epoch}, best_val={best_val:.6f}\")\n",
    "    else:\n",
    "        print(f\"[resume] No checkpoint found at '{checkpoint_path}'. Starting fresh.\")\n",
    "\n",
    "    return start_epoch, best_val, feat_mean, feat_std\n",
    "\n",
    "# ---- if you need train-only stats but checkpoint doesn't have them ----\n",
    "def estimate_feature_stats_once(train_loader, device):\n",
    "    x_sum = None; x_sqsum = None; n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, pad, obs, *_ in train_loader:\n",
    "            x = x.to(device)\n",
    "            valid = obs.to(device).bool() & (~pad.to(device).bool()).unsqueeze(-1)\n",
    "            xs = x[valid]\n",
    "            if x_sum is None:\n",
    "                D = x.shape[-1]\n",
    "                x_sum   = xs.sum(dim=0)\n",
    "                x_sqsum = (xs*xs).sum(dim=0)\n",
    "            else:\n",
    "                x_sum   += xs.sum(dim=0)\n",
    "                x_sqsum += (xs*xs).sum(dim=0)\n",
    "            n += xs.shape[0]\n",
    "    mean = x_sum / max(1, n)\n",
    "    var  = x_sqsum / max(1, n) - mean*mean\n",
    "    std  = torch.sqrt(torch.clamp(var, min=1e-8))\n",
    "    return mean, std\n",
    "\n",
    "# ---------- RESUME ----------\n",
    "start_epoch, best_val, ckpt_mean, ckpt_std = resume_or_init(\n",
    "    checkpoint_path, model, opt, scheduler, scaler, DEVICE\n",
    ")\n",
    "\n",
    "# If the checkpoint did not include feature stats, compute them now\n",
    "if ckpt_mean is not None and ckpt_std is not None:\n",
    "    feat_mean, feat_std = ckpt_mean, ckpt_std\n",
    "else:\n",
    "    # you already computed these above; if not:\n",
    "    # feat_mean, feat_std = estimate_feature_stats_once(train_loader, DEVICE)\n",
    "    feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "# ---------- (OPTIONAL) evaluate right after loading ----------\n",
    "test_mse_std = evaluate(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "test_mse_org = evaluate_original_scale(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "print(f\"🧪 Test MSE (std): {test_mse_std:.6f}   |  Test MSE (orig): {test_mse_org:.6f}\")\n",
    "\n",
    "# ---------- CONTINUE TRAINING ----------\n",
    "# Use star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13f736c7-7ef5-4bf9-8daf-ebfd46498d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, logging\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(\"train\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# avoid duplicate handlers if you re-run cells\n",
    "logger.handlers.clear()\n",
    "\n",
    "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "                        datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "fh = logging.FileHandler(\"logs/train_log.txt\", encoding=\"utf-8\")\n",
    "fh.setFormatter(fmt); fh.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(fmt); ch.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(fh); logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ee41078-ce84-4a5c-914c-910d71426bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11791a1f77c4ce8b35512625675a3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:54:36 | INFO | Epoch 000 — train_mse(std): 0.657968  val_mse(std): 0.398767  val_ema: 0.657968  last l2: 0.001594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 000 — train_mse(std): 0.657968  val_mse(std): 0.398767  val_ema: 0.657968  last l2: 0.001594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:54:36 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:55:25 | INFO | Epoch 001 — train_mse(std): 0.356456  val_mse(std): 0.232869  val_ema: 0.356456  last l2: 0.000903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 001 — train_mse(std): 0.356456  val_mse(std): 0.232869  val_ema: 0.356456  last l2: 0.000903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:55:25 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:56:14 | INFO | Epoch 002 — train_mse(std): 0.251370  val_mse(std): 0.176105  val_ema: 0.251370  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 002 — train_mse(std): 0.251370  val_mse(std): 0.176105  val_ema: 0.251370  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:56:14 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:04 | INFO | Epoch 003 — train_mse(std): 0.211749  val_mse(std): 0.154745  val_ema: 0.211749  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 003 — train_mse(std): 0.211749  val_mse(std): 0.154745  val_ema: 0.211749  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:05 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:55 | INFO | Epoch 004 — train_mse(std): 0.193569  val_mse(std): 0.146567  val_ema: 0.193569  last l2: 0.000532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 004 — train_mse(std): 0.193569  val_mse(std): 0.146567  val_ema: 0.193569  last l2: 0.000532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:55 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:58:45 | INFO | Epoch 005 — train_mse(std): 0.182340  val_mse(std): 0.140709  val_ema: 0.182340  last l2: 0.000504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 005 — train_mse(std): 0.182340  val_mse(std): 0.140709  val_ema: 0.182340  last l2: 0.000504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:58:45 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:59:34 | INFO | Epoch 006 — train_mse(std): 0.175548  val_mse(std): 0.136471  val_ema: 0.175548  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 006 — train_mse(std): 0.175548  val_mse(std): 0.136471  val_ema: 0.175548  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:59:34 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:00:23 | INFO | Epoch 007 — train_mse(std): 0.169993  val_mse(std): 0.133248  val_ema: 0.169993  last l2: 0.000509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 007 — train_mse(std): 0.169993  val_mse(std): 0.133248  val_ema: 0.169993  last l2: 0.000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:00:23 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:01:12 | INFO | Epoch 008 — train_mse(std): 0.166767  val_mse(std): 0.131351  val_ema: 0.166767  last l2: 0.000641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 008 — train_mse(std): 0.166767  val_mse(std): 0.131351  val_ema: 0.166767  last l2: 0.000641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:01:12 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:01 | INFO | Epoch 009 — train_mse(std): 0.163981  val_mse(std): 0.129934  val_ema: 0.163981  last l2: 0.000645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 009 — train_mse(std): 0.163981  val_mse(std): 0.129934  val_ema: 0.163981  last l2: 0.000645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:01 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:50 | INFO | Epoch 010 — train_mse(std): 0.161740  val_mse(std): 0.127993  val_ema: 0.161740  last l2: 0.000580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 010 — train_mse(std): 0.161740  val_mse(std): 0.127993  val_ema: 0.161740  last l2: 0.000580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:50 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:03:38 | INFO | Epoch 011 — train_mse(std): 0.159046  val_mse(std): 0.126898  val_ema: 0.159046  last l2: 0.000654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 011 — train_mse(std): 0.159046  val_mse(std): 0.126898  val_ema: 0.159046  last l2: 0.000654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:03:38 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:04:27 | INFO | Epoch 012 — train_mse(std): 0.156910  val_mse(std): 0.126340  val_ema: 0.156910  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 012 — train_mse(std): 0.156910  val_mse(std): 0.126340  val_ema: 0.156910  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:04:27 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:05:17 | INFO | Epoch 013 — train_mse(std): 0.155779  val_mse(std): 0.124418  val_ema: 0.155779  last l2: 0.000820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 013 — train_mse(std): 0.155779  val_mse(std): 0.124418  val_ema: 0.155779  last l2: 0.000820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:05:17 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:07 | INFO | Epoch 014 — train_mse(std): 0.154636  val_mse(std): 0.125700  val_ema: 0.154636  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 014 — train_mse(std): 0.154636  val_mse(std): 0.125700  val_ema: 0.154636  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:07 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:58 | INFO | Epoch 015 — train_mse(std): 0.152880  val_mse(std): 0.123939  val_ema: 0.152880  last l2: 0.000687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 015 — train_mse(std): 0.152880  val_mse(std): 0.123939  val_ema: 0.152880  last l2: 0.000687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:58 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:07:47 | INFO | Epoch 016 — train_mse(std): 0.152070  val_mse(std): 0.123013  val_ema: 0.152070  last l2: 0.000714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 016 — train_mse(std): 0.152070  val_mse(std): 0.123013  val_ema: 0.152070  last l2: 0.000714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:07:47 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:08:37 | INFO | Epoch 017 — train_mse(std): 0.151241  val_mse(std): 0.123075  val_ema: 0.151241  last l2: 0.000853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 017 — train_mse(std): 0.151241  val_mse(std): 0.123075  val_ema: 0.151241  last l2: 0.000853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:08:37 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:09:27 | INFO | Epoch 018 — train_mse(std): 0.150740  val_mse(std): 0.122094  val_ema: 0.150740  last l2: 0.001127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 018 — train_mse(std): 0.150740  val_mse(std): 0.122094  val_ema: 0.150740  last l2: 0.001127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:09:27 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:10:17 | INFO | Epoch 019 — train_mse(std): 0.149966  val_mse(std): 0.124055  val_ema: 0.149966  last l2: 0.001263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 019 — train_mse(std): 0.149966  val_mse(std): 0.124055  val_ema: 0.149966  last l2: 0.001263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:10:17 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:07 | INFO | Epoch 020 — train_mse(std): 0.149710  val_mse(std): 0.122020  val_ema: 0.149710  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 020 — train_mse(std): 0.149710  val_mse(std): 0.122020  val_ema: 0.149710  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:07 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:57 | INFO | Epoch 021 — train_mse(std): 0.148886  val_mse(std): 0.121973  val_ema: 0.148886  last l2: 0.000826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 021 — train_mse(std): 0.148886  val_mse(std): 0.121973  val_ema: 0.148886  last l2: 0.000826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:57 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:12:46 | INFO | Epoch 022 — train_mse(std): 0.148518  val_mse(std): 0.121442  val_ema: 0.148518  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 022 — train_mse(std): 0.148518  val_mse(std): 0.121442  val_ema: 0.148518  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:12:47 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:13:36 | INFO | Epoch 023 — train_mse(std): 0.148065  val_mse(std): 0.121496  val_ema: 0.148065  last l2: 0.001157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 023 — train_mse(std): 0.148065  val_mse(std): 0.121496  val_ema: 0.148065  last l2: 0.001157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:13:36 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:14:25 | INFO | Epoch 024 — train_mse(std): 0.147480  val_mse(std): 0.120894  val_ema: 0.147480  last l2: 0.001517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 024 — train_mse(std): 0.147480  val_mse(std): 0.120894  val_ema: 0.147480  last l2: 0.001517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:14:25 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:15:14 | INFO | Epoch 025 — train_mse(std): 0.147261  val_mse(std): 0.122632  val_ema: 0.147261  last l2: 0.001348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 025 — train_mse(std): 0.147261  val_mse(std): 0.122632  val_ema: 0.147261  last l2: 0.001348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:15:14 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:02 | INFO | Epoch 026 — train_mse(std): 0.148065  val_mse(std): 0.120654  val_ema: 0.148065  last l2: 0.000843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 026 — train_mse(std): 0.148065  val_mse(std): 0.120654  val_ema: 0.148065  last l2: 0.000843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:51 | INFO | Epoch 027 — train_mse(std): 0.146942  val_mse(std): 0.120430  val_ema: 0.146942  last l2: 0.001107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 027 — train_mse(std): 0.146942  val_mse(std): 0.120430  val_ema: 0.146942  last l2: 0.001107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:51 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:17:39 | INFO | Epoch 028 — train_mse(std): 0.146430  val_mse(std): 0.123608  val_ema: 0.146430  last l2: 0.001690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 028 — train_mse(std): 0.146430  val_mse(std): 0.123608  val_ema: 0.146430  last l2: 0.001690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:17:39 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:18:28 | INFO | Epoch 029 — train_mse(std): 0.146033  val_mse(std): 0.120278  val_ema: 0.146033  last l2: 0.001318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 029 — train_mse(std): 0.146033  val_mse(std): 0.120278  val_ema: 0.146033  last l2: 0.001318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:18:28 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:19:17 | INFO | Epoch 030 — train_mse(std): 0.147227  val_mse(std): 0.120477  val_ema: 0.147227  last l2: 0.001134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 030 — train_mse(std): 0.147227  val_mse(std): 0.120477  val_ema: 0.147227  last l2: 0.001134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:05 | INFO | Epoch 031 — train_mse(std): 0.145493  val_mse(std): 0.120019  val_ema: 0.145493  last l2: 0.000901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 031 — train_mse(std): 0.145493  val_mse(std): 0.120019  val_ema: 0.145493  last l2: 0.000901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:05 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:53 | INFO | Epoch 032 — train_mse(std): 0.145444  val_mse(std): 0.122823  val_ema: 0.145444  last l2: 0.000980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 032 — train_mse(std): 0.145444  val_mse(std): 0.122823  val_ema: 0.145444  last l2: 0.000980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:21:41 | INFO | Epoch 033 — train_mse(std): 0.145667  val_mse(std): 0.119850  val_ema: 0.145667  last l2: 0.001444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 033 — train_mse(std): 0.145667  val_mse(std): 0.119850  val_ema: 0.145667  last l2: 0.001444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:22:31 | INFO | Epoch 034 — train_mse(std): 0.145077  val_mse(std): 0.119917  val_ema: 0.145077  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 034 — train_mse(std): 0.145077  val_mse(std): 0.119917  val_ema: 0.145077  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:22:31 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:23:21 | INFO | Epoch 035 — train_mse(std): 0.145271  val_mse(std): 0.120079  val_ema: 0.145271  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 035 — train_mse(std): 0.145271  val_mse(std): 0.120079  val_ema: 0.145271  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:24:10 | INFO | Epoch 036 — train_mse(std): 0.145010  val_mse(std): 0.119868  val_ema: 0.145010  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 036 — train_mse(std): 0.145010  val_mse(std): 0.119868  val_ema: 0.145010  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:00 | INFO | Epoch 037 — train_mse(std): 0.144819  val_mse(std): 0.124801  val_ema: 0.144819  last l2: 0.001709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 037 — train_mse(std): 0.144819  val_mse(std): 0.124801  val_ema: 0.144819  last l2: 0.001709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:00 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:49 | INFO | Epoch 038 — train_mse(std): 0.145099  val_mse(std): 0.119710  val_ema: 0.145099  last l2: 0.000998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 038 — train_mse(std): 0.145099  val_mse(std): 0.119710  val_ema: 0.145099  last l2: 0.000998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:26:39 | INFO | Epoch 039 — train_mse(std): 0.144176  val_mse(std): 0.119724  val_ema: 0.144176  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 039 — train_mse(std): 0.144176  val_mse(std): 0.119724  val_ema: 0.144176  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:26:39 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:27:28 | INFO | Epoch 040 — train_mse(std): 0.143993  val_mse(std): 0.119417  val_ema: 0.143993  last l2: 0.001391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 040 — train_mse(std): 0.143993  val_mse(std): 0.119417  val_ema: 0.143993  last l2: 0.001391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:27:28 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:28:17 | INFO | Epoch 041 — train_mse(std): 0.144166  val_mse(std): 0.119564  val_ema: 0.144166  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 041 — train_mse(std): 0.144166  val_mse(std): 0.119564  val_ema: 0.144166  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:29:07 | INFO | Epoch 042 — train_mse(std): 0.144874  val_mse(std): 0.123009  val_ema: 0.144874  last l2: 0.000996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 042 — train_mse(std): 0.144874  val_mse(std): 0.123009  val_ema: 0.144874  last l2: 0.000996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:29:56 | INFO | Epoch 043 — train_mse(std): 0.144414  val_mse(std): 0.119315  val_ema: 0.144414  last l2: 0.000749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 043 — train_mse(std): 0.144414  val_mse(std): 0.119315  val_ema: 0.144414  last l2: 0.000749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:30:45 | INFO | Epoch 044 — train_mse(std): 0.143427  val_mse(std): 0.121894  val_ema: 0.143427  last l2: 0.001353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 044 — train_mse(std): 0.143427  val_mse(std): 0.121894  val_ema: 0.143427  last l2: 0.001353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:30:45 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:31:35 | INFO | Epoch 045 — train_mse(std): 0.144043  val_mse(std): 0.119630  val_ema: 0.144043  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 045 — train_mse(std): 0.144043  val_mse(std): 0.119630  val_ema: 0.144043  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:32:25 | INFO | Epoch 046 — train_mse(std): 0.143026  val_mse(std): 0.119075  val_ema: 0.143026  last l2: 0.001100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 046 — train_mse(std): 0.143026  val_mse(std): 0.119075  val_ema: 0.143026  last l2: 0.001100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:32:25 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:33:15 | INFO | Epoch 047 — train_mse(std): 0.142840  val_mse(std): 0.119132  val_ema: 0.142840  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 047 — train_mse(std): 0.142840  val_mse(std): 0.119132  val_ema: 0.142840  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:33:15 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:05 | INFO | Epoch 048 — train_mse(std): 0.143125  val_mse(std): 0.119211  val_ema: 0.143125  last l2: 0.000823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 048 — train_mse(std): 0.143125  val_mse(std): 0.119211  val_ema: 0.143125  last l2: 0.000823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:56 | INFO | Epoch 049 — train_mse(std): 0.142567  val_mse(std): 0.119013  val_ema: 0.142567  last l2: 0.000897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 049 — train_mse(std): 0.142567  val_mse(std): 0.119013  val_ema: 0.142567  last l2: 0.000897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:56 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:35:45 | INFO | Epoch 050 — train_mse(std): 0.142618  val_mse(std): 0.119318  val_ema: 0.142618  last l2: 0.001303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 050 — train_mse(std): 0.142618  val_mse(std): 0.119318  val_ema: 0.142618  last l2: 0.001303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:36:35 | INFO | Epoch 051 — train_mse(std): 0.144058  val_mse(std): 0.119228  val_ema: 0.144058  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 051 — train_mse(std): 0.144058  val_mse(std): 0.119228  val_ema: 0.144058  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:37:25 | INFO | Epoch 052 — train_mse(std): 0.142197  val_mse(std): 0.118797  val_ema: 0.142197  last l2: 0.000644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 052 — train_mse(std): 0.142197  val_mse(std): 0.118797  val_ema: 0.142197  last l2: 0.000644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:37:25 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:38:15 | INFO | Epoch 053 — train_mse(std): 0.142041  val_mse(std): 0.118939  val_ema: 0.142041  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 053 — train_mse(std): 0.142041  val_mse(std): 0.118939  val_ema: 0.142041  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:38:15 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:39:05 | INFO | Epoch 054 — train_mse(std): 0.142668  val_mse(std): 0.122709  val_ema: 0.142668  last l2: 0.001189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 054 — train_mse(std): 0.142668  val_mse(std): 0.122709  val_ema: 0.142668  last l2: 0.001189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:39:54 | INFO | Epoch 055 — train_mse(std): 0.142625  val_mse(std): 0.118877  val_ema: 0.142625  last l2: 0.001010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 055 — train_mse(std): 0.142625  val_mse(std): 0.118877  val_ema: 0.142625  last l2: 0.001010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:40:43 | INFO | Epoch 056 — train_mse(std): 0.141836  val_mse(std): 0.119269  val_ema: 0.141836  last l2: 0.001061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 056 — train_mse(std): 0.141836  val_mse(std): 0.119269  val_ema: 0.141836  last l2: 0.001061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:40:43 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:41:31 | INFO | Epoch 057 — train_mse(std): 0.141793  val_mse(std): 0.120463  val_ema: 0.141793  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 057 — train_mse(std): 0.141793  val_mse(std): 0.120463  val_ema: 0.141793  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:42:20 | INFO | Epoch 058 — train_mse(std): 0.142440  val_mse(std): 0.118697  val_ema: 0.142440  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 058 — train_mse(std): 0.142440  val_mse(std): 0.118697  val_ema: 0.142440  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:08 | INFO | Epoch 059 — train_mse(std): 0.141606  val_mse(std): 0.118625  val_ema: 0.141606  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 059 — train_mse(std): 0.141606  val_mse(std): 0.118625  val_ema: 0.141606  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:08 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:58 | INFO | Epoch 060 — train_mse(std): 0.141523  val_mse(std): 0.118701  val_ema: 0.141523  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 060 — train_mse(std): 0.141523  val_mse(std): 0.118701  val_ema: 0.141523  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:44:48 | INFO | Epoch 061 — train_mse(std): 0.142802  val_mse(std): 0.119269  val_ema: 0.142802  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 061 — train_mse(std): 0.142802  val_mse(std): 0.119269  val_ema: 0.142802  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:45:37 | INFO | Epoch 062 — train_mse(std): 0.141424  val_mse(std): 0.118808  val_ema: 0.141424  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 062 — train_mse(std): 0.141424  val_mse(std): 0.118808  val_ema: 0.141424  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:45:37 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:46:26 | INFO | Epoch 063 — train_mse(std): 0.141317  val_mse(std): 0.118593  val_ema: 0.141317  last l2: 0.001043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 063 — train_mse(std): 0.141317  val_mse(std): 0.118593  val_ema: 0.141317  last l2: 0.001043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:46:26 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:47:16 | INFO | Epoch 064 — train_mse(std): 0.142075  val_mse(std): 0.118469  val_ema: 0.142075  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 064 — train_mse(std): 0.142075  val_mse(std): 0.118469  val_ema: 0.142075  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:05 | INFO | Epoch 065 — train_mse(std): 0.141190  val_mse(std): 0.118838  val_ema: 0.141190  last l2: 0.001360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 065 — train_mse(std): 0.141190  val_mse(std): 0.118838  val_ema: 0.141190  last l2: 0.001360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:05 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:55 | INFO | Epoch 066 — train_mse(std): 0.141148  val_mse(std): 0.118634  val_ema: 0.141148  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 066 — train_mse(std): 0.141148  val_mse(std): 0.118634  val_ema: 0.141148  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:49:44 | INFO | Epoch 067 — train_mse(std): 0.141630  val_mse(std): 0.118601  val_ema: 0.141630  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 067 — train_mse(std): 0.141630  val_mse(std): 0.118601  val_ema: 0.141630  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:50:34 | INFO | Epoch 068 — train_mse(std): 0.142085  val_mse(std): 0.118897  val_ema: 0.142085  last l2: 0.000479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 068 — train_mse(std): 0.142085  val_mse(std): 0.118897  val_ema: 0.142085  last l2: 0.000479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:51:24 | INFO | Epoch 069 — train_mse(std): 0.140955  val_mse(std): 0.118513  val_ema: 0.140955  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 069 — train_mse(std): 0.140955  val_mse(std): 0.118513  val_ema: 0.140955  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:51:24 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:52:12 | INFO | Epoch 070 — train_mse(std): 0.141749  val_mse(std): 0.120252  val_ema: 0.141749  last l2: 0.000799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 070 — train_mse(std): 0.141749  val_mse(std): 0.120252  val_ema: 0.141749  last l2: 0.000799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:53:01 | INFO | Epoch 071 — train_mse(std): 0.141340  val_mse(std): 0.118620  val_ema: 0.141340  last l2: 0.000564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 071 — train_mse(std): 0.141340  val_mse(std): 0.118620  val_ema: 0.141340  last l2: 0.000564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:53:49 | INFO | Epoch 072 — train_mse(std): 0.140894  val_mse(std): 0.118880  val_ema: 0.140894  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 072 — train_mse(std): 0.140894  val_mse(std): 0.118880  val_ema: 0.140894  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:54:37 | INFO | Epoch 073 — train_mse(std): 0.140832  val_mse(std): 0.118653  val_ema: 0.140832  last l2: 0.000713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 073 — train_mse(std): 0.140832  val_mse(std): 0.118653  val_ema: 0.140832  last l2: 0.000713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:54:37 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:55:25 | INFO | Epoch 074 — train_mse(std): 0.140831  val_mse(std): 0.118943  val_ema: 0.140831  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 074 — train_mse(std): 0.140831  val_mse(std): 0.118943  val_ema: 0.140831  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:56:13 | INFO | Epoch 075 — train_mse(std): 0.141569  val_mse(std): 0.118393  val_ema: 0.141569  last l2: 0.000934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 075 — train_mse(std): 0.141569  val_mse(std): 0.118393  val_ema: 0.141569  last l2: 0.000934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:02 | INFO | Epoch 076 — train_mse(std): 0.141859  val_mse(std): 0.118570  val_ema: 0.141859  last l2: 0.000660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 076 — train_mse(std): 0.141859  val_mse(std): 0.118570  val_ema: 0.141859  last l2: 0.000660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:49 | INFO | Epoch 077 — train_mse(std): 0.140596  val_mse(std): 0.118748  val_ema: 0.140596  last l2: 0.000808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 077 — train_mse(std): 0.140596  val_mse(std): 0.118748  val_ema: 0.140596  last l2: 0.000808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:49 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:58:37 | INFO | Epoch 078 — train_mse(std): 0.140850  val_mse(std): 0.119147  val_ema: 0.140850  last l2: 0.000617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 078 — train_mse(std): 0.140850  val_mse(std): 0.119147  val_ema: 0.140850  last l2: 0.000617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:59:25 | INFO | Epoch 079 — train_mse(std): 0.140776  val_mse(std): 0.118857  val_ema: 0.140776  last l2: 0.000817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 079 — train_mse(std): 0.140776  val_mse(std): 0.118857  val_ema: 0.140776  last l2: 0.000817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:00:13 | INFO | Epoch 080 — train_mse(std): 0.140785  val_mse(std): 0.118799  val_ema: 0.140785  last l2: 0.000596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 080 — train_mse(std): 0.140785  val_mse(std): 0.118799  val_ema: 0.140785  last l2: 0.000596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:01 | INFO | Epoch 081 — train_mse(std): 0.140685  val_mse(std): 0.119386  val_ema: 0.140685  last l2: 0.000869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 081 — train_mse(std): 0.140685  val_mse(std): 0.119386  val_ema: 0.140685  last l2: 0.000869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:49 | INFO | Epoch 082 — train_mse(std): 0.140488  val_mse(std): 0.118929  val_ema: 0.140488  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 082 — train_mse(std): 0.140488  val_mse(std): 0.118929  val_ema: 0.140488  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:49 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:02:37 | INFO | Epoch 083 — train_mse(std): 0.140356  val_mse(std): 0.118639  val_ema: 0.140356  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 083 — train_mse(std): 0.140356  val_mse(std): 0.118639  val_ema: 0.140356  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:02:37 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:03:25 | INFO | Epoch 084 — train_mse(std): 0.141092  val_mse(std): 0.118931  val_ema: 0.141092  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 084 — train_mse(std): 0.141092  val_mse(std): 0.118931  val_ema: 0.141092  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:04:14 | INFO | Epoch 085 — train_mse(std): 0.140290  val_mse(std): 0.118749  val_ema: 0.140290  last l2: 0.000560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 085 — train_mse(std): 0.140290  val_mse(std): 0.118749  val_ema: 0.140290  last l2: 0.000560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:05:02 | INFO | Epoch 086 — train_mse(std): 0.140464  val_mse(std): 0.118968  val_ema: 0.140464  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 086 — train_mse(std): 0.140464  val_mse(std): 0.118968  val_ema: 0.140464  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:05:51 | INFO | Epoch 087 — train_mse(std): 0.141237  val_mse(std): 0.119306  val_ema: 0.141237  last l2: 0.000880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 087 — train_mse(std): 0.141237  val_mse(std): 0.119306  val_ema: 0.141237  last l2: 0.000880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:06:40 | INFO | Epoch 088 — train_mse(std): 0.140284  val_mse(std): 0.118867  val_ema: 0.140284  last l2: 0.000975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 088 — train_mse(std): 0.140284  val_mse(std): 0.118867  val_ema: 0.140284  last l2: 0.000975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:07:30 | INFO | Epoch 089 — train_mse(std): 0.140511  val_mse(std): 0.119445  val_ema: 0.140511  last l2: 0.000750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 089 — train_mse(std): 0.140511  val_mse(std): 0.119445  val_ema: 0.140511  last l2: 0.000750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:08:19 | INFO | Epoch 090 — train_mse(std): 0.140187  val_mse(std): 0.119114  val_ema: 0.140187  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 090 — train_mse(std): 0.140187  val_mse(std): 0.119114  val_ema: 0.140187  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:08:19 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:09:09 | INFO | Epoch 091 — train_mse(std): 0.140484  val_mse(std): 0.120274  val_ema: 0.140484  last l2: 0.001185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 091 — train_mse(std): 0.140484  val_mse(std): 0.120274  val_ema: 0.140484  last l2: 0.001185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:09:59 | INFO | Epoch 092 — train_mse(std): 0.140220  val_mse(std): 0.118732  val_ema: 0.140220  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 092 — train_mse(std): 0.140220  val_mse(std): 0.118732  val_ema: 0.140220  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:10:47 | INFO | Epoch 093 — train_mse(std): 0.140071  val_mse(std): 0.118931  val_ema: 0.140071  last l2: 0.000690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 093 — train_mse(std): 0.140071  val_mse(std): 0.118931  val_ema: 0.140071  last l2: 0.000690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:10:47 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:11:35 | INFO | Epoch 094 — train_mse(std): 0.140164  val_mse(std): 0.119307  val_ema: 0.140164  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 094 — train_mse(std): 0.140164  val_mse(std): 0.119307  val_ema: 0.140164  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:12:24 | INFO | Epoch 095 — train_mse(std): 0.139907  val_mse(std): 0.119035  val_ema: 0.139907  last l2: 0.000582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 095 — train_mse(std): 0.139907  val_mse(std): 0.119035  val_ema: 0.139907  last l2: 0.000582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:12:24 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:13:13 | INFO | Epoch 096 — train_mse(std): 0.139957  val_mse(std): 0.119088  val_ema: 0.139957  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 096 — train_mse(std): 0.139957  val_mse(std): 0.119088  val_ema: 0.139957  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:02 | INFO | Epoch 097 — train_mse(std): 0.139975  val_mse(std): 0.119151  val_ema: 0.139975  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 097 — train_mse(std): 0.139975  val_mse(std): 0.119151  val_ema: 0.139975  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:51 | INFO | Epoch 098 — train_mse(std): 0.139773  val_mse(std): 0.119013  val_ema: 0.139773  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 098 — train_mse(std): 0.139773  val_mse(std): 0.119013  val_ema: 0.139773  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:51 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:15:40 | INFO | Epoch 099 — train_mse(std): 0.139881  val_mse(std): 0.119633  val_ema: 0.139881  last l2: 0.000977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 099 — train_mse(std): 0.139881  val_mse(std): 0.119633  val_ema: 0.139881  last l2: 0.000977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:16:28 | INFO | Epoch 100 — train_mse(std): 0.139653  val_mse(std): 0.119164  val_ema: 0.139653  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 100 — train_mse(std): 0.139653  val_mse(std): 0.119164  val_ema: 0.139653  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:16:28 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:17:17 | INFO | Epoch 101 — train_mse(std): 0.140206  val_mse(std): 0.118987  val_ema: 0.140206  last l2: 0.000621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 101 — train_mse(std): 0.140206  val_mse(std): 0.118987  val_ema: 0.140206  last l2: 0.000621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:05 | INFO | Epoch 102 — train_mse(std): 0.139545  val_mse(std): 0.119602  val_ema: 0.139545  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 102 — train_mse(std): 0.139545  val_mse(std): 0.119602  val_ema: 0.139545  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:05 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:53 | INFO | Epoch 103 — train_mse(std): 0.139564  val_mse(std): 0.119144  val_ema: 0.139564  last l2: 0.000589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 103 — train_mse(std): 0.139564  val_mse(std): 0.119144  val_ema: 0.139564  last l2: 0.000589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:19:41 | INFO | Epoch 104 — train_mse(std): 0.140558  val_mse(std): 0.119921  val_ema: 0.140558  last l2: 0.000555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 104 — train_mse(std): 0.140558  val_mse(std): 0.119921  val_ema: 0.140558  last l2: 0.000555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:20:31 | INFO | Epoch 105 — train_mse(std): 0.140321  val_mse(std): 0.119385  val_ema: 0.140321  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 105 — train_mse(std): 0.140321  val_mse(std): 0.119385  val_ema: 0.140321  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:21:20 | INFO | Epoch 106 — train_mse(std): 0.139471  val_mse(std): 0.119729  val_ema: 0.139471  last l2: 0.001036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 106 — train_mse(std): 0.139471  val_mse(std): 0.119729  val_ema: 0.139471  last l2: 0.001036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:09 | INFO | Epoch 107 — train_mse(std): 0.139419  val_mse(std): 0.119356  val_ema: 0.139419  last l2: 0.000536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 107 — train_mse(std): 0.139419  val_mse(std): 0.119356  val_ema: 0.139419  last l2: 0.000536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:09 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:58 | INFO | Epoch 108 — train_mse(std): 0.139426  val_mse(std): 0.121143  val_ema: 0.139426  last l2: 0.001171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 108 — train_mse(std): 0.139426  val_mse(std): 0.121143  val_ema: 0.139426  last l2: 0.001171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:23:48 | INFO | Epoch 109 — train_mse(std): 0.139678  val_mse(std): 0.119115  val_ema: 0.139678  last l2: 0.000971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 109 — train_mse(std): 0.139678  val_mse(std): 0.119115  val_ema: 0.139678  last l2: 0.000971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:24:36 | INFO | Epoch 110 — train_mse(std): 0.139411  val_mse(std): 0.119651  val_ema: 0.139411  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 110 — train_mse(std): 0.139411  val_mse(std): 0.119651  val_ema: 0.139411  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:25:25 | INFO | Epoch 111 — train_mse(std): 0.140045  val_mse(std): 0.120271  val_ema: 0.140045  last l2: 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 111 — train_mse(std): 0.140045  val_mse(std): 0.120271  val_ema: 0.140045  last l2: 0.000772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:26:14 | INFO | Epoch 112 — train_mse(std): 0.139504  val_mse(std): 0.120671  val_ema: 0.139504  last l2: 0.000595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 112 — train_mse(std): 0.139504  val_mse(std): 0.120671  val_ema: 0.139504  last l2: 0.000595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:02 | INFO | Epoch 113 — train_mse(std): 0.140152  val_mse(std): 0.119239  val_ema: 0.140152  last l2: 0.000691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 113 — train_mse(std): 0.140152  val_mse(std): 0.119239  val_ema: 0.140152  last l2: 0.000691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:51 | INFO | Epoch 114 — train_mse(std): 0.139264  val_mse(std): 0.119132  val_ema: 0.139264  last l2: 0.000525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 114 — train_mse(std): 0.139264  val_mse(std): 0.119132  val_ema: 0.139264  last l2: 0.000525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:51 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:28:40 | INFO | Epoch 115 — train_mse(std): 0.139879  val_mse(std): 0.119567  val_ema: 0.139879  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 115 — train_mse(std): 0.139879  val_mse(std): 0.119567  val_ema: 0.139879  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:29:29 | INFO | Epoch 116 — train_mse(std): 0.139375  val_mse(std): 0.118979  val_ema: 0.139375  last l2: 0.000571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 116 — train_mse(std): 0.139375  val_mse(std): 0.118979  val_ema: 0.139375  last l2: 0.000571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:30:17 | INFO | Epoch 117 — train_mse(std): 0.139391  val_mse(std): 0.119209  val_ema: 0.139391  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 117 — train_mse(std): 0.139391  val_mse(std): 0.119209  val_ema: 0.139391  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:31:06 | INFO | Epoch 118 — train_mse(std): 0.139677  val_mse(std): 0.119714  val_ema: 0.139677  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 118 — train_mse(std): 0.139677  val_mse(std): 0.119714  val_ema: 0.139677  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:31:54 | INFO | Epoch 119 — train_mse(std): 0.139249  val_mse(std): 0.119220  val_ema: 0.139249  last l2: 0.000635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 119 — train_mse(std): 0.139249  val_mse(std): 0.119220  val_ema: 0.139249  last l2: 0.000635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:32:43 | INFO | Epoch 120 — train_mse(std): 0.139553  val_mse(std): 0.121011  val_ema: 0.139553  last l2: 0.000729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 120 — train_mse(std): 0.139553  val_mse(std): 0.121011  val_ema: 0.139553  last l2: 0.000729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:33:32 | INFO | Epoch 121 — train_mse(std): 0.139383  val_mse(std): 0.119094  val_ema: 0.139383  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 121 — train_mse(std): 0.139383  val_mse(std): 0.119094  val_ema: 0.139383  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:34:20 | INFO | Epoch 122 — train_mse(std): 0.139544  val_mse(std): 0.120566  val_ema: 0.139544  last l2: 0.000874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 122 — train_mse(std): 0.139544  val_mse(std): 0.120566  val_ema: 0.139544  last l2: 0.000874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:35:09 | INFO | Epoch 123 — train_mse(std): 0.139437  val_mse(std): 0.120219  val_ema: 0.139437  last l2: 0.000979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 123 — train_mse(std): 0.139437  val_mse(std): 0.120219  val_ema: 0.139437  last l2: 0.000979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:35:58 | INFO | Epoch 124 — train_mse(std): 0.139292  val_mse(std): 0.119557  val_ema: 0.139292  last l2: 0.000905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 124 — train_mse(std): 0.139292  val_mse(std): 0.119557  val_ema: 0.139292  last l2: 0.000905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:36:47 | INFO | Epoch 125 — train_mse(std): 0.139275  val_mse(std): 0.119805  val_ema: 0.139275  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 125 — train_mse(std): 0.139275  val_mse(std): 0.119805  val_ema: 0.139275  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:37:36 | INFO | Epoch 126 — train_mse(std): 0.139582  val_mse(std): 0.120172  val_ema: 0.139582  last l2: 0.000761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 126 — train_mse(std): 0.139582  val_mse(std): 0.120172  val_ema: 0.139582  last l2: 0.000761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:38:25 | INFO | Epoch 127 — train_mse(std): 0.139401  val_mse(std): 0.120163  val_ema: 0.139401  last l2: 0.000956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 127 — train_mse(std): 0.139401  val_mse(std): 0.120163  val_ema: 0.139401  last l2: 0.000956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:39:14 | INFO | Epoch 128 — train_mse(std): 0.139426  val_mse(std): 0.119285  val_ema: 0.139426  last l2: 0.000620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 128 — train_mse(std): 0.139426  val_mse(std): 0.119285  val_ema: 0.139426  last l2: 0.000620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:03 | INFO | Epoch 129 — train_mse(std): 0.139028  val_mse(std): 0.119481  val_ema: 0.139028  last l2: 0.000626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 129 — train_mse(std): 0.139028  val_mse(std): 0.119481  val_ema: 0.139028  last l2: 0.000626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:03 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:53 | INFO | Epoch 130 — train_mse(std): 0.139136  val_mse(std): 0.119774  val_ema: 0.139136  last l2: 0.000686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 130 — train_mse(std): 0.139136  val_mse(std): 0.119774  val_ema: 0.139136  last l2: 0.000686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:41:41 | INFO | Epoch 131 — train_mse(std): 0.139548  val_mse(std): 0.119418  val_ema: 0.139548  last l2: 0.000503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 131 — train_mse(std): 0.139548  val_mse(std): 0.119418  val_ema: 0.139548  last l2: 0.000503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:42:31 | INFO | Epoch 132 — train_mse(std): 0.139149  val_mse(std): 0.119545  val_ema: 0.139149  last l2: 0.001082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 132 — train_mse(std): 0.139149  val_mse(std): 0.119545  val_ema: 0.139149  last l2: 0.001082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:43:20 | INFO | Epoch 133 — train_mse(std): 0.139097  val_mse(std): 0.119828  val_ema: 0.139097  last l2: 0.001150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 133 — train_mse(std): 0.139097  val_mse(std): 0.119828  val_ema: 0.139097  last l2: 0.001150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:44:09 | INFO | Epoch 134 — train_mse(std): 0.139489  val_mse(std): 0.119413  val_ema: 0.139489  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 134 — train_mse(std): 0.139489  val_mse(std): 0.119413  val_ema: 0.139489  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:44:57 | INFO | Epoch 135 — train_mse(std): 0.139340  val_mse(std): 0.119443  val_ema: 0.139340  last l2: 0.000858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 135 — train_mse(std): 0.139340  val_mse(std): 0.119443  val_ema: 0.139340  last l2: 0.000858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:45:46 | INFO | Epoch 136 — train_mse(std): 0.138900  val_mse(std): 0.119632  val_ema: 0.138900  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 136 — train_mse(std): 0.138900  val_mse(std): 0.119632  val_ema: 0.138900  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:45:47 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:46:35 | INFO | Epoch 137 — train_mse(std): 0.138968  val_mse(std): 0.119322  val_ema: 0.138968  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 137 — train_mse(std): 0.138968  val_mse(std): 0.119322  val_ema: 0.138968  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:47:23 | INFO | Epoch 138 — train_mse(std): 0.139339  val_mse(std): 0.121323  val_ema: 0.139339  last l2: 0.000717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 138 — train_mse(std): 0.139339  val_mse(std): 0.121323  val_ema: 0.139339  last l2: 0.000717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:48:11 | INFO | Epoch 139 — train_mse(std): 0.139113  val_mse(std): 0.119289  val_ema: 0.139113  last l2: 0.000444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 139 — train_mse(std): 0.139113  val_mse(std): 0.119289  val_ema: 0.139113  last l2: 0.000444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:49:01 | INFO | Epoch 140 — train_mse(std): 0.139049  val_mse(std): 0.119654  val_ema: 0.139049  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 140 — train_mse(std): 0.139049  val_mse(std): 0.119654  val_ema: 0.139049  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:49:50 | INFO | Epoch 141 — train_mse(std): 0.138955  val_mse(std): 0.119233  val_ema: 0.138955  last l2: 0.000827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 141 — train_mse(std): 0.138955  val_mse(std): 0.119233  val_ema: 0.138955  last l2: 0.000827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:50:38 | INFO | Epoch 142 — train_mse(std): 0.139072  val_mse(std): 0.119506  val_ema: 0.139072  last l2: 0.000657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 142 — train_mse(std): 0.139072  val_mse(std): 0.119506  val_ema: 0.139072  last l2: 0.000657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:51:27 | INFO | Epoch 143 — train_mse(std): 0.138957  val_mse(std): 0.119169  val_ema: 0.138957  last l2: 0.000496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 143 — train_mse(std): 0.138957  val_mse(std): 0.119169  val_ema: 0.138957  last l2: 0.000496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:52:16 | INFO | Epoch 144 — train_mse(std): 0.139119  val_mse(std): 0.119390  val_ema: 0.139119  last l2: 0.000942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 144 — train_mse(std): 0.139119  val_mse(std): 0.119390  val_ema: 0.139119  last l2: 0.000942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:53:05 | INFO | Epoch 145 — train_mse(std): 0.139307  val_mse(std): 0.119261  val_ema: 0.139307  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 145 — train_mse(std): 0.139307  val_mse(std): 0.119261  val_ema: 0.139307  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:53:54 | INFO | Epoch 146 — train_mse(std): 0.139591  val_mse(std): 0.118808  val_ema: 0.139591  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 146 — train_mse(std): 0.139591  val_mse(std): 0.118808  val_ema: 0.139591  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:54:43 | INFO | Epoch 147 — train_mse(std): 0.138875  val_mse(std): 0.118912  val_ema: 0.138875  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 147 — train_mse(std): 0.138875  val_mse(std): 0.118912  val_ema: 0.138875  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:55:33 | INFO | Epoch 148 — train_mse(std): 0.138912  val_mse(std): 0.119083  val_ema: 0.138912  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 148 — train_mse(std): 0.138912  val_mse(std): 0.119083  val_ema: 0.138912  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:56:22 | INFO | Epoch 149 — train_mse(std): 0.138888  val_mse(std): 0.118839  val_ema: 0.138888  last l2: 0.000609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 149 — train_mse(std): 0.138888  val_mse(std): 0.118839  val_ema: 0.138888  last l2: 0.000609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:57:12 | INFO | Epoch 150 — train_mse(std): 0.139389  val_mse(std): 0.118809  val_ema: 0.139389  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 150 — train_mse(std): 0.139389  val_mse(std): 0.118809  val_ema: 0.139389  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:00 | INFO | Epoch 151 — train_mse(std): 0.138774  val_mse(std): 0.118816  val_ema: 0.138774  last l2: 0.000633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 151 — train_mse(std): 0.138774  val_mse(std): 0.118816  val_ema: 0.138774  last l2: 0.000633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:00 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:48 | INFO | Epoch 152 — train_mse(std): 0.138798  val_mse(std): 0.118779  val_ema: 0.138798  last l2: 0.000816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 152 — train_mse(std): 0.138798  val_mse(std): 0.118779  val_ema: 0.138798  last l2: 0.000816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:59:37 | INFO | Epoch 153 — train_mse(std): 0.139160  val_mse(std): 0.121257  val_ema: 0.139160  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 153 — train_mse(std): 0.139160  val_mse(std): 0.121257  val_ema: 0.139160  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:00:25 | INFO | Epoch 154 — train_mse(std): 0.139142  val_mse(std): 0.118815  val_ema: 0.139142  last l2: 0.000538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 154 — train_mse(std): 0.139142  val_mse(std): 0.118815  val_ema: 0.139142  last l2: 0.000538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:01:14 | INFO | Epoch 155 — train_mse(std): 0.138711  val_mse(std): 0.118909  val_ema: 0.138711  last l2: 0.000951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 155 — train_mse(std): 0.138711  val_mse(std): 0.118909  val_ema: 0.138711  last l2: 0.000951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:02:02 | INFO | Epoch 156 — train_mse(std): 0.138714  val_mse(std): 0.118941  val_ema: 0.138714  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 156 — train_mse(std): 0.138714  val_mse(std): 0.118941  val_ema: 0.138714  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:02:51 | INFO | Epoch 157 — train_mse(std): 0.138879  val_mse(std): 0.119378  val_ema: 0.138879  last l2: 0.000860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 157 — train_mse(std): 0.138879  val_mse(std): 0.119378  val_ema: 0.138879  last l2: 0.000860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:03:40 | INFO | Epoch 158 — train_mse(std): 0.138839  val_mse(std): 0.118874  val_ema: 0.138839  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 158 — train_mse(std): 0.138839  val_mse(std): 0.118874  val_ema: 0.138839  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:04:29 | INFO | Epoch 159 — train_mse(std): 0.138782  val_mse(std): 0.120255  val_ema: 0.138782  last l2: 0.000950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 159 — train_mse(std): 0.138782  val_mse(std): 0.120255  val_ema: 0.138782  last l2: 0.000950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:05:17 | INFO | Epoch 160 — train_mse(std): 0.139146  val_mse(std): 0.118762  val_ema: 0.139146  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 160 — train_mse(std): 0.139146  val_mse(std): 0.118762  val_ema: 0.139146  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:05 | INFO | Epoch 161 — train_mse(std): 0.138610  val_mse(std): 0.118674  val_ema: 0.138610  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 161 — train_mse(std): 0.138610  val_mse(std): 0.118674  val_ema: 0.138610  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:05 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:53 | INFO | Epoch 162 — train_mse(std): 0.138730  val_mse(std): 0.118633  val_ema: 0.138730  last l2: 0.000779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 162 — train_mse(std): 0.138730  val_mse(std): 0.118633  val_ema: 0.138730  last l2: 0.000779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:07:41 | INFO | Epoch 163 — train_mse(std): 0.138625  val_mse(std): 0.118914  val_ema: 0.138625  last l2: 0.001065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 163 — train_mse(std): 0.138625  val_mse(std): 0.118914  val_ema: 0.138625  last l2: 0.001065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:08:29 | INFO | Epoch 164 — train_mse(std): 0.138699  val_mse(std): 0.118695  val_ema: 0.138699  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 164 — train_mse(std): 0.138699  val_mse(std): 0.118695  val_ema: 0.138699  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:09:17 | INFO | Epoch 165 — train_mse(std): 0.139157  val_mse(std): 0.119164  val_ema: 0.139157  last l2: 0.000694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 165 — train_mse(std): 0.139157  val_mse(std): 0.119164  val_ema: 0.139157  last l2: 0.000694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:10:04 | INFO | Epoch 166 — train_mse(std): 0.138777  val_mse(std): 0.118651  val_ema: 0.138777  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 166 — train_mse(std): 0.138777  val_mse(std): 0.118651  val_ema: 0.138777  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:10:54 | INFO | Epoch 167 — train_mse(std): 0.138569  val_mse(std): 0.118900  val_ema: 0.138569  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 167 — train_mse(std): 0.138569  val_mse(std): 0.118900  val_ema: 0.138569  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:11:42 | INFO | Epoch 168 — train_mse(std): 0.138970  val_mse(std): 0.118961  val_ema: 0.138970  last l2: 0.000561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 168 — train_mse(std): 0.138970  val_mse(std): 0.118961  val_ema: 0.138970  last l2: 0.000561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:12:30 | INFO | Epoch 169 — train_mse(std): 0.138588  val_mse(std): 0.118590  val_ema: 0.138588  last l2: 0.000684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 169 — train_mse(std): 0.138588  val_mse(std): 0.118590  val_ema: 0.138588  last l2: 0.000684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:13:19 | INFO | Epoch 170 — train_mse(std): 0.138563  val_mse(std): 0.119115  val_ema: 0.138563  last l2: 0.000511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 170 — train_mse(std): 0.138563  val_mse(std): 0.119115  val_ema: 0.138563  last l2: 0.000511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:14:08 | INFO | Epoch 171 — train_mse(std): 0.139056  val_mse(std): 0.120301  val_ema: 0.139056  last l2: 0.000947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 171 — train_mse(std): 0.139056  val_mse(std): 0.120301  val_ema: 0.139056  last l2: 0.000947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:14:57 | INFO | Epoch 172 — train_mse(std): 0.138802  val_mse(std): 0.118797  val_ema: 0.138802  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 172 — train_mse(std): 0.138802  val_mse(std): 0.118797  val_ema: 0.138802  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:15:46 | INFO | Epoch 173 — train_mse(std): 0.138711  val_mse(std): 0.118799  val_ema: 0.138711  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 173 — train_mse(std): 0.138711  val_mse(std): 0.118799  val_ema: 0.138711  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:16:34 | INFO | Epoch 174 — train_mse(std): 0.138488  val_mse(std): 0.118929  val_ema: 0.138488  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 174 — train_mse(std): 0.138488  val_mse(std): 0.118929  val_ema: 0.138488  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:16:34 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:17:22 | INFO | Epoch 175 — train_mse(std): 0.138658  val_mse(std): 0.119109  val_ema: 0.138658  last l2: 0.000757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 175 — train_mse(std): 0.138658  val_mse(std): 0.119109  val_ema: 0.138658  last l2: 0.000757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:18:10 | INFO | Epoch 176 — train_mse(std): 0.138969  val_mse(std): 0.119113  val_ema: 0.138969  last l2: 0.000565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 176 — train_mse(std): 0.138969  val_mse(std): 0.119113  val_ema: 0.138969  last l2: 0.000565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:18:59 | INFO | Epoch 177 — train_mse(std): 0.138462  val_mse(std): 0.119006  val_ema: 0.138462  last l2: 0.001059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 177 — train_mse(std): 0.138462  val_mse(std): 0.119006  val_ema: 0.138462  last l2: 0.001059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:19:48 | INFO | Epoch 178 — train_mse(std): 0.138538  val_mse(std): 0.118961  val_ema: 0.138538  last l2: 0.000778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 178 — train_mse(std): 0.138538  val_mse(std): 0.118961  val_ema: 0.138538  last l2: 0.000778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:20:37 | INFO | Epoch 179 — train_mse(std): 0.139650  val_mse(std): 0.118900  val_ema: 0.139650  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 179 — train_mse(std): 0.139650  val_mse(std): 0.118900  val_ema: 0.139650  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:21:26 | INFO | Epoch 180 — train_mse(std): 0.138450  val_mse(std): 0.118704  val_ema: 0.138450  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 180 — train_mse(std): 0.138450  val_mse(std): 0.118704  val_ema: 0.138450  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:22:15 | INFO | Epoch 181 — train_mse(std): 0.138387  val_mse(std): 0.119307  val_ema: 0.138387  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 181 — train_mse(std): 0.138387  val_mse(std): 0.119307  val_ema: 0.138387  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:22:15 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:23:04 | INFO | Epoch 182 — train_mse(std): 0.138476  val_mse(std): 0.119204  val_ema: 0.138476  last l2: 0.000594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 182 — train_mse(std): 0.138476  val_mse(std): 0.119204  val_ema: 0.138476  last l2: 0.000594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:23:53 | INFO | Epoch 183 — train_mse(std): 0.138623  val_mse(std): 0.118832  val_ema: 0.138623  last l2: 0.000751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 183 — train_mse(std): 0.138623  val_mse(std): 0.118832  val_ema: 0.138623  last l2: 0.000751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:24:42 | INFO | Epoch 184 — train_mse(std): 0.139383  val_mse(std): 0.119713  val_ema: 0.139383  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 184 — train_mse(std): 0.139383  val_mse(std): 0.119713  val_ema: 0.139383  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:25:31 | INFO | Epoch 185 — train_mse(std): 0.138874  val_mse(std): 0.119561  val_ema: 0.138874  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 185 — train_mse(std): 0.138874  val_mse(std): 0.119561  val_ema: 0.138874  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:26:20 | INFO | Epoch 186 — train_mse(std): 0.138489  val_mse(std): 0.119076  val_ema: 0.138489  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 186 — train_mse(std): 0.138489  val_mse(std): 0.119076  val_ema: 0.138489  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:27:10 | INFO | Epoch 187 — train_mse(std): 0.138512  val_mse(std): 0.119713  val_ema: 0.138512  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 187 — train_mse(std): 0.138512  val_mse(std): 0.119713  val_ema: 0.138512  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:27:59 | INFO | Epoch 188 — train_mse(std): 0.138606  val_mse(std): 0.118944  val_ema: 0.138606  last l2: 0.000550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 188 — train_mse(std): 0.138606  val_mse(std): 0.118944  val_ema: 0.138606  last l2: 0.000550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:28:47 | INFO | Epoch 189 — train_mse(std): 0.138940  val_mse(std): 0.118880  val_ema: 0.138940  last l2: 0.001011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 189 — train_mse(std): 0.138940  val_mse(std): 0.118880  val_ema: 0.138940  last l2: 0.001011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:29:36 | INFO | Epoch 190 — train_mse(std): 0.138397  val_mse(std): 0.119753  val_ema: 0.138397  last l2: 0.000735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 190 — train_mse(std): 0.138397  val_mse(std): 0.119753  val_ema: 0.138397  last l2: 0.000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:30:24 | INFO | Epoch 191 — train_mse(std): 0.138348  val_mse(std): 0.119565  val_ema: 0.138348  last l2: 0.000762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 191 — train_mse(std): 0.138348  val_mse(std): 0.119565  val_ema: 0.138348  last l2: 0.000762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:31:13 | INFO | Epoch 192 — train_mse(std): 0.138612  val_mse(std): 0.119810  val_ema: 0.138612  last l2: 0.000578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 192 — train_mse(std): 0.138612  val_mse(std): 0.119810  val_ema: 0.138612  last l2: 0.000578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:32:02 | INFO | Epoch 193 — train_mse(std): 0.138337  val_mse(std): 0.119583  val_ema: 0.138337  last l2: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 193 — train_mse(std): 0.138337  val_mse(std): 0.119583  val_ema: 0.138337  last l2: 0.000832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:32:50 | INFO | Epoch 194 — train_mse(std): 0.138347  val_mse(std): 0.119774  val_ema: 0.138347  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 194 — train_mse(std): 0.138347  val_mse(std): 0.119774  val_ema: 0.138347  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:33:38 | INFO | Epoch 195 — train_mse(std): 0.138900  val_mse(std): 0.119295  val_ema: 0.138900  last l2: 0.000698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 195 — train_mse(std): 0.138900  val_mse(std): 0.119295  val_ema: 0.138900  last l2: 0.000698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:34:28 | INFO | Epoch 196 — train_mse(std): 0.138363  val_mse(std): 0.119582  val_ema: 0.138363  last l2: 0.000848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 196 — train_mse(std): 0.138363  val_mse(std): 0.119582  val_ema: 0.138363  last l2: 0.000848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:35:17 | INFO | Epoch 197 — train_mse(std): 0.138698  val_mse(std): 0.120201  val_ema: 0.138698  last l2: 0.000527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 197 — train_mse(std): 0.138698  val_mse(std): 0.120201  val_ema: 0.138698  last l2: 0.000527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:36:07 | INFO | Epoch 198 — train_mse(std): 0.138391  val_mse(std): 0.120141  val_ema: 0.138391  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 198 — train_mse(std): 0.138391  val_mse(std): 0.120141  val_ema: 0.138391  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:36:56 | INFO | Epoch 199 — train_mse(std): 0.138305  val_mse(std): 0.119546  val_ema: 0.138305  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 199 — train_mse(std): 0.138305  val_mse(std): 0.119546  val_ema: 0.138305  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:37:45 | INFO | Epoch 200 — train_mse(std): 0.138412  val_mse(std): 0.120111  val_ema: 0.138412  last l2: 0.001037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 200 — train_mse(std): 0.138412  val_mse(std): 0.120111  val_ema: 0.138412  last l2: 0.001037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:38:35 | INFO | Epoch 201 — train_mse(std): 0.138505  val_mse(std): 0.119832  val_ema: 0.138505  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 201 — train_mse(std): 0.138505  val_mse(std): 0.119832  val_ema: 0.138505  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:39:24 | INFO | Epoch 202 — train_mse(std): 0.138372  val_mse(std): 0.119658  val_ema: 0.138372  last l2: 0.000588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 202 — train_mse(std): 0.138372  val_mse(std): 0.119658  val_ema: 0.138372  last l2: 0.000588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:40:12 | INFO | Epoch 203 — train_mse(std): 0.138522  val_mse(std): 0.120157  val_ema: 0.138522  last l2: 0.000745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 203 — train_mse(std): 0.138522  val_mse(std): 0.120157  val_ema: 0.138522  last l2: 0.000745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:00 | INFO | Epoch 204 — train_mse(std): 0.138993  val_mse(std): 0.119856  val_ema: 0.138993  last l2: 0.000669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 204 — train_mse(std): 0.138993  val_mse(std): 0.119856  val_ema: 0.138993  last l2: 0.000669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:47 | INFO | Epoch 205 — train_mse(std): 0.138255  val_mse(std): 0.120004  val_ema: 0.138255  last l2: 0.000507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 205 — train_mse(std): 0.138255  val_mse(std): 0.120004  val_ema: 0.138255  last l2: 0.000507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:47 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:42:35 | INFO | Epoch 206 — train_mse(std): 0.138342  val_mse(std): 0.119247  val_ema: 0.138342  last l2: 0.000546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 206 — train_mse(std): 0.138342  val_mse(std): 0.119247  val_ema: 0.138342  last l2: 0.000546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:43:23 | INFO | Epoch 207 — train_mse(std): 0.138467  val_mse(std): 0.119620  val_ema: 0.138467  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 207 — train_mse(std): 0.138467  val_mse(std): 0.119620  val_ema: 0.138467  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:44:10 | INFO | Epoch 208 — train_mse(std): 0.138397  val_mse(std): 0.120117  val_ema: 0.138397  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 208 — train_mse(std): 0.138397  val_mse(std): 0.120117  val_ema: 0.138397  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:44:58 | INFO | Epoch 209 — train_mse(std): 0.138267  val_mse(std): 0.120339  val_ema: 0.138267  last l2: 0.000737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 209 — train_mse(std): 0.138267  val_mse(std): 0.120339  val_ema: 0.138267  last l2: 0.000737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:45:46 | INFO | Epoch 210 — train_mse(std): 0.138342  val_mse(std): 0.121189  val_ema: 0.138342  last l2: 0.000911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 210 — train_mse(std): 0.138342  val_mse(std): 0.121189  val_ema: 0.138342  last l2: 0.000911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:46:33 | INFO | Epoch 211 — train_mse(std): 0.138293  val_mse(std): 0.119818  val_ema: 0.138293  last l2: 0.001329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 211 — train_mse(std): 0.138293  val_mse(std): 0.119818  val_ema: 0.138293  last l2: 0.001329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:47:20 | INFO | Epoch 212 — train_mse(std): 0.138756  val_mse(std): 0.120569  val_ema: 0.138756  last l2: 0.000672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 212 — train_mse(std): 0.138756  val_mse(std): 0.120569  val_ema: 0.138756  last l2: 0.000672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:48:08 | INFO | Epoch 213 — train_mse(std): 0.138300  val_mse(std): 0.120690  val_ema: 0.138300  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 213 — train_mse(std): 0.138300  val_mse(std): 0.120690  val_ema: 0.138300  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:48:55 | INFO | Epoch 214 — train_mse(std): 0.138560  val_mse(std): 0.120750  val_ema: 0.138560  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 214 — train_mse(std): 0.138560  val_mse(std): 0.120750  val_ema: 0.138560  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:49:43 | INFO | Epoch 215 — train_mse(std): 0.138464  val_mse(std): 0.120705  val_ema: 0.138464  last l2: 0.000867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 215 — train_mse(std): 0.138464  val_mse(std): 0.120705  val_ema: 0.138464  last l2: 0.000867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:50:30 | INFO | Epoch 216 — train_mse(std): 0.138170  val_mse(std): 0.119588  val_ema: 0.138170  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 216 — train_mse(std): 0.138170  val_mse(std): 0.119588  val_ema: 0.138170  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:51:18 | INFO | Epoch 217 — train_mse(std): 0.138388  val_mse(std): 0.121753  val_ema: 0.138388  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 217 — train_mse(std): 0.138388  val_mse(std): 0.121753  val_ema: 0.138388  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:52:07 | INFO | Epoch 218 — train_mse(std): 0.138343  val_mse(std): 0.120919  val_ema: 0.138343  last l2: 0.000743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 218 — train_mse(std): 0.138343  val_mse(std): 0.120919  val_ema: 0.138343  last l2: 0.000743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:52:56 | INFO | Epoch 219 — train_mse(std): 0.138344  val_mse(std): 0.120470  val_ema: 0.138344  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 219 — train_mse(std): 0.138344  val_mse(std): 0.120470  val_ema: 0.138344  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:53:44 | INFO | Epoch 220 — train_mse(std): 0.138478  val_mse(std): 0.120818  val_ema: 0.138478  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 220 — train_mse(std): 0.138478  val_mse(std): 0.120818  val_ema: 0.138478  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:54:32 | INFO | Epoch 221 — train_mse(std): 0.138213  val_mse(std): 0.120658  val_ema: 0.138213  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 221 — train_mse(std): 0.138213  val_mse(std): 0.120658  val_ema: 0.138213  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:55:20 | INFO | Epoch 222 — train_mse(std): 0.138118  val_mse(std): 0.120881  val_ema: 0.138118  last l2: 0.000614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 222 — train_mse(std): 0.138118  val_mse(std): 0.120881  val_ema: 0.138118  last l2: 0.000614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:55:20 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:56:08 | INFO | Epoch 223 — train_mse(std): 0.138343  val_mse(std): 0.120808  val_ema: 0.138343  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 223 — train_mse(std): 0.138343  val_mse(std): 0.120808  val_ema: 0.138343  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:56:57 | INFO | Epoch 224 — train_mse(std): 0.138353  val_mse(std): 0.121462  val_ema: 0.138353  last l2: 0.000851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 224 — train_mse(std): 0.138353  val_mse(std): 0.121462  val_ema: 0.138353  last l2: 0.000851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:57:45 | INFO | Epoch 225 — train_mse(std): 0.138490  val_mse(std): 0.120684  val_ema: 0.138490  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 225 — train_mse(std): 0.138490  val_mse(std): 0.120684  val_ema: 0.138490  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:58:33 | INFO | Epoch 226 — train_mse(std): 0.138098  val_mse(std): 0.121131  val_ema: 0.138098  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 226 — train_mse(std): 0.138098  val_mse(std): 0.121131  val_ema: 0.138098  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:59:21 | INFO | Epoch 227 — train_mse(std): 0.138422  val_mse(std): 0.121319  val_ema: 0.138422  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 227 — train_mse(std): 0.138422  val_mse(std): 0.121319  val_ema: 0.138422  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:00:09 | INFO | Epoch 228 — train_mse(std): 0.138316  val_mse(std): 0.120924  val_ema: 0.138316  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 228 — train_mse(std): 0.138316  val_mse(std): 0.120924  val_ema: 0.138316  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:00:57 | INFO | Epoch 229 — train_mse(std): 0.138248  val_mse(std): 0.121040  val_ema: 0.138248  last l2: 0.000892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 229 — train_mse(std): 0.138248  val_mse(std): 0.121040  val_ema: 0.138248  last l2: 0.000892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:01:45 | INFO | Epoch 230 — train_mse(std): 0.138407  val_mse(std): 0.120424  val_ema: 0.138407  last l2: 0.001375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 230 — train_mse(std): 0.138407  val_mse(std): 0.120424  val_ema: 0.138407  last l2: 0.001375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:02:32 | INFO | Epoch 231 — train_mse(std): 0.138078  val_mse(std): 0.120908  val_ema: 0.138078  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 231 — train_mse(std): 0.138078  val_mse(std): 0.120908  val_ema: 0.138078  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:03:20 | INFO | Epoch 232 — train_mse(std): 0.138088  val_mse(std): 0.120554  val_ema: 0.138088  last l2: 0.000473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 232 — train_mse(std): 0.138088  val_mse(std): 0.120554  val_ema: 0.138088  last l2: 0.000473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:04:08 | INFO | Epoch 233 — train_mse(std): 0.138257  val_mse(std): 0.121214  val_ema: 0.138257  last l2: 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 233 — train_mse(std): 0.138257  val_mse(std): 0.121214  val_ema: 0.138257  last l2: 0.000896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:04:58 | INFO | Epoch 234 — train_mse(std): 0.138127  val_mse(std): 0.121052  val_ema: 0.138127  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 234 — train_mse(std): 0.138127  val_mse(std): 0.121052  val_ema: 0.138127  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:05:47 | INFO | Epoch 235 — train_mse(std): 0.138138  val_mse(std): 0.120174  val_ema: 0.138138  last l2: 0.000809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 235 — train_mse(std): 0.138138  val_mse(std): 0.120174  val_ema: 0.138138  last l2: 0.000809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:06:36 | INFO | Epoch 236 — train_mse(std): 0.138128  val_mse(std): 0.121043  val_ema: 0.138128  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 236 — train_mse(std): 0.138128  val_mse(std): 0.121043  val_ema: 0.138128  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:07:24 | INFO | Epoch 237 — train_mse(std): 0.138556  val_mse(std): 0.121389  val_ema: 0.138556  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 237 — train_mse(std): 0.138556  val_mse(std): 0.121389  val_ema: 0.138556  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:08:12 | INFO | Epoch 238 — train_mse(std): 0.138244  val_mse(std): 0.120523  val_ema: 0.138244  last l2: 0.000648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 238 — train_mse(std): 0.138244  val_mse(std): 0.120523  val_ema: 0.138244  last l2: 0.000648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:00 | INFO | Epoch 239 — train_mse(std): 0.138204  val_mse(std): 0.120725  val_ema: 0.138204  last l2: 0.000533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 239 — train_mse(std): 0.138204  val_mse(std): 0.120725  val_ema: 0.138204  last l2: 0.000533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:48 | INFO | Epoch 240 — train_mse(std): 0.137991  val_mse(std): 0.120795  val_ema: 0.137991  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 240 — train_mse(std): 0.137991  val_mse(std): 0.120795  val_ema: 0.137991  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:48 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:10:36 | INFO | Epoch 241 — train_mse(std): 0.138252  val_mse(std): 0.121225  val_ema: 0.138252  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 241 — train_mse(std): 0.138252  val_mse(std): 0.121225  val_ema: 0.138252  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:11:24 | INFO | Epoch 242 — train_mse(std): 0.138118  val_mse(std): 0.120965  val_ema: 0.138118  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 242 — train_mse(std): 0.138118  val_mse(std): 0.120965  val_ema: 0.138118  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:12:13 | INFO | Epoch 243 — train_mse(std): 0.138066  val_mse(std): 0.121674  val_ema: 0.138066  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 243 — train_mse(std): 0.138066  val_mse(std): 0.121674  val_ema: 0.138066  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:13:00 | INFO | Epoch 244 — train_mse(std): 0.138169  val_mse(std): 0.121353  val_ema: 0.138169  last l2: 0.000655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 244 — train_mse(std): 0.138169  val_mse(std): 0.121353  val_ema: 0.138169  last l2: 0.000655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:13:49 | INFO | Epoch 245 — train_mse(std): 0.138424  val_mse(std): 0.122700  val_ema: 0.138424  last l2: 0.000907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 245 — train_mse(std): 0.138424  val_mse(std): 0.122700  val_ema: 0.138424  last l2: 0.000907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:14:37 | INFO | Epoch 246 — train_mse(std): 0.138246  val_mse(std): 0.121545  val_ema: 0.138246  last l2: 0.000488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 246 — train_mse(std): 0.138246  val_mse(std): 0.121545  val_ema: 0.138246  last l2: 0.000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:15:25 | INFO | Epoch 247 — train_mse(std): 0.138222  val_mse(std): 0.121743  val_ema: 0.138222  last l2: 0.000831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 247 — train_mse(std): 0.138222  val_mse(std): 0.121743  val_ema: 0.138222  last l2: 0.000831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:16:14 | INFO | Epoch 248 — train_mse(std): 0.138068  val_mse(std): 0.120805  val_ema: 0.138068  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 248 — train_mse(std): 0.138068  val_mse(std): 0.120805  val_ema: 0.138068  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:17:02 | INFO | Epoch 249 — train_mse(std): 0.138018  val_mse(std): 0.122027  val_ema: 0.138018  last l2: 0.000704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 249 — train_mse(std): 0.138018  val_mse(std): 0.122027  val_ema: 0.138018  last l2: 0.000704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:17:51 | INFO | Epoch 250 — train_mse(std): 0.138047  val_mse(std): 0.120897  val_ema: 0.138047  last l2: 0.000899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 250 — train_mse(std): 0.138047  val_mse(std): 0.120897  val_ema: 0.138047  last l2: 0.000899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:18:39 | INFO | Epoch 251 — train_mse(std): 0.138166  val_mse(std): 0.121249  val_ema: 0.138166  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 251 — train_mse(std): 0.138166  val_mse(std): 0.121249  val_ema: 0.138166  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:19:28 | INFO | Epoch 252 — train_mse(std): 0.138055  val_mse(std): 0.121589  val_ema: 0.138055  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 252 — train_mse(std): 0.138055  val_mse(std): 0.121589  val_ema: 0.138055  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:20:16 | INFO | Epoch 253 — train_mse(std): 0.138272  val_mse(std): 0.122592  val_ema: 0.138272  last l2: 0.000680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 253 — train_mse(std): 0.138272  val_mse(std): 0.122592  val_ema: 0.138272  last l2: 0.000680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:21:04 | INFO | Epoch 254 — train_mse(std): 0.138105  val_mse(std): 0.121085  val_ema: 0.138105  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 254 — train_mse(std): 0.138105  val_mse(std): 0.121085  val_ema: 0.138105  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:21:52 | INFO | Epoch 255 — train_mse(std): 0.138018  val_mse(std): 0.121514  val_ema: 0.138018  last l2: 0.001299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 255 — train_mse(std): 0.138018  val_mse(std): 0.121514  val_ema: 0.138018  last l2: 0.001299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:22:41 | INFO | Epoch 256 — train_mse(std): 0.137966  val_mse(std): 0.121934  val_ema: 0.137966  last l2: 0.000753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 256 — train_mse(std): 0.137966  val_mse(std): 0.121934  val_ema: 0.137966  last l2: 0.000753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:23:31 | INFO | Epoch 257 — train_mse(std): 0.138069  val_mse(std): 0.121955  val_ema: 0.138069  last l2: 0.000813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 257 — train_mse(std): 0.138069  val_mse(std): 0.121955  val_ema: 0.138069  last l2: 0.000813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:24:21 | INFO | Epoch 258 — train_mse(std): 0.138015  val_mse(std): 0.121635  val_ema: 0.138015  last l2: 0.000591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 258 — train_mse(std): 0.138015  val_mse(std): 0.121635  val_ema: 0.138015  last l2: 0.000591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:09 | INFO | Epoch 259 — train_mse(std): 0.138554  val_mse(std): 0.121705  val_ema: 0.138554  last l2: 0.000870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 259 — train_mse(std): 0.138554  val_mse(std): 0.121705  val_ema: 0.138554  last l2: 0.000870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:59 | INFO | Epoch 260 — train_mse(std): 0.137869  val_mse(std): 0.122090  val_ema: 0.137869  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 260 — train_mse(std): 0.137869  val_mse(std): 0.122090  val_ema: 0.137869  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:59 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:26:48 | INFO | Epoch 261 — train_mse(std): 0.137931  val_mse(std): 0.122396  val_ema: 0.137931  last l2: 0.000972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 261 — train_mse(std): 0.137931  val_mse(std): 0.122396  val_ema: 0.137931  last l2: 0.000972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:27:37 | INFO | Epoch 262 — train_mse(std): 0.138004  val_mse(std): 0.121088  val_ema: 0.138004  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 262 — train_mse(std): 0.138004  val_mse(std): 0.121088  val_ema: 0.138004  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:28:26 | INFO | Epoch 263 — train_mse(std): 0.137930  val_mse(std): 0.124228  val_ema: 0.137930  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 263 — train_mse(std): 0.137930  val_mse(std): 0.124228  val_ema: 0.137930  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:29:15 | INFO | Epoch 264 — train_mse(std): 0.138297  val_mse(std): 0.122051  val_ema: 0.138297  last l2: 0.000863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 264 — train_mse(std): 0.138297  val_mse(std): 0.122051  val_ema: 0.138297  last l2: 0.000863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:30:04 | INFO | Epoch 265 — train_mse(std): 0.137868  val_mse(std): 0.122383  val_ema: 0.137868  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 265 — train_mse(std): 0.137868  val_mse(std): 0.122383  val_ema: 0.137868  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:30:53 | INFO | Epoch 266 — train_mse(std): 0.137945  val_mse(std): 0.122297  val_ema: 0.137945  last l2: 0.001044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 266 — train_mse(std): 0.137945  val_mse(std): 0.122297  val_ema: 0.137945  last l2: 0.001044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:31:42 | INFO | Epoch 267 — train_mse(std): 0.137919  val_mse(std): 0.122395  val_ema: 0.137919  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 267 — train_mse(std): 0.137919  val_mse(std): 0.122395  val_ema: 0.137919  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:32:31 | INFO | Epoch 268 — train_mse(std): 0.138147  val_mse(std): 0.121861  val_ema: 0.138147  last l2: 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 268 — train_mse(std): 0.138147  val_mse(std): 0.121861  val_ema: 0.138147  last l2: 0.000937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:33:20 | INFO | Epoch 269 — train_mse(std): 0.137845  val_mse(std): 0.121558  val_ema: 0.137845  last l2: 0.000668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 269 — train_mse(std): 0.137845  val_mse(std): 0.121558  val_ema: 0.137845  last l2: 0.000668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:34:09 | INFO | Epoch 270 — train_mse(std): 0.138494  val_mse(std): 0.121792  val_ema: 0.138494  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 270 — train_mse(std): 0.138494  val_mse(std): 0.121792  val_ema: 0.138494  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:34:58 | INFO | Epoch 271 — train_mse(std): 0.137794  val_mse(std): 0.121319  val_ema: 0.137794  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 271 — train_mse(std): 0.137794  val_mse(std): 0.121319  val_ema: 0.137794  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:35:47 | INFO | Epoch 272 — train_mse(std): 0.137931  val_mse(std): 0.121942  val_ema: 0.137931  last l2: 0.000605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 272 — train_mse(std): 0.137931  val_mse(std): 0.121942  val_ema: 0.137931  last l2: 0.000605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:36:36 | INFO | Epoch 273 — train_mse(std): 0.138032  val_mse(std): 0.122323  val_ema: 0.138032  last l2: 0.000692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 273 — train_mse(std): 0.138032  val_mse(std): 0.122323  val_ema: 0.138032  last l2: 0.000692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:37:25 | INFO | Epoch 274 — train_mse(std): 0.137880  val_mse(std): 0.122288  val_ema: 0.137880  last l2: 0.000786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 274 — train_mse(std): 0.137880  val_mse(std): 0.122288  val_ema: 0.137880  last l2: 0.000786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:38:14 | INFO | Epoch 275 — train_mse(std): 0.137916  val_mse(std): 0.122158  val_ema: 0.137916  last l2: 0.000935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 275 — train_mse(std): 0.137916  val_mse(std): 0.122158  val_ema: 0.137916  last l2: 0.000935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:39:03 | INFO | Epoch 276 — train_mse(std): 0.138292  val_mse(std): 0.122577  val_ema: 0.138292  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 276 — train_mse(std): 0.138292  val_mse(std): 0.122577  val_ema: 0.138292  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:39:52 | INFO | Epoch 277 — train_mse(std): 0.138009  val_mse(std): 0.122673  val_ema: 0.138009  last l2: 0.001026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 277 — train_mse(std): 0.138009  val_mse(std): 0.122673  val_ema: 0.138009  last l2: 0.001026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:40:41 | INFO | Epoch 278 — train_mse(std): 0.137895  val_mse(std): 0.122164  val_ema: 0.137895  last l2: 0.000825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 278 — train_mse(std): 0.137895  val_mse(std): 0.122164  val_ema: 0.137895  last l2: 0.000825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:41:30 | INFO | Epoch 279 — train_mse(std): 0.137938  val_mse(std): 0.123192  val_ema: 0.137938  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 279 — train_mse(std): 0.137938  val_mse(std): 0.123192  val_ema: 0.137938  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:42:19 | INFO | Epoch 280 — train_mse(std): 0.137896  val_mse(std): 0.121636  val_ema: 0.137896  last l2: 0.001258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 280 — train_mse(std): 0.137896  val_mse(std): 0.121636  val_ema: 0.137896  last l2: 0.001258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:43:08 | INFO | Epoch 281 — train_mse(std): 0.138228  val_mse(std): 0.122452  val_ema: 0.138228  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 281 — train_mse(std): 0.138228  val_mse(std): 0.122452  val_ema: 0.138228  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:43:57 | INFO | Epoch 282 — train_mse(std): 0.137788  val_mse(std): 0.122152  val_ema: 0.137788  last l2: 0.000878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 282 — train_mse(std): 0.137788  val_mse(std): 0.122152  val_ema: 0.137788  last l2: 0.000878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:44:45 | INFO | Epoch 283 — train_mse(std): 0.137917  val_mse(std): 0.122772  val_ema: 0.137917  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 283 — train_mse(std): 0.137917  val_mse(std): 0.122772  val_ema: 0.137917  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:45:35 | INFO | Epoch 284 — train_mse(std): 0.138063  val_mse(std): 0.124819  val_ema: 0.138063  last l2: 0.001078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 284 — train_mse(std): 0.138063  val_mse(std): 0.124819  val_ema: 0.138063  last l2: 0.001078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:46:24 | INFO | Epoch 285 — train_mse(std): 0.137998  val_mse(std): 0.122166  val_ema: 0.137998  last l2: 0.000908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 285 — train_mse(std): 0.137998  val_mse(std): 0.122166  val_ema: 0.137998  last l2: 0.000908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:47:13 | INFO | Epoch 286 — train_mse(std): 0.137857  val_mse(std): 0.121530  val_ema: 0.137857  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 286 — train_mse(std): 0.137857  val_mse(std): 0.121530  val_ema: 0.137857  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:03 | INFO | Epoch 287 — train_mse(std): 0.137711  val_mse(std): 0.121819  val_ema: 0.137711  last l2: 0.000720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 287 — train_mse(std): 0.137711  val_mse(std): 0.121819  val_ema: 0.137711  last l2: 0.000720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:03 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:52 | INFO | Epoch 288 — train_mse(std): 0.138199  val_mse(std): 0.121426  val_ema: 0.138199  last l2: 0.000652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 288 — train_mse(std): 0.138199  val_mse(std): 0.121426  val_ema: 0.138199  last l2: 0.000652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:49:41 | INFO | Epoch 289 — train_mse(std): 0.137748  val_mse(std): 0.122732  val_ema: 0.137748  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 289 — train_mse(std): 0.137748  val_mse(std): 0.122732  val_ema: 0.137748  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:50:30 | INFO | Epoch 290 — train_mse(std): 0.138075  val_mse(std): 0.123761  val_ema: 0.138075  last l2: 0.000883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 290 — train_mse(std): 0.138075  val_mse(std): 0.123761  val_ema: 0.138075  last l2: 0.000883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:51:19 | INFO | Epoch 291 — train_mse(std): 0.137958  val_mse(std): 0.121679  val_ema: 0.137958  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 291 — train_mse(std): 0.137958  val_mse(std): 0.121679  val_ema: 0.137958  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:52:08 | INFO | Epoch 292 — train_mse(std): 0.137759  val_mse(std): 0.123421  val_ema: 0.137759  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 292 — train_mse(std): 0.137759  val_mse(std): 0.123421  val_ema: 0.137759  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:52:57 | INFO | Epoch 293 — train_mse(std): 0.137790  val_mse(std): 0.122664  val_ema: 0.137790  last l2: 0.000917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 293 — train_mse(std): 0.137790  val_mse(std): 0.122664  val_ema: 0.137790  last l2: 0.000917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:53:45 | INFO | Epoch 294 — train_mse(std): 0.137776  val_mse(std): 0.122383  val_ema: 0.137776  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 294 — train_mse(std): 0.137776  val_mse(std): 0.122383  val_ema: 0.137776  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:54:33 | INFO | Epoch 295 — train_mse(std): 0.138131  val_mse(std): 0.123313  val_ema: 0.138131  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 295 — train_mse(std): 0.138131  val_mse(std): 0.123313  val_ema: 0.138131  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:55:21 | INFO | Epoch 296 — train_mse(std): 0.137700  val_mse(std): 0.122773  val_ema: 0.137700  last l2: 0.000781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 296 — train_mse(std): 0.137700  val_mse(std): 0.122773  val_ema: 0.137700  last l2: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:56:09 | INFO | Epoch 297 — train_mse(std): 0.138047  val_mse(std): 0.122764  val_ema: 0.138047  last l2: 0.000719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 297 — train_mse(std): 0.138047  val_mse(std): 0.122764  val_ema: 0.138047  last l2: 0.000719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:56:58 | INFO | Epoch 298 — train_mse(std): 0.137707  val_mse(std): 0.122599  val_ema: 0.137707  last l2: 0.000656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 298 — train_mse(std): 0.137707  val_mse(std): 0.122599  val_ema: 0.137707  last l2: 0.000656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:57:47 | INFO | Epoch 299 — train_mse(std): 0.137672  val_mse(std): 0.122467  val_ema: 0.137672  last l2: 0.000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 299 — train_mse(std): 0.137672  val_mse(std): 0.122467  val_ema: 0.137672  last l2: 0.000886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:58:36 | INFO | Epoch 300 — train_mse(std): 0.137953  val_mse(std): 0.123540  val_ema: 0.137953  last l2: 0.000707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 300 — train_mse(std): 0.137953  val_mse(std): 0.123540  val_ema: 0.137953  last l2: 0.000707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:59:25 | INFO | Epoch 301 — train_mse(std): 0.137967  val_mse(std): 0.122130  val_ema: 0.137967  last l2: 0.000590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 301 — train_mse(std): 0.137967  val_mse(std): 0.122130  val_ema: 0.137967  last l2: 0.000590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:00:14 | INFO | Epoch 302 — train_mse(std): 0.137610  val_mse(std): 0.123534  val_ema: 0.137610  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 302 — train_mse(std): 0.137610  val_mse(std): 0.123534  val_ema: 0.137610  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:00:14 | INFO |   🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  🔖 Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:01:02 | INFO | Epoch 303 — train_mse(std): 0.137686  val_mse(std): 0.123148  val_ema: 0.137686  last l2: 0.000783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 303 — train_mse(std): 0.137686  val_mse(std): 0.123148  val_ema: 0.137686  last l2: 0.000783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:01:52 | INFO | Epoch 304 — train_mse(std): 0.137739  val_mse(std): 0.122032  val_ema: 0.137739  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 304 — train_mse(std): 0.137739  val_mse(std): 0.122032  val_ema: 0.137739  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:02:42 | INFO | Epoch 305 — train_mse(std): 0.137951  val_mse(std): 0.122521  val_ema: 0.137951  last l2: 0.000736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 305 — train_mse(std): 0.137951  val_mse(std): 0.122521  val_ema: 0.137951  last l2: 0.000736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:03:31 | INFO | Epoch 306 — train_mse(std): 0.137819  val_mse(std): 0.125034  val_ema: 0.137819  last l2: 0.000658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 306 — train_mse(std): 0.137819  val_mse(std): 0.125034  val_ema: 0.137819  last l2: 0.000658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:04:20 | INFO | Epoch 307 — train_mse(std): 0.137826  val_mse(std): 0.123475  val_ema: 0.137826  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 307 — train_mse(std): 0.137826  val_mse(std): 0.123475  val_ema: 0.137826  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:05:09 | INFO | Epoch 308 — train_mse(std): 0.137935  val_mse(std): 0.123178  val_ema: 0.137935  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 308 — train_mse(std): 0.137935  val_mse(std): 0.123178  val_ema: 0.137935  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:05:58 | INFO | Epoch 309 — train_mse(std): 0.137812  val_mse(std): 0.123229  val_ema: 0.137812  last l2: 0.000835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 309 — train_mse(std): 0.137812  val_mse(std): 0.123229  val_ema: 0.137812  last l2: 0.000835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:06:46 | INFO | Epoch 310 — train_mse(std): 0.137637  val_mse(std): 0.123131  val_ema: 0.137637  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 310 — train_mse(std): 0.137637  val_mse(std): 0.123131  val_ema: 0.137637  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:07:35 | INFO | Epoch 311 — train_mse(std): 0.137695  val_mse(std): 0.122824  val_ema: 0.137695  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 311 — train_mse(std): 0.137695  val_mse(std): 0.122824  val_ema: 0.137695  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:08:23 | INFO | Epoch 312 — train_mse(std): 0.137974  val_mse(std): 0.122279  val_ema: 0.137974  last l2: 0.000754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 312 — train_mse(std): 0.137974  val_mse(std): 0.122279  val_ema: 0.137974  last l2: 0.000754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:09:11 | INFO | Epoch 313 — train_mse(std): 0.137608  val_mse(std): 0.123396  val_ema: 0.137608  last l2: 0.000796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 313 — train_mse(std): 0.137608  val_mse(std): 0.123396  val_ema: 0.137608  last l2: 0.000796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:10:00 | INFO | Epoch 314 — train_mse(std): 0.137869  val_mse(std): 0.123718  val_ema: 0.137869  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 314 — train_mse(std): 0.137869  val_mse(std): 0.123718  val_ema: 0.137869  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:10:48 | INFO | Epoch 315 — train_mse(std): 0.137745  val_mse(std): 0.122907  val_ema: 0.137745  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 315 — train_mse(std): 0.137745  val_mse(std): 0.122907  val_ema: 0.137745  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:11:37 | INFO | Epoch 316 — train_mse(std): 0.137621  val_mse(std): 0.123264  val_ema: 0.137621  last l2: 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 316 — train_mse(std): 0.137621  val_mse(std): 0.123264  val_ema: 0.137621  last l2: 0.000913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:12:25 | INFO | Epoch 317 — train_mse(std): 0.137606  val_mse(std): 0.123764  val_ema: 0.137606  last l2: 0.000563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 317 — train_mse(std): 0.137606  val_mse(std): 0.123764  val_ema: 0.137606  last l2: 0.000563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:13:14 | INFO | Epoch 318 — train_mse(std): 0.137722  val_mse(std): 0.122842  val_ema: 0.137722  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 318 — train_mse(std): 0.137722  val_mse(std): 0.122842  val_ema: 0.137722  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:14:02 | INFO | Epoch 319 — train_mse(std): 0.137673  val_mse(std): 0.122469  val_ema: 0.137673  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 319 — train_mse(std): 0.137673  val_mse(std): 0.122469  val_ema: 0.137673  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:14:51 | INFO | Epoch 320 — train_mse(std): 0.137731  val_mse(std): 0.121959  val_ema: 0.137731  last l2: 0.001035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 320 — train_mse(std): 0.137731  val_mse(std): 0.121959  val_ema: 0.137731  last l2: 0.001035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:15:39 | INFO | Epoch 321 — train_mse(std): 0.137914  val_mse(std): 0.122854  val_ema: 0.137914  last l2: 0.000482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 321 — train_mse(std): 0.137914  val_mse(std): 0.122854  val_ema: 0.137914  last l2: 0.000482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:16:28 | INFO | Epoch 322 — train_mse(std): 0.137546  val_mse(std): 0.124235  val_ema: 0.137546  last l2: 0.000945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 322 — train_mse(std): 0.137546  val_mse(std): 0.124235  val_ema: 0.137546  last l2: 0.000945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:17:17 | INFO | Epoch 323 — train_mse(std): 0.138038  val_mse(std): 0.124308  val_ema: 0.138038  last l2: 0.000689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 323 — train_mse(std): 0.138038  val_mse(std): 0.124308  val_ema: 0.138038  last l2: 0.000689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:18:05 | INFO | Epoch 324 — train_mse(std): 0.137752  val_mse(std): 0.123099  val_ema: 0.137752  last l2: 0.000873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 324 — train_mse(std): 0.137752  val_mse(std): 0.123099  val_ema: 0.137752  last l2: 0.000873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:18:54 | INFO | Epoch 325 — train_mse(std): 0.137567  val_mse(std): 0.122898  val_ema: 0.137567  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 325 — train_mse(std): 0.137567  val_mse(std): 0.122898  val_ema: 0.137567  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:19:43 | INFO | Epoch 326 — train_mse(std): 0.137621  val_mse(std): 0.124089  val_ema: 0.137621  last l2: 0.001074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 326 — train_mse(std): 0.137621  val_mse(std): 0.124089  val_ema: 0.137621  last l2: 0.001074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:20:33 | INFO | Epoch 327 — train_mse(std): 0.137619  val_mse(std): 0.124051  val_ema: 0.137619  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 327 — train_mse(std): 0.137619  val_mse(std): 0.124051  val_ema: 0.137619  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:21:22 | INFO | Epoch 328 — train_mse(std): 0.137587  val_mse(std): 0.123962  val_ema: 0.137587  last l2: 0.000696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 328 — train_mse(std): 0.137587  val_mse(std): 0.123962  val_ema: 0.137587  last l2: 0.000696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:22:11 | INFO | Epoch 329 — train_mse(std): 0.137979  val_mse(std): 0.123727  val_ema: 0.137979  last l2: 0.000512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 329 — train_mse(std): 0.137979  val_mse(std): 0.123727  val_ema: 0.137979  last l2: 0.000512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:22:59 | INFO | Epoch 330 — train_mse(std): 0.137667  val_mse(std): 0.123019  val_ema: 0.137667  last l2: 0.000807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 330 — train_mse(std): 0.137667  val_mse(std): 0.123019  val_ema: 0.137667  last l2: 0.000807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:23:48 | INFO | Epoch 331 — train_mse(std): 0.137621  val_mse(std): 0.123012  val_ema: 0.137621  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 331 — train_mse(std): 0.137621  val_mse(std): 0.123012  val_ema: 0.137621  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:24:36 | INFO | Epoch 332 — train_mse(std): 0.137860  val_mse(std): 0.123342  val_ema: 0.137860  last l2: 0.000665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 332 — train_mse(std): 0.137860  val_mse(std): 0.123342  val_ema: 0.137860  last l2: 0.000665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:24:36 | INFO |   ⏹ Early stopping after 30 epochs without meaningful improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:  ⏹ Early stopping after 30 epochs without meaningful improvement.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path  = \"./models/best_model_tod_3.pth\"\n",
    "# ---- compute train-only stats once ----\n",
    "feat_mean, feat_std = estimate_feature_stats(train_loader, DEVICE)\n",
    "feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "\n",
    "# -------------------- TRAIN LOOP (MSE / Huber + optional adaptive L2) --------\n",
    "USE_HUBER      = False      # set True to use Huber instead of MSE\n",
    "# before training loop\n",
    "L2_COEFF       = 0.1      # <- your fixed coefficient\n",
    "warmup_epochs  = 30       # same as before (or 0 to disable warmup)\n",
    "\n",
    "use_amp        = (DEVICE.type == \"cuda\")\n",
    "scaler         = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "from contextlib import nullcontext\n",
    "amp_ctx = (lambda: torch.amp.autocast('cuda', dtype=torch.float16)) if use_amp else (lambda: nullcontext())\n",
    "\n",
    "best_val, epochs_no_improve = float(\"inf\"), 0\n",
    "min_delta, patience = 1e-4, 30\n",
    "ema_alpha, val_ema  = 0.2, None\n",
    "max_grad = 1.0  # set to 0 to disable clipping\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    train_sse, train_n, last_l2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, _, _ in train_loader:\n",
    "        x, pad_mask, obs_mask = x.to(DEVICE), pad_mask.to(DEVICE).bool(), obs_mask.to(DEVICE).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with amp_ctx():\n",
    "            recon, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "            # reconstruction loss in standardized space\n",
    "            recon_loss = masked_huber(recon, x_std_tgt, pad_mask, obs_mask, delta=1.0) if USE_HUBER \\\n",
    "                         else masked_mse  (recon, x_std_tgt, pad_mask, obs_mask)\n",
    "\n",
    "            # optional adaptive latent L2: keeps l2 ≈ TARGET_L2_RATIO * recon\n",
    "            eps = 1e-8\n",
    "            # inside the training step, after you computed recon_loss and z\n",
    "            latent_l2 = z.pow(2).sum(dim=1).mean()        # E[||z||^2] over the batch\n",
    "            warm      = min(1.0, (epoch + 1) / max(1, warmup_epochs))\n",
    "            l2_loss   = L2_COEFF * warm * latent_l2\n",
    "            \n",
    "            loss = recon_loss + l2_loss\n",
    "\n",
    "            # for logging standardized MSE\n",
    "            valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "            diff  = (recon - x_std_tgt)[valid]\n",
    "            sse   = (diff * diff).sum()\n",
    "            nvalid= valid.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if max_grad and max_grad > 0:\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        train_sse += float(sse.item())\n",
    "        train_n   += float(nvalid.item())\n",
    "        last_l2    = float(l2_loss.detach().item())\n",
    "\n",
    "    scheduler.step()\n",
    "    train_mse = train_sse / max(1.0, train_n)\n",
    "    val_mse   = evaluate(model, val_loader, DEVICE, feat_mean, feat_std)\n",
    "\n",
    "    # EMA smoothing + early stop\n",
    "    val_ema = train_mse if val_ema is None else (1-ema_alpha)*train_mse + ema_alpha*train_mse\n",
    "    improved = (best_val - val_ema) > min_delta\n",
    "    logger.info(f\"Epoch {epoch:03d} — train_mse(std): {train_mse:.6f}  val_mse(std): {val_mse:.6f}  \"\n",
    "          f\"val_ema: {val_ema:.6f}  last l2: {last_l2:.6f}\")\n",
    "\n",
    "    if improved:\n",
    "        best_val = val_ema\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch':                epoch,\n",
    "            'model_state_dict':     model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_mse':         float(val_mse),\n",
    "            'feat_mean':            feat_mean,\n",
    "            'feat_std':             feat_std,\n",
    "        }, checkpoint_path)\n",
    "        logger.info(\"  🔖 Saved new best model.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(f\"  ⏹ Early stopping after {patience} epochs without meaningful improvement.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96000b9f-4193-40c1-a19f-58ed27c84787",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path  = \"./models/best_model_tod_finetune_2_simulation.pth\"\n",
    "# ---- compute train-only stats once ----\n",
    "feat_mean, feat_std = estimate_feature_stats(ttrain_loader, DEVICE)\n",
    "feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "\n",
    "# -------------------- TRAIN LOOP (MSE / Huber + optional adaptive L2) --------\n",
    "USE_HUBER      = False      # set True to use Huber instead of MSE\n",
    "# before training loop\n",
    "L2_COEFF       = 0.0      # <- your fixed coefficient\n",
    "warmup_epochs  = 0       # same as before (or 0 to disable warmup)\n",
    "\n",
    "use_amp        = (DEVICE.type == \"cuda\")\n",
    "scaler         = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "from contextlib import nullcontext\n",
    "amp_ctx = (lambda: torch.amp.autocast('cuda', dtype=torch.float16)) if use_amp else (lambda: nullcontext())\n",
    "\n",
    "best_val, epochs_no_improve = float(\"inf\"), 0\n",
    "min_delta, patience = 1e-4, 100\n",
    "ema_alpha, val_ema  = 0.2, None\n",
    "max_grad = 1.0  # set to 0 to disable clipping\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    train_sse, train_n, last_l2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, _, _ in train_loader:\n",
    "        x, pad_mask, obs_mask = x.to(DEVICE), pad_mask.to(DEVICE).bool(), obs_mask.to(DEVICE).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with amp_ctx():\n",
    "            recon, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "            # reconstruction loss in standardized space\n",
    "            recon_loss = masked_huber(recon, x_std_tgt, pad_mask, obs_mask, delta=1.0) if USE_HUBER \\\n",
    "                         else masked_mse  (recon, x_std_tgt, pad_mask, obs_mask)\n",
    "\n",
    "            # optional adaptive latent L2: keeps l2 ≈ TARGET_L2_RATIO * recon\n",
    "            eps = 1e-8\n",
    "            # inside the training step, after you computed recon_loss and z\n",
    "            latent_l2 = z.pow(2).sum(dim=1).mean()        # E[||z||^2] over the batch\n",
    "            warm      = min(1.0, (epoch + 1) / max(1, warmup_epochs))\n",
    "            l2_loss   = L2_COEFF * warm * latent_l2\n",
    "            \n",
    "            loss = recon_loss + l2_loss\n",
    "\n",
    "            # for logging standardized MSE\n",
    "            valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "            diff  = (recon - x_std_tgt)[valid]\n",
    "            sse   = (diff * diff).sum()\n",
    "            nvalid= valid.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if max_grad and max_grad > 0:\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        train_sse += float(sse.item())\n",
    "        train_n   += float(nvalid.item())\n",
    "        last_l2    = float(l2_loss.detach().item())\n",
    "\n",
    "    scheduler.step()\n",
    "    train_mse = train_sse / max(1.0, train_n)\n",
    "    val_mse   = evaluate(model, val_loader, DEVICE, feat_mean, feat_std)\n",
    "\n",
    "    # EMA smoothing + early stop\n",
    "    val_ema = val_mse if val_ema is None else (1-ema_alpha)*val_ema + ema_alpha*val_mse\n",
    "    improved = (best_val - val_ema) > min_delta\n",
    "    print(f\"Epoch {epoch:03d} — train_mse(std): {train_mse:.6f}  val_mse(std): {val_mse:.6f}  \"\n",
    "          f\"val_ema: {val_ema:.6f}  last l2: {last_l2:.6f}\")\n",
    "\n",
    "    if improved:\n",
    "        best_val = val_ema\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch':                epoch,\n",
    "            'model_state_dict':     model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_mse':         float(val_mse),\n",
    "            'feat_mean':            feat_mean,\n",
    "            'feat_std':             feat_std,\n",
    "        }, checkpoint_path)\n",
    "        print(\"  🔖 Saved new best model.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"  ⏹ Early stopping after {patience} epochs without meaningful improvement.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f89ccb1a-394b-4824-ae1f-9ca3be4916c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m checkpoint_path  = \u001b[33m\"\u001b[39m\u001b[33m./models/best_model_tod_3.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model.load_state_dict(ckpt[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m feat_mean = ckpt.get(\u001b[33m'\u001b[39m\u001b[33mfeat_mean\u001b[39m\u001b[33m'\u001b[39m, feat_mean).to(DEVICE)\n\u001b[32m      6\u001b[39m feat_std  = ckpt.get(\u001b[33m'\u001b[39m\u001b[33mfeat_std\u001b[39m\u001b[33m'\u001b[39m,  feat_std ).to(DEVICE)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Pipeline' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "# -------------------- TEST --------------------\n",
    "checkpoint_path  = \"./models/best_model_tod_3.pth\"\n",
    "ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "feat_mean = ckpt.get('feat_mean', feat_mean).to(DEVICE)\n",
    "feat_std  = ckpt.get('feat_std',  feat_std ).to(DEVICE)\n",
    "\n",
    "test_mse_std = evaluate(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "test_mse_org = evaluate_original_scale(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "print(f\"🧪 Test MSE (std): {test_mse_std:.6f}   |  Test MSE (orig): {test_mse_org:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48ada3c6-48cb-4b15-9bb9-0f5d19d9c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traj 0be69199cbf323a60203877d040c6583c6bbb5c20c2189f1ea9f133dcaba3b4a ===\n",
      "z shape: (64,) | ||z||2=0.064 | mean|z|=0.0045\n",
      "Cosine per step (std space, masked) — avg=0.9596, median=0.9668, best=0.9691, worst=0.9255\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      "109    13     128 0.9255\n",
      "108    12     128 0.9357\n",
      " 51     3     128 0.9568\n",
      " 52     4     128 0.9569\n",
      "134    14     128 0.9614\n",
      " 19    19     128 0.9615\n",
      "116    20     128 0.9668\n",
      "117    21     128 0.9677\n",
      "119    23     128 0.9678\n",
      " 22    22     128 0.9678\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      "  8     8     128 0.9691\n",
      " 39    15     128 0.9690\n",
      "  9     9     128 0.9690\n",
      " 22    22     128 0.9678\n",
      "119    23     128 0.9678\n",
      "117    21     128 0.9677\n",
      "116    20     128 0.9668\n",
      " 19    19     128 0.9615\n",
      "134    14     128 0.9614\n",
      " 52     4     128 0.9569\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      96    4.0857                 56.5       13\n",
      "      79    5.6164                 52.5       13\n",
      "      24    0.1899                 44.3       13\n",
      "      29    0.1875                 43.7       13\n",
      "      98    3.4779                 42.7       13\n",
      "      18    0.1787                 41.3       13\n",
      "      23    0.1963                 41.2       13\n",
      "     123    3.3994                 39.9       13\n",
      "       5    0.1853                 38.5       13\n",
      "       0    0.1743                 38.3       13\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      97    0.3526                  7.7       13\n",
      "     102    1.3861                  8.5       13\n",
      "       4    0.0509                 10.8       13\n",
      "     105    1.1941                 11.2       13\n",
      "      35    0.0563                 11.4       13\n",
      "      84    1.4258                 11.6       13\n",
      "      25    0.0572                 11.6       13\n",
      "      69    1.3118                 11.7       13\n",
      "      60    0.0581                 12.1       13\n",
      "      17    0.0509                 12.1       13\n",
      "\n",
      "=== Traj 5625a5c6d8d568a375e391cd7b0ef43bc87b7ece25663712000259876a7cca9d ===\n",
      "z shape: (64,) | ||z||2=0.085 | mean|z|=0.0068\n",
      "Cosine per step (std space, masked) — avg=0.9463, median=0.9466, best=0.9526, worst=0.9196\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      " 93    21     128 0.9196\n",
      " 90    18     128 0.9301\n",
      " 86    14     128 0.9329\n",
      "116    20     128 0.9372\n",
      "109    13     128 0.9459\n",
      " 87    15     128 0.9461\n",
      " 56     8     128 0.9461\n",
      "107    11     128 0.9462\n",
      " 40    16     128 0.9463\n",
      " 36    12     128 0.9465\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      " 30     6     128 0.9526\n",
      " 53     5     128 0.9526\n",
      " 28     4     128 0.9525\n",
      " 79     7     128 0.9524\n",
      "121     1     128 0.9523\n",
      " 99     3     128 0.9522\n",
      " 74     2     128 0.9522\n",
      "118    22     128 0.9522\n",
      " 71    23     128 0.9521\n",
      " 24     0     128 0.9520\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      55    0.3064                 66.3       23\n",
      "      30    0.2584                 60.3       23\n",
      "      27    0.2468                 56.4       23\n",
      "      53    0.2699                 55.9       23\n",
      "      79    5.9715                 55.8       23\n",
      "     110    5.2826                 55.7       23\n",
      "      78    4.0601                 55.3       23\n",
      "      46    0.2348                 50.4       23\n",
      "      67    6.2488                 50.0       23\n",
      "      35    0.2327                 47.3       23\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "     111    1.3870                  5.9       23\n",
      "      88    0.8719                  8.2       23\n",
      "      90    1.3994                 10.7       23\n",
      "     118    1.5150                 11.8       23\n",
      "      60    0.0571                 11.9       23\n",
      "     112    1.4060                 12.5       23\n",
      "      15    0.0597                 12.6       23\n",
      "     102    2.1044                 12.9       23\n",
      "      84    1.6048                 13.1       23\n",
      "     117    1.1685                 14.2       23\n",
      "\n",
      "=== Traj db8c1845f4c22fa37bd0779dd7f8a493e8c5e86c0461ba18c336d1ab003660b5 ===\n",
      "z shape: (64,) | ||z||2=0.036 | mean|z|=0.0033\n",
      "Cosine per step (std space, masked) — avg=0.9304, median=0.9286, best=0.9536, worst=0.9032\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      " t  hour  n_dims cosine\n",
      "81     9     128 0.9032\n",
      "85    13     128 0.9041\n",
      "19    19     128 0.9225\n",
      "95    23     128 0.9226\n",
      "42    18     128 0.9227\n",
      "44    20     128 0.9228\n",
      "65    17     128 0.9232\n",
      "38    14     128 0.9340\n",
      "22    22     128 0.9340\n",
      "21    21     128 0.9340\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      " t  hour  n_dims cosine\n",
      "82    10     128 0.9536\n",
      "80     8     128 0.9535\n",
      "39    15     128 0.9478\n",
      "40    16     128 0.9475\n",
      "21    21     128 0.9340\n",
      "22    22     128 0.9340\n",
      "38    14     128 0.9340\n",
      "65    17     128 0.9232\n",
      "44    20     128 0.9228\n",
      "42    18     128 0.9227\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "     123    6.7340                 79.0       14\n",
      "     110    6.3882                 67.3       14\n",
      "      59    0.2777                 62.5       14\n",
      "     115    5.8927                 62.4       14\n",
      "     122    3.9380                 58.0       14\n",
      "      46    0.2638                 56.6       14\n",
      "      47    0.2535                 56.3       14\n",
      "       3    0.2632                 55.6       14\n",
      "      57    0.2452                 53.8       14\n",
      "      74    5.1560                 52.8       14\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      98    0.7943                  9.7       14\n",
      "       4    0.0504                 10.7       14\n",
      "      31    0.0553                 12.0       14\n",
      "      90    1.6783                 12.9       14\n",
      "     109    2.1532                 13.5       14\n",
      "      64    1.7853                 13.9       14\n",
      "      39    0.0681                 14.4       14\n",
      "     104    0.8313                 14.9       14\n",
      "      17    0.0631                 15.1       14\n",
      "      89    2.4264                 16.0       14\n",
      "\n",
      "=== Dataset cosine summary (std space, masked) ===\n",
      "mean=0.9352  median=0.9415  p05=0.8792  p95=0.9731  n=168981\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_examples(model, loader, device, feat_mean, feat_std, k=5, which=\"first\", top_k=10):\n",
    "    \"\"\"\n",
    "    For k trajectories: prints latent stats, per-feature RMSE (orig scale),\n",
    "    and per-time-step cosine similarity (std space, masked).\n",
    "    which: \"first\" | \"random\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    shown, rng = 0, np.random.default_rng(0)\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, idxs, traj_ids in loader:\n",
    "        x        = x.to(device)                 # (B,L,D) raw\n",
    "        pad_mask = pad_mask.to(device).bool()   # (B,L)\n",
    "        obs_mask = obs_mask.to(device).bool()   # (B,L,D)\n",
    "        hours    = hours.to(device).long()      # (B,L)\n",
    "\n",
    "        # standardize inputs as in training\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        x_in  = x_std.masked_fill(~obs_mask, 0.0).masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "\n",
    "        recon_std, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        # for reporting RMSE in original scale\n",
    "        recon = recon_std * feat_std.view(1,1,-1) + feat_mean.view(1,1,-1)\n",
    "\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)      # (B,L,D)\n",
    "        B, L, D = x.shape\n",
    "\n",
    "        order = list(range(B))\n",
    "        if which == \"random\":\n",
    "            rng.shuffle(order)\n",
    "\n",
    "        for b in order:\n",
    "            vb = valid[b]  # (L,D)\n",
    "            if not vb.any():\n",
    "                continue\n",
    "\n",
    "            # ---- per-feature RMSE on ORIGINAL scale ----\n",
    "            se_feat = torch.zeros(D, device=device)\n",
    "            n_feat  = torch.zeros(D, device=device)\n",
    "            for t in range(L):\n",
    "                vtd = vb[t]                            # (D,)\n",
    "                if vtd.any():\n",
    "                    dtd = (recon[b, t] - x[b, t])[vtd]\n",
    "                    se_feat[vtd] += dtd.pow(2)\n",
    "                    n_feat[vtd]  += 1\n",
    "            rmse_feat = (se_feat / n_feat.clamp_min(1)).sqrt().cpu().numpy()  # (D,)\n",
    "            feat_std_np = feat_std.cpu().numpy()\n",
    "            nrmse_pct = 100.0 * (rmse_feat / np.maximum(feat_std_np, 1e-8))\n",
    "\n",
    "            df_feat = pd.DataFrame({\n",
    "                \"feature\": np.arange(D),\n",
    "                \"RMSE_orig\": rmse_feat,\n",
    "                \"NRMSE_%_of_train_std\": nrmse_pct,\n",
    "                \"n_valid\": n_feat.cpu().numpy().astype(int)\n",
    "            })\n",
    "            worst_feat = df_feat.sort_values(\"NRMSE_%_of_train_std\", ascending=False).head(top_k)\n",
    "            best_feat  = df_feat.sort_values(\"NRMSE_%_of_train_std\", ascending=True ).head(top_k)\n",
    "\n",
    "            # ---- per-time-step cosine similarity (STANDARDIZED) ----\n",
    "            cos_list, n_dim_list, hour_list, tidx_list = [], [], [], []\n",
    "            for t in range(L):\n",
    "                vtd = vb[t]  # valid dims at time t\n",
    "                if vtd.any():\n",
    "                    xt = x_std[b, t][vtd]\n",
    "                    rt = recon_std[b, t][vtd]\n",
    "                    # cosine with masking\n",
    "                    denom = (xt.norm() * rt.norm()).clamp_min(1e-12)\n",
    "                    cos_t = float((xt * rt).sum() / denom)\n",
    "                    cos_list.append(cos_t)\n",
    "                    n_dim_list.append(int(vtd.sum().item()))\n",
    "                    hour_list.append(int(hours[b, t].item()))\n",
    "                    tidx_list.append(t)\n",
    "\n",
    "            if len(cos_list) == 0:\n",
    "                avg_cos, med_cos = float(\"nan\"), float(\"nan\")\n",
    "                best_steps = worst_steps = pd.DataFrame()\n",
    "            else:\n",
    "                cos_arr = np.array(cos_list)\n",
    "                avg_cos = float(np.mean(cos_arr))\n",
    "                med_cos = float(np.median(cos_arr))\n",
    "                df_time = pd.DataFrame({\n",
    "                    \"t\": tidx_list,\n",
    "                    \"hour\": hour_list,\n",
    "                    \"n_dims\": n_dim_list,\n",
    "                    \"cosine\": cos_arr\n",
    "                })\n",
    "                best_steps  = df_time.sort_values(\"cosine\", ascending=False).head(top_k)\n",
    "                worst_steps = df_time.sort_values(\"cosine\", ascending=True ).head(top_k)\n",
    "\n",
    "            # ---- print summary ----\n",
    "            z_np = z[b].cpu().numpy()\n",
    "            print(f\"\\n=== Traj {traj_ids[b]} ===\")\n",
    "            print(f\"z shape: {z_np.shape} | ||z||2={np.linalg.norm(z_np):.3f} | mean|z|={np.abs(z_np).mean():.4f}\")\n",
    "            print(f\"Cosine per step (std space, masked) — avg={avg_cos:.4f}, median={med_cos:.4f}, \"\n",
    "                  f\"best={np.max(cos_list) if cos_list else float('nan'):.4f}, \"\n",
    "                  f\"worst={np.min(cos_list) if cos_list else float('nan'):.4f}\")\n",
    "\n",
    "            print(\"\\nTop-10 WORST time steps by cosine:\")\n",
    "            if len(cos_list):\n",
    "                print(worst_steps.to_string(index=False, formatters={\n",
    "                    \"cosine\": lambda v: f\"{v:.4f}\"\n",
    "                }))\n",
    "            else:\n",
    "                print(\"  (no valid steps)\")\n",
    "\n",
    "            print(\"\\nTop-10 BEST time steps by cosine:\")\n",
    "            if len(cos_list):\n",
    "                print(best_steps.to_string(index=False, formatters={\n",
    "                    \"cosine\": lambda v: f\"{v:.4f}\"\n",
    "                }))\n",
    "            else:\n",
    "                print(\"  (no valid steps)\")\n",
    "\n",
    "            print(\"\\nTop-10 WORST features by % of train std:\")\n",
    "            print(worst_feat.to_string(index=False, formatters={\n",
    "                \"RMSE_orig\": lambda v: f\"{v:.4f}\",\n",
    "                \"NRMSE_%_of_train_std\": lambda v: f\"{v:.1f}\"\n",
    "            }))\n",
    "            print(\"\\nTop-10 BEST features by % of train std:\")\n",
    "            print(best_feat.to_string(index=False, formatters={\n",
    "                \"RMSE_orig\": lambda v: f\"{v:.4f}\",\n",
    "                \"NRMSE_%_of_train_std\": lambda v: f\"{v:.1f}\"\n",
    "            }))\n",
    "\n",
    "            shown += 1\n",
    "            if shown >= k:\n",
    "                return\n",
    "\n",
    "    if shown == 0:\n",
    "        print(\"No valid examples found (all entries missing?)\")\n",
    "\n",
    "\n",
    "# ---------- Optional: dataset-level cosine summary ----------\n",
    "@torch.no_grad()\n",
    "def summarize_cosine(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"Aggregate cosine per time step across the whole loader.\"\"\"\n",
    "    model.eval()\n",
    "    cos_vals = []\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x        = x.to(device)\n",
    "        pad_mask = pad_mask.to(device).bool()\n",
    "        obs_mask = obs_mask.to(device).bool()\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        x_in  = x_std.masked_fill(~obs_mask, 0.0).masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "        recon_std, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        B, L, D = x.shape\n",
    "        for b in range(B):\n",
    "            for t in range(L):\n",
    "                vtd = valid[b, t]\n",
    "                if vtd.any():\n",
    "                    xt = x_std[b, t][vtd]\n",
    "                    rt = recon_std[b, t][vtd]\n",
    "                    denom = (xt.norm() * rt.norm()).clamp_min(1e-12)\n",
    "                    cos_vals.append(float((xt * rt).sum() / denom))\n",
    "    if not cos_vals:\n",
    "        print(\"No valid steps for cosine.\")\n",
    "        return\n",
    "    arr = np.array(cos_vals)\n",
    "    print(\"\\n=== Dataset cosine summary (std space, masked) ===\")\n",
    "    print(f\"mean={arr.mean():.4f}  median={np.median(arr):.4f}  \"\n",
    "          f\"p05={np.percentile(arr,5):.4f}  p95={np.percentile(arr,95):.4f}  n={arr.size}\")\n",
    "\n",
    "# ---- Example usage ----\n",
    "# Non-shuffled loader for inspection\n",
    "test_inspect_loader = DataLoader(\n",
    "    test_ds, batch_size=32, shuffle=False,\n",
    "    collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda')\n",
    ")\n",
    "\n",
    "analyze_examples(model, test_inspect_loader, DEVICE, feat_mean, feat_std, k=3, which=\"first\", top_k=10)\n",
    "summarize_cosine(model, test_inspect_loader, DEVICE, feat_mean, feat_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fa57ca5-5e3a-4cdb-b127-d80fd7aa972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def collect_latents(model, loader, device, feat_mean, feat_std):\n",
    "    model.eval()\n",
    "    Z_chunks, ids = [], []\n",
    "    for x, pad_mask, obs_mask, hours, _, traj_ids in loader:\n",
    "        x        = x.to(device)\n",
    "        pad_mask = pad_mask.to(device).bool()\n",
    "        obs_mask = obs_mask.to(device).bool()\n",
    "\n",
    "        # same standardization you used for training\n",
    "        x_in, _ = standardize_batch(x, obs_mask, feat_mean, feat_std)  # or pass pad_mask if your fn supports it\n",
    "        _, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "        Z_chunks.append(z.cpu())      # (B, d_model)\n",
    "        ids.extend(traj_ids)          # keep exact mapping\n",
    "    Z = torch.cat(Z_chunks, dim=0).numpy()  # (N_traj, d_model)\n",
    "    return Z, ids\n",
    "\n",
    "# Build a NON-shuffled loader over the set you want to cluster (train/val/test/full)\n",
    "full_loader = DataLoader(\n",
    "    dataset,                      # or train_ds / val_ds / test_ds\n",
    "    batch_size=128,\n",
    "    shuffle=False,                # IMPORTANT for reproducible ordering (we still collect ids anyway)\n",
    "    collate_fn=collate_fn,        # your make_collate_fn_time(...)\n",
    "    pin_memory=(DEVICE.type=='cuda'),\n",
    ")\n",
    "\n",
    "Z, ids = collect_latents(model, full_loader, DEVICE, feat_mean, feat_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c71642e5-ce53-4d18-95e9-a7f9abc1838a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95410, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a275fc8e-c7a2-4fce-bc11-ee036876f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./latent.npy', Z)\n",
    "np.save('./ids.npy', ids)\n",
    "#loaded_data = np.load('my_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "07ecb973-9c1e-4dc3-823f-c1f958017b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95410,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_gdf.traj_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095d2e7-6b31-49a0-bf93-3464aee70b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means_constrained import KMeansConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cc88e-ce64-4aae-aa86-6bf911175298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "Zs = StandardScaler().fit_transform(Z) \n",
    "kmeans = KMeansConstrained(\n",
    "    n_clusters=4,\n",
    "    size_min=10,\n",
    "    size_max=30,\n",
    "    random_state=42\n",
    ")\n",
    "kmeans.fit_predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9ab76-5e23-4de2-9c3b-abc911ad2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ground_t.pickle\", 'rb') as f:\n",
    "    y_true_str = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137c1d0-dddb-4398-9b3c-6ac221170e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_str = [y_true_str[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af74479-436d-451c-9ee6-d96e84035cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def per_category_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute per-category accuracy (recall) using optimal cluster→label mapping.\n",
    "    Returns:\n",
    "      per_class_df, mapping_dict, overall_acc, confmat_df\n",
    "    \"\"\"\n",
    "    # Encode true labels to stable ints\n",
    "    le = LabelEncoder().fit(y_true)\n",
    "    yt = le.transform(y_true)\n",
    "    yp = np.asarray(y_pred)\n",
    "\n",
    "    # Build confusion matrix (rows=true, cols=pred)\n",
    "    true_classes = np.arange(len(le.classes_))\n",
    "    pred_classes = np.unique(yp)\n",
    "    C = confusion_matrix(yt, yp, labels=true_classes)\n",
    "\n",
    "    # If #pred ≠ #true, pad to square for Hungarian\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:\n",
    "        C_pad = np.pad(C, ((0,0),(0, nT-nP)), mode='constant')\n",
    "    elif nP > nT:\n",
    "        C_pad = np.pad(C, ((0, nP-nT),(0,0)), mode='constant')\n",
    "    else:\n",
    "        C_pad = C\n",
    "\n",
    "    # Hungarian to maximize trace\n",
    "    r_idx, c_idx = linear_sum_assignment(-C_pad)\n",
    "    # Build mapping from pred cluster -> true class index (only valid ones)\n",
    "    mapping = {}\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:  # ignore padded region\n",
    "            mapping[pred_classes[c]] = true_classes[r]\n",
    "\n",
    "    # Apply mapping to predictions (unmapped preds remain unmapped -> will count as wrong)\n",
    "    yp_mapped_true_idx = np.array([mapping.get(p, -9999) for p in yp])\n",
    "\n",
    "    # Overall accuracy (micro)\n",
    "    overall_acc = float(np.mean(yp_mapped_true_idx == yt))\n",
    "\n",
    "    # Per-class stats\n",
    "    rows = []\n",
    "    for k, name in enumerate(le.classes_):\n",
    "        support = int(np.sum(yt == k))\n",
    "        correct = int(np.sum((yt == k) & (yp_mapped_true_idx == k)))\n",
    "        # predicted positives for this class (precision denom)\n",
    "        pred_pos = int(np.sum(yp_mapped_true_idx == k))\n",
    "        recall = (correct / support) if support else np.nan\n",
    "        precision = (correct / pred_pos) if pred_pos else np.nan\n",
    "        f1 = (2*precision*recall / (precision+recall)) if (precision and recall) else np.nan\n",
    "        rows.append(dict(category=name, support=support, correct=correct,\n",
    "                         accuracy_recall=recall, precision=precision, f1=f1))\n",
    "    per_class_df = pd.DataFrame(rows).sort_values(\"category\").reset_index(drop=True)\n",
    "\n",
    "    # Nice confusion matrix with mapped columns renamed to true labels (for reference)\n",
    "    confmat_df = pd.DataFrame(C, index=[f\"true:{c}\" for c in le.classes_],\n",
    "                                 columns=[f\"pred:{p}\" for p in pred_classes])\n",
    "\n",
    "    return per_class_df, {k: le.classes_[v] for k, v in mapping.items()}, overall_acc, confmat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1519f-4ba8-40d5-8bc7-af42377ea8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "for i in tqdm(range(1000)):\n",
    "\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=4,\n",
    "        size_min=5,\n",
    "        size_max=35,\n",
    "        random_state=i\n",
    "    )\n",
    "    kmeans.fit_predict(X)\n",
    "    \n",
    "    #print(\"Cluster labels:\", kmeans.labels_)\n",
    "    #print(\"Cluster centers:\", kmeans.cluster_centers_)# whiten latents\n",
    "    #kmeans = KMeans(n_clusters=4, n_init=20, random_state=0)\n",
    "    labels = kmeans.fit_predict(Zs)\n",
    "    sil = silhouette_score(Zs, labels)\n",
    "    \n",
    "    cluster_df = pd.DataFrame({\"traj_id\": ids, \"cluster\": labels})\n",
    "    \n",
    "    labels  = cluster_df.cluster.to_list()\n",
    "    per_class, mapping, acc_overall, cm = per_category_accuracy(y_true_str, labels)\n",
    "    if acc_overall<= best:\n",
    "        pass\n",
    "    else:\n",
    "        best = acc_overall\n",
    "        best_model = kmeans\n",
    "        best_df = cluster_df\n",
    "        print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abd7f6-2828-49b3-b2ca-cadacdec8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3-class sweep with KMeansConstrained (drop 'evac_short_in_zone') ---\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Inputs you already have:\n",
    "#   Zs          -> standardized features for ALL rows (np.array, shape [N, d])\n",
    "#   y_true_str  -> ground-truth strings of length N\n",
    "#   ids         -> traj ids of length N\n",
    "\n",
    "# 1) keep only the 3 classes we care about\n",
    "keep = pd.Series(y_true_str).isin([\"evac_out_of_zone\", \"sip_home_grocery\", \"sip_hospital\"]).to_numpy()\n",
    "Zs3   = Zs[keep]\n",
    "y3    = pd.Series(y_true_str)[keep].astype(str).reset_index(drop=True)\n",
    "ids3  = pd.Series(ids)[keep].reset_index(drop=True)\n",
    "\n",
    "print(f\"Using {keep.sum()} rows; dropped {(~keep).sum()} 'evac_short_in_zone'.\")\n",
    "\n",
    "# 2) label-safe evaluator (works for any #clusters; here it will be 3)\n",
    "def per_category_accuracy_3(y_true, y_pred):\n",
    "    yt = pd.Series(list(map(str, y_true)), name=\"true\")\n",
    "    yp = pd.Series(list(y_pred), name=\"pred\")\n",
    "\n",
    "    cm = pd.crosstab(yt, yp, dropna=False)              # rows=true names, cols=cluster ids\n",
    "    true_names = cm.index.tolist()\n",
    "    pred_ids   = cm.columns.tolist()\n",
    "    C = cm.to_numpy()\n",
    "\n",
    "    # pad to square for Hungarian\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:   Cpad = np.pad(C, ((0,0),(0,nT-nP)), 'constant')\n",
    "    elif nP > nT: Cpad = np.pad(C, ((0,nP-nT),(0,0)), 'constant')\n",
    "    else:         Cpad = C\n",
    "\n",
    "    r_idx, c_idx = linear_sum_assignment(-Cpad)\n",
    "    mapping = {}\n",
    "    correct = 0\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:\n",
    "            mapping[pred_ids[c]] = true_names[r]\n",
    "            correct += C[r, c]\n",
    "    acc = correct / len(yt)\n",
    "\n",
    "    # per-class recall/precision/F1\n",
    "    yp_named = yp.map(mapping)\n",
    "    rows = []\n",
    "    for name in true_names:\n",
    "        m_true  = (yt == name)\n",
    "        support = int(m_true.sum())\n",
    "        correct = int(((yt == name) & (yp_named == name)).sum())\n",
    "        predpos = int((yp_named == name).sum())\n",
    "        recall = correct / support if support else np.nan\n",
    "        prec   = correct / predpos if predpos else np.nan\n",
    "        f1     = 2*prec*recall/(prec+recall) if (prec and recall) else np.nan\n",
    "        rows.append(dict(category=name, support=support, correct=correct,\n",
    "                         accuracy_recall=recall, precision=prec, f1=f1))\n",
    "    per_class = pd.DataFrame(rows).sort_values(\"category\").reset_index(drop=True)\n",
    "    return per_class, mapping, acc, cm\n",
    "\n",
    "# 3) sweep random seeds with 3 clusters\n",
    "best_acc = -1.0\n",
    "best_model = None\n",
    "best_df = None\n",
    "best_mapping = None\n",
    "best_per_class = None\n",
    "best_sil = None\n",
    "\n",
    "N3 = len(Zs3)\n",
    "# sensible size bounds for 3 clusters (near-equal but flexible)\n",
    "approx = N3 // 3\n",
    "size_min = max(5, approx - 10)\n",
    "size_max = approx + 10\n",
    "\n",
    "for i in tqdm(range(2000), desc=\"K=3 constrained sweeps\"):\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=3,\n",
    "        size_min=size_min,\n",
    "        size_max=size_max,\n",
    "        random_state=i\n",
    "    )\n",
    "    labels = kmeans.fit_predict(Zs3)\n",
    "\n",
    "    sil = np.nan\n",
    "    try:\n",
    "        sil = silhouette_score(Zs3, labels)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cluster_df = pd.DataFrame({\"traj_id\": ids3, \"cluster\": labels})\n",
    "    per_class, mapping, acc_overall, cm = per_category_accuracy_3(y3, cluster_df.cluster.to_list())\n",
    "\n",
    "    if acc_overall > best_acc:\n",
    "        best_acc = acc_overall\n",
    "        best_model = kmeans\n",
    "        best_df = cluster_df.copy()\n",
    "        best_mapping = mapping\n",
    "        best_per_class = per_class.copy()\n",
    "        best_sil = sil\n",
    "        print(f\"new best acc={best_acc:.3f}\" )\n",
    "\n",
    "print(\"\\n=== BEST (3-class, no 'evac_short_in_zone') ===\")\n",
    "print(\"Overall accuracy:\", round(best_acc, 3))\n",
    "print(\"Cluster → label mapping:\", best_mapping)\n",
    "display(best_per_class)\n",
    "# best_df contains traj_id + cluster for the 3-class subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a66a4b-c51b-4432-ad25-8def77b14302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true_str: array-like of ground-truth strings (e.g., 'sip_home_grocery', ...)\n",
    "# labels:     predicted cluster ids (ints) from your chosen method/run\n",
    "labels  = best_df.cluster.to_list()\n",
    "per_class, mapping, acc_overall, cm = per_category_accuracy(y3, labels)\n",
    "print(\"Overall accuracy (after mapping):\", round(acc_overall, 3))\n",
    "print(\"Cluster→label mapping:\", mapping)\n",
    "display(per_class)\n",
    "# Optional: display(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22edae8-266b-445e-9800-9595efd71ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ee6ae-c552-4a54-9000-fce856375e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "# y3: ground-truth strings for the kept rows (len N3)\n",
    "# labels (or best_df['cluster']): predicted cluster IDs for the same rows (len N3)\n",
    "# mapping: dict {cluster_id -> class_name} from your Hungarian step on the 3-class subset\n",
    "\n",
    "gt = pd.Series(y3).astype(str).reset_index(drop=True)\n",
    "\n",
    "# predicted clusters aligned with y3\n",
    "if 'labels' in locals() and len(labels) == len(gt):\n",
    "    pred_clusters = pd.Series(labels).reset_index(drop=True)\n",
    "elif 'best_df' in locals() and len(best_df) == len(gt):\n",
    "    pred_clusters = best_df['cluster'].reset_index(drop=True)\n",
    "else:\n",
    "    raise ValueError(\"Provide 'labels' (np.array/list) aligned with y3, or 'best_df[\\\"cluster\\\"]'.\")\n",
    "\n",
    "mapping3 = mapping  # your cluster→class mapping returned earlier\n",
    "\n",
    "# map predicted cluster IDs -> 3-class names\n",
    "y_pred_names = pred_clusters.map(mapping3)\n",
    "\n",
    "# safety: ensure all clusters are mapped\n",
    "if y_pred_names.isna().any():\n",
    "    missing = sorted(pred_clusters[y_pred_names.isna()].unique().tolist())\n",
    "    raise ValueError(f\"Unmapped cluster IDs in mapping: {missing}\")\n",
    "\n",
    "# collapse to binary: 1=EVAC, 0=SIP\n",
    "to_bin = lambda s: 1 if str(s).lower().startswith(\"evac\") else 0\n",
    "y_true_bin = gt.map(to_bin).to_numpy()\n",
    "y_pred_bin = y_pred_names.map(to_bin).to_numpy()\n",
    "\n",
    "# confusion matrix & metrics\n",
    "C = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])\n",
    "cm_df = pd.DataFrame(C, index=[\"true:SIP(0)\",\"true:EVAC(1)\"], columns=[\"pred:SIP(0)\",\"pred:EVAC(1)\"])\n",
    "tn, fp, fn, tp = C.ravel()\n",
    "acc     = (tp + tn) / C.sum()\n",
    "bal_acc = balanced_accuracy_score(y_true_bin, y_pred_bin)\n",
    "mcc     = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
    "report  = classification_report(y_true_bin, y_pred_bin,\n",
    "                                labels=[0,1], target_names=[\"SIP(0)\",\"EVAC(1)\"],\n",
    "                                output_dict=True, zero_division=0)\n",
    "\n",
    "print(\"Cluster→class mapping used:\", mapping3)\n",
    "display(cm_df)\n",
    "print(f\"Overall accuracy:    {acc:.3f}\")\n",
    "print(f\"Balanced accuracy:   {bal_acc:.3f}\")\n",
    "print(f\"Matthews corr (MCC): {mcc:.3f}\")\n",
    "print(f\"SIP  — P:{report['SIP(0)']['precision']:.3f}  R:{report['SIP(0)']['recall']:.3f}  F1:{report['SIP(0)']['f1-score']:.3f}  (n={int(report['SIP(0)']['support'])})\")\n",
    "print(f\"EVAC — P:{report['EVAC(1)']['precision']:.3f}  R:{report['EVAC(1)']['recall']:.3f}  F1:{report['EVAC(1)']['f1-score']:.3f}  (n={int(report['EVAC(1)']['support'])})\")\n",
    "\n",
    "# Optional: attach to your table\n",
    "# best_df['gt_binary']   = y_true_bin\n",
    "# best_df['pred_binary'] = y_pred_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a82e44-5e73-4545-962d-1941ddcc8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from math import sqrt\n",
    "from scipy.stats import fisher_exact, chi2_contingency, binomtest\n",
    "\n",
    "# Inputs already computed above:\n",
    "# C            -> 2x2 confusion matrix with order [[TN, FP],[FN, TP]]\n",
    "# y_true_bin   -> 0=SIP, 1=EVAC\n",
    "# y_pred_bin   -> 0=SIP, 1=EVAC\n",
    "\n",
    "tn, fp, fn, tp = C.ravel()\n",
    "N = C.sum()\n",
    "acc = (tp + tn) / N\n",
    "sens = tp / (tp + fn) if (tp + fn) else np.nan  # EVAC recall\n",
    "spec = tn / (tn + fp) if (tn + fp) else np.nan  # SIP recall\n",
    "prev1 = (y_true_bin == 1).mean()\n",
    "prev0 = 1 - prev1\n",
    "maj_base = max(prev0, prev1)  # majority-class baseline accuracy\n",
    "\n",
    "def wilson(successes, n, alpha=0.05):\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    z = 1.959963984540054  # ~ N(0,1) 97.5% for 95% CI\n",
    "    p = successes / n\n",
    "    denom = 1 + z**2 / n\n",
    "    center = (p + z**2/(2*n)) / denom\n",
    "    half = (z * sqrt((p*(1-p) + z**2/(4*n)) / n)) / denom\n",
    "    return center - half, center + half\n",
    "\n",
    "acc_ci = wilson(tp + tn, N)\n",
    "sens_ci = wilson(tp, tp + fn) if np.isfinite(sens) else (np.nan, np.nan)\n",
    "spec_ci = wilson(tn, tn + fp) if np.isfinite(spec) else (np.nan, np.nan)\n",
    "\n",
    "# 1) Fisher's exact test (association)\n",
    "odds_ratio, p_fisher = fisher_exact([[tn, fp],[fn, tp]], alternative=\"two-sided\")\n",
    "\n",
    "# 2) Chi-square test of independence\n",
    "chi2, p_chi, dof, expected = chi2_contingency([[tn, fp],[fn, tp]], correction=False)\n",
    "\n",
    "# 3) Exact binomial tests on accuracy\n",
    "p_binom_vs_majority = binomtest(k=int(tp+tn), n=int(N), p=float(maj_base), alternative=\"greater\").pvalue\n",
    "p_binom_vs_half     = binomtest(k=int(tp+tn), n=int(N), p=0.5,             alternative=\"greater\").pvalue\n",
    "\n",
    "# 4) McNemar's test (exact, two-sided) on disagreements b=FP, c=FN\n",
    "b, c = fp, fn\n",
    "if (b + c) > 0:\n",
    "    # exact McNemar p-value via binomial\n",
    "    k = min(b, c)\n",
    "    from scipy.stats import binom\n",
    "    p_mcnemar = 2 * binom.cdf(k, b + c, 0.5)\n",
    "    p_mcnemar = min(1.0, p_mcnemar)\n",
    "else:\n",
    "    p_mcnemar = np.nan\n",
    "\n",
    "# ---- Print a tidy summary ----\n",
    "print(\"Counts:  TN={}, FP={}, FN={}, TP={}, N={}\".format(tn, fp, fn, tp, N))\n",
    "print(f\"Accuracy = {acc:.3f}  (95% CI {acc_ci[0]:.3f}–{acc_ci[1]:.3f})\")\n",
    "print(f\"Sensitivity (EVAC recall) = {sens:.3f}  (95% CI {sens_ci[0]:.3f}–{sens_ci[1]:.3f})\")\n",
    "print(f\"Specificity (SIP recall)  = {spec:.3f}  (95% CI {spec_ci[0]:.3f}–{spec_ci[1]:.3f})\\n\")\n",
    "\n",
    "print(f\"Fisher’s exact:  odds ratio={odds_ratio:.3g},  p={p_fisher:.4g}\")\n",
    "print(f\"Chi-square(1):   chi2={chi2:.3f},  p={p_chi:.4g}\")\n",
    "print(f\"Binomial test (acc > majority={maj_base:.3f}):  p={p_binom_vs_majority:.4g}\")\n",
    "print(f\"Binomial test (acc > 0.5):                     p={p_binom_vs_half:.4g}\")\n",
    "print(f\"McNemar’s exact (FP vs FN symmetry):           p={p_mcnemar:.4g}\")\n",
    "\n",
    "# Optional: a small DataFrame of the p-values\n",
    "pv = pd.DataFrame({\n",
    "    \"test\": [\"Fisher exact\", \"Chi-square\", \"Binomial vs majority\", \"Binomial vs 0.5\", \"McNemar exact\"],\n",
    "    \"p_value\": [p_fisher, p_chi, p_binom_vs_majority, p_binom_vs_half, p_mcnemar]\n",
    "})\n",
    "display(pv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d7dd5-d801-4fb0-9085-8d8e7477f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= BEST MODEL SELECTION ON BINARY (EVAC vs SIP) =========\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, matthews_corrcoef, silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats import fisher_exact, chi2_contingency, binom, binomtest\n",
    "\n",
    "# ---------- Inputs expected ----------\n",
    "#   y_true_str : GT strings for all rows (e.g., 'sip_home_grocery','evac_out_of_zone',...)\n",
    "#   Zs         : standardized features for all rows  (shape [N, d]); if you only have Z, do Zs = StandardScaler().fit_transform(Z)\n",
    "#   ids        : trajectory IDs aligned with rows\n",
    "#\n",
    "# If you already filtered to 3 classes earlier (y3, Zs3, ids3), set USE_SUBSET=True.\n",
    "USE_SUBSET  = True   # set False if you want to keep all 4 classes\n",
    "N_CLASSES   = 3      # 3 if you dropped 'evac_short_in_zone'; else 4\n",
    "KEEP_NAMES  = [\"evac_out_of_zone\", \"sip_home_grocery\", \"sip_hospital\"] if N_CLASSES==3 else None\n",
    "\n",
    "# ---------- Prep subset if requested ----------\n",
    "if USE_SUBSET:\n",
    "    keep = pd.Series(y_true_str).isin(KEEP_NAMES).to_numpy()\n",
    "    gt_names = pd.Series(y_true_str)[keep].astype(str).reset_index(drop=True)\n",
    "    X = np.asarray(Zs)[keep]\n",
    "    ids_used = pd.Series(ids)[keep].reset_index(drop=True)\n",
    "else:\n",
    "    gt_names = pd.Series(y_true_str).astype(str).reset_index(drop=True)\n",
    "    X = np.asarray(Zs)\n",
    "    ids_used = pd.Series(ids).reset_index(drop=True)\n",
    "\n",
    "N = len(gt_names)\n",
    "assert X.shape[0] == N, \"Feature rows must match y_true\"\n",
    "\n",
    "# Reasonable size bounds for constrained KMeans\n",
    "approx = N // N_CLASSES\n",
    "size_min = max(5, approx - 10)\n",
    "size_max = approx + 10\n",
    "\n",
    "# Binary collapse helper\n",
    "to_bin = lambda s: 1 if str(s).lower().startswith(\"evac\") else 0\n",
    "y_true_bin = gt_names.map(to_bin).to_numpy()\n",
    "\n",
    "# ---------- Sweep seeds and pick best by binary objective ----------\n",
    "best_tuple   = None   # lexicographic: (MCC, bal_acc, acc, -p_binom_vs_majority, sil)\n",
    "best_model   = None\n",
    "best_df      = None\n",
    "best_mapping = None\n",
    "best_cm_bin  = None\n",
    "best_report  = None\n",
    "best_stats   = None\n",
    "\n",
    "for seed in tqdm(range(5000), desc=f\"K={N_CLASSES} constrained sweeps (binary selection)\"):\n",
    "    # 1) fit constrained K-means\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=N_CLASSES,\n",
    "        size_min=20,\n",
    "        size_max=70,\n",
    "        random_state=seed\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # 2) Hungarian map: clusters -> class names (label-safe on crosstab)\n",
    "    cm_full = pd.crosstab(gt_names, pd.Series(labels, name=\"pred\"), dropna=False)\n",
    "    true_names = cm_full.index.tolist()\n",
    "    pred_ids   = cm_full.columns.tolist()\n",
    "    C = cm_full.to_numpy()\n",
    "\n",
    "    # pad to square\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:\n",
    "        Cpad = np.pad(C, ((0,0),(0,nT-nP)), 'constant')\n",
    "    elif nP > nT:\n",
    "        Cpad = np.pad(C, ((0,nP-nT),(0,0)), 'constant')\n",
    "    else:\n",
    "        Cpad = C\n",
    "\n",
    "    r_idx, c_idx = linear_sum_assignment(-Cpad)\n",
    "    mapping = {}\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:\n",
    "            mapping[pred_ids[c]] = true_names[r]\n",
    "\n",
    "    # 3) Map predictions to names, then to binary\n",
    "    y_pred_names = pd.Series(labels).map(mapping)\n",
    "    # if any unmapped cluster sneaks in, treat as SIP (conservative)\n",
    "    y_pred_names = y_pred_names.fillna(\"sip_unknown\")\n",
    "    y_pred_bin = y_pred_names.map(to_bin).to_numpy()\n",
    "\n",
    "    # 4) Binary confusion & metrics\n",
    "    C2 = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])\n",
    "    tn, fp, fn, tp = C2.ravel()\n",
    "    N2 = C2.sum()\n",
    "    acc = (tp + tn) / N2\n",
    "    bal_acc = balanced_accuracy_score(y_true_bin, y_pred_bin)\n",
    "    mcc = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
    "\n",
    "    # p-values\n",
    "    # Fisher / Chi-square on 2x2\n",
    "    try:\n",
    "        _, p_fisher = fisher_exact([[tn, fp],[fn, tp]], alternative=\"two-sided\")\n",
    "    except Exception:\n",
    "        p_fisher = np.nan\n",
    "    try:\n",
    "        _, p_chi, _, _ = chi2_contingency([[tn, fp],[fn, tp]], correction=False)\n",
    "    except Exception:\n",
    "        p_chi = np.nan\n",
    "\n",
    "    # Binomial test vs majority baseline\n",
    "    prev1 = (y_true_bin == 1).mean()\n",
    "    prev0 = 1 - prev1\n",
    "    maj_base = float(max(prev0, prev1))\n",
    "    p_binom_vs_maj = binomtest(k=int(tp+tn), n=int(N2), p=maj_base, alternative=\"greater\").pvalue\n",
    "\n",
    "    # McNemar exact\n",
    "    b, c = fp, fn\n",
    "    if (b + c) > 0:\n",
    "        p_mcnemar = 2 * binom.cdf(min(b, c), b + c, 0.5)\n",
    "        p_mcnemar = float(min(1.0, p_mcnemar))\n",
    "    else:\n",
    "        p_mcnemar = np.nan\n",
    "\n",
    "    # silhouette (can fail with degenerate splits)\n",
    "    try:\n",
    "        sil = float(silhouette_score(X, labels))\n",
    "    except Exception:\n",
    "        sil = float(\"nan\")\n",
    "\n",
    "    # objective tuple (maximize first elements, minimize p-value via negative)\n",
    "    score_tuple = (float(mcc), float(bal_acc), float(acc), -float(p_binom_vs_maj), float(sil))\n",
    "\n",
    "    if (best_tuple is None) or (score_tuple > best_tuple):\n",
    "        best_tuple   = score_tuple\n",
    "        best_model   = kmeans\n",
    "        best_df      = pd.DataFrame({\"traj_id\": ids_used, \"cluster\": labels, \"pred_name\": y_pred_names})\n",
    "        best_mapping = mapping.copy()\n",
    "        best_cm_bin  = pd.DataFrame(C2, index=[\"true:SIP(0)\",\"true:EVAC(1)\"], columns=[\"pred:SIP(0)\",\"pred:EVAC(1)\"])\n",
    "        # build a small report dict\n",
    "        best_stats = {\n",
    "            \"acc\": acc, \"balanced_acc\": bal_acc, \"mcc\": mcc,\n",
    "            \"p_fisher\": p_fisher, \"p_chi\": p_chi,\n",
    "            \"p_binom_vs_majority\": p_binom_vs_maj,\n",
    "            \"p_mcnemar\": p_mcnemar,\n",
    "            \"silhouette\": sil,\n",
    "            \"objective_tuple\": score_tuple,\n",
    "        }\n",
    "        print(f\"new BEST — MCC={mcc:.3f}, bal_acc={bal_acc:.3f}, acc={acc:.3f}, p(bin>maj)={p_binom_vs_maj:.2e}, sil={sil:.3f}\")\n",
    "\n",
    "# ---------- Summary ----------\n",
    "print(\"\\n=== BEST MODEL (binary selection) ===\")\n",
    "print(\"Cluster → class mapping:\", best_mapping)\n",
    "display(best_cm_bin)\n",
    "print(\"Metrics:\", {k: (round(v,3) if isinstance(v, (int,float)) and np.isfinite(v) else v) for k,v in best_stats.items()})\n",
    "# best_model     -> the fitted KMeansConstrained instance\n",
    "# best_df        -> DataFrame with traj_id, cluster, and mapped class name for the kept rows\n",
    "# best_mapping   -> dict {cluster_id: class_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d82ac-aeeb-42d3-a003-d8088a95057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_distribution = cluster_df.merge(\n",
    "    clean_joined,            # the table with your new columns\n",
    "    on=\"traj_id\",          # column to join on\n",
    "    how=\"right\",          # keep all rows in clean_joined\n",
    "    #validate=\"1:1\"       # optional: check that df_final.GEOID is unique\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e7a8a-0e4e-4287-af99-6ce92b66626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of the min pt_idx for each traj_id\n",
    "idx = ses_distribution.groupby(\"traj_id\")[\"pt_idx\"].idxmin()\n",
    "\n",
    "# select only those rows\n",
    "ses_first_pts = ses_distribution.loc[idx].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40b3ba-8614-4466-bc23-508e5ee958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = ses_distribution.groupby(\"traj_id\")\n",
    "\n",
    "# mean income\n",
    "mean_inc = grp[\"med_income\"].mean()\n",
    "\n",
    "# mode income (most‐frequent); take the first mode if there’s a tie\n",
    "mode_inc = grp[\"med_income\"] \\\n",
    "    .agg(lambda x: x.mode().iat[0] if not x.mode().empty else x.iloc[0])\n",
    "\n",
    "# cluster label (each traj has a single cluster)\n",
    "cluster_lbl = grp[\"cluster\"].first()\n",
    "\n",
    "# assemble\n",
    "df_traj = pd.DataFrame({\n",
    "    \"cluster\": cluster_lbl,\n",
    "    \"mean_income\": mean_inc,\n",
    "    \"mode_income\": mode_inc\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb5c92-e130-4385-bfb5-7991a6c40296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for cl in sorted(df_traj[\"cluster\"].unique()):\n",
    "    vals = df_traj.loc[df_traj[\"cluster\"] == cl, \"mean_income\"]\n",
    "    plt.hist(vals, bins=100, density=True, alpha=0.5, label=f\"Cluster {cl}\")\n",
    "\n",
    "plt.xlabel(\"Average Median Income per Trajectory\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Mean Income by Cluster\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a1df8-d0fd-459e-abb5-78a1e8da8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for cl in sorted(df_traj[\"cluster\"].unique()):\n",
    "    vals = df_traj.loc[df_traj[\"cluster\"] == cl, \"mode_income\"]\n",
    "    plt.hist(vals, bins=100, density=True, alpha=0.5, label=f\"Cluster {cl}\")\n",
    "\n",
    "plt.xlabel(\"Modal Median Income per Trajectory\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Mode Income by Cluster\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874eb89-3ce5-4fd4-8481-4b826ababb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Assuming df_traj exists with columns 'cluster', 'mean_income', 'mode_income'\n",
    "clusters = sorted(df_traj['cluster'].unique())\n",
    "\n",
    "# 1. KDE plot for mean_income\n",
    "x_mean = df_traj['mean_income']\n",
    "x_min, x_max = x_mean.min(), x_mean.max()\n",
    "x_grid = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in clusters:\n",
    "    data = df_traj.loc[df_traj['cluster'] == cl, 'mean_income']\n",
    "    kde = gaussian_kde(data)\n",
    "    plt.plot(x_grid, kde(x_grid), label=f'Cluster {cl}')\n",
    "\n",
    "plt.xlabel('Average Median Income per Trajectory')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KDE of Mean Income by Cluster')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. KDE plot for mode_income\n",
    "x_mode = df_traj['mode_income']\n",
    "x_min, x_max = x_mode.min(), x_mode.max()\n",
    "x_grid = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in clusters:\n",
    "    data = df_traj.loc[df_traj['cluster'] == cl, 'mode_income']\n",
    "    kde = gaussian_kde(data)\n",
    "    plt.plot(x_grid, kde(x_grid), label=f'Cluster {cl}')\n",
    "\n",
    "plt.xlabel('Modal Median Income per Trajectory')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KDE of Mode Income by Cluster')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a157cb-ac4e-467c-a260-d5633fd25be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_first_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233c3fa-e053-4693-aa57-f6c40aba59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e0941-1ebf-455d-91bb-6aa7f28c3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_first_pts['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789ecef-735e-4e42-ab69-e59d350d12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your GeoDataFrame with first points is named `ses_first_pts`\n",
    "# and contains columns 'cluster' and 'med_income'.\n",
    "colors = [\"green\",\"blue\",\"yellow\",\"red\",\"purple\",\"orange\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in sorted(ses_first_pts['cluster'].unique()):\n",
    "    plt.hist(\n",
    "        ses_first_pts.loc[ses_first_pts['cluster'] == cl, 'med_income'],\n",
    "        bins=90,\n",
    "        alpha=0.9,\n",
    "        density = True,\n",
    "        label=f'Cluster {cl}',\n",
    "        color=colors[cl]\n",
    "    )\n",
    "\n",
    "plt.xlabel('Median Household Income')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Median Income by Cluster')\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c2735-fb5d-44fb-9d8b-c48886eb8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import LineString\n",
    "import random\n",
    "centroids_aea = gpd.GeoSeries(\n",
    "    clean_joined['centroid'].values,\n",
    ")\n",
    "\n",
    "# 2) Reproject that GeoSeries to EPSG:4326\n",
    "centroids_wgs = centroids_aea.to_crs(epsg=4326)\n",
    "\n",
    "# 3) Overwrite the old column (or make a new one)\n",
    "clean_joined['centroid'] = centroids_wgs.values\n",
    "\n",
    "centroids_aea = gpd.GeoSeries(\n",
    "    ses_gdf['centroid'].values,\n",
    ")\n",
    "\n",
    "# 2) Reproject that GeoSeries to EPSG:4326\n",
    "centroids_wgs = centroids_aea.to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "ses_gdf['centroid'] = centroids_wgs.values\n",
    "# 4) If you also want your polygons in 4326, do that too:\n",
    "clean_joined = clean_joined.to_crs(epsg=4326)\n",
    "# ─── 2) Randomly sample N trajectories ───────────────────────────────────────\n",
    "N = 50\n",
    "all_ids    = clean_joined['traj_id'].unique().tolist()\n",
    "sample_ids = random.sample(all_ids, k=N)\n",
    "\n",
    "# ─── 3) Build the sample_gdf ──────────────────────────────────────────────────\n",
    "sample_lines = []\n",
    "for tid in sample_ids:\n",
    "    sub = (\n",
    "        clean_joined[ clean_joined['traj_id'] == tid ]\n",
    "          .sort_values('pt_idx')\n",
    "    )\n",
    "    pts = [\n",
    "        ses_gdf.at[int(h), 'centroid']\n",
    "        for h in sub['index_right'].dropna().astype(int)\n",
    "    ]\n",
    "    if len(pts) > 1:\n",
    "        sample_lines.append({\n",
    "            'traj_id': tid,\n",
    "            'geometry': LineString(pts)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816ce34-a873-41a9-aba1-cea81187d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5b6ce-f07f-4341-b73b-2d10075abfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcf31a-4709-494e-ac13-32f9615aee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "states = gpd.read_file('cb_2018_us_state_500k.shp')\n",
    "df = clean_joined.copy()\n",
    "\n",
    "# ── 0) Utility to pick top‐m trajectories per cluster by proximity in Z-space\n",
    "def find_representative_trajectories(Z, labels, traj_ids, centers, m=50):\n",
    "    reps = {}\n",
    "    K = centers.shape[0]\n",
    "\n",
    "    for c in tqdm(range(K)):\n",
    "        idx_c = np.where(labels == c)[0]          # positions in Z for cluster c\n",
    "        Zc    = Z[idx_c]\n",
    "        dists = np.linalg.norm(Zc - centers[c], axis=1)\n",
    "        order = np.argsort(dists)[: min(m, len(dists))]\n",
    "\n",
    "        # use .iloc to get by *position*\n",
    "        reps[c] = traj_ids.iloc[idx_c[order]].tolist()\n",
    "\n",
    "    return reps\n",
    "m = 100\n",
    "# ── 1) Compute representatives (50 per cluster)\n",
    "#    MAKE SURE Z, labels, ds.ids, and kmeans.cluster_centers_ are in scope\n",
    "representatives = find_representative_trajectories(\n",
    "    Z, labels, clean_joined.traj_id, kmeans.cluster_centers_, m\n",
    ")\n",
    "\n",
    "# ── 2) Merge cluster labels into your point‐level table\n",
    "joined = df.merge(cluster_df, on=\"traj_id\", how=\"left\")\n",
    "\n",
    "# ── 3) Build LineStrings for the representative traj_ids\n",
    "traj_lines = []\n",
    "for cl, tid_list in tqdm(representatives.items()):\n",
    "    for tid in tqdm(tid_list):\n",
    "        sub = joined[joined[\"traj_id\"] == tid].sort_values(\"pt_idx\")\n",
    "        pts = [\n",
    "            ses_gdf.at[int(h), \"centroid\"]\n",
    "            for h in sub[\"index_right\"].dropna().astype(int)\n",
    "        ]\n",
    "        if len(pts) >= 2:\n",
    "            traj_lines.append({\n",
    "                \"traj_id\": tid,\n",
    "                \"cluster\": cl,\n",
    "                \"geometry\": LineString(pts)\n",
    "            })\n",
    "\n",
    "traj_lines_gdf = gpd.GeoDataFrame(\n",
    "    traj_lines,\n",
    "    geometry=\"geometry\",\n",
    "    crs=ses_gdf.crs\n",
    ")\n",
    "\n",
    "# ── 4) Prepare output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f181a4-59e3-4365-8eac-171cb0a76f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined['vec_weighted_avg'] = clean_joined['vec_weighted_avg'].apply(fill_vec)\n",
    "cj = (\n",
    "    clean_joined\n",
    "      .merge(\n",
    "         traj_lines_gdf[['traj_id','cluster']],\n",
    "         on='traj_id',\n",
    "         how='left'\n",
    "  )\n",
    ")\n",
    "cj\n",
    "# 2) Now pick your cluster i and time‐step t\n",
    "cluster_i = 2\n",
    "time_t    = 143\n",
    "\n",
    "sub = cj[\n",
    "    (cj['cluster'] == cluster_i) &\n",
    "    (cj['pt_idx']   == time_t)\n",
    "]\n",
    "\n",
    "vectors_by_t = {}\n",
    "for t in sorted(cj['pt_idx'].unique()):\n",
    "    part = cj[(cj['cluster']==cluster_i)&(cj['pt_idx']==t)]\n",
    "    vectors_by_t[t] = (\n",
    "        np.vstack(part['vec_weighted_avg'].tolist())\n",
    "        if not part.empty\n",
    "        else np.zeros((0, emb_dim))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c43d28-317d-433c-97a3-51fd6eeeace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ─── CONFIGURATION ─────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "k      = 10       # number of logits to sum\n",
    "T      = 2.0      # temperature (unused if =1)\n",
    "K      = 3        # number of clusters\n",
    "\n",
    "# outputs\n",
    "df_counts_by_cluster     = {}\n",
    "df_counts_cat_by_cluster = {}\n",
    "\n",
    "# ─── MAIN LOOP ─────────────────────────────────────────────────────────────\n",
    "for cluster_i in range(K):\n",
    "    # 1) select all POIs in this cluster\n",
    "    cluster_data = cj[cj['cluster'] == cluster_i]\n",
    "    counts_by_t  = {}\n",
    "\n",
    "    # 2) no grads needed\n",
    "    with torch.no_grad():\n",
    "        # 3) loop over each distinct time‐step\n",
    "        for t in sorted(cluster_data['pt_idx'].unique()):\n",
    "            sub = cluster_data[cluster_data['pt_idx'] == t]\n",
    "            if sub.empty:\n",
    "                counts_by_t[t] = {}   # empty hour\n",
    "                continue\n",
    "\n",
    "            # 4) stack embeddings and push to device\n",
    "            arr = np.stack(sub['vec_weighted_avg'].values).astype(np.float32)  # (n_traj, D)\n",
    "            X   = torch.from_numpy(arr).to(device)\n",
    "\n",
    "            # 5) run only the head to get logits\n",
    "            logits = bottleneck_model.head(X)  # (n_traj, n_classes)\n",
    "            if t%100 == 0:\n",
    "                print(logits.shape)\n",
    "            probs = torch.softmax(logits,axis=1)\n",
    "\n",
    "            # 6) pick the top-k logits per POI\n",
    "            topk_vals, topk_idx = probs.topk(k, dim=1)  # both are (n_traj, k)\n",
    "            topk_vals = topk_vals.cpu().numpy()\n",
    "            topk_idx  = topk_idx.cpu().numpy()\n",
    "\n",
    "            # 7) sum those logits into a per-class accumulator\n",
    "            agg = {}\n",
    "            for idx_row, val_row in zip(topk_idx, topk_vals):\n",
    "                for cls, score in zip(idx_row, val_row):\n",
    "                    agg[cls] = agg.get(cls, 0.0) + float(score)\n",
    "\n",
    "            counts_by_t[t] = agg\n",
    "\n",
    "    # ─── Build DataFrame of raw sums ────────────────────────────────\n",
    "    df_counts = (\n",
    "        pd.DataFrame.from_dict(counts_by_t, orient='index')\n",
    "          .fillna(0.0)\n",
    "    )\n",
    "    df_counts.index.name = 'pt_idx'\n",
    "\n",
    "    # rename numeric class‐indices → the string labels\n",
    "    df_counts.columns = [classes[int(c)] for c in df_counts.columns]\n",
    "\n",
    "    # ─── Collapse subcategories to top‐level categories ─────────────\n",
    "    col2cat = df_counts.columns.map(lambda s: s.split('[sep]')[0])\n",
    "    df_counts_cat = df_counts.groupby(col2cat, axis=1).sum()\n",
    "\n",
    "    # ─── Store for later use ─────────────────────────────────────────\n",
    "    df_counts_by_cluster[cluster_i]     = df_counts\n",
    "    df_counts_cat_by_cluster[cluster_i] = df_counts_cat\n",
    "\n",
    "# ─── Now df_counts_by_cluster[i] is the raw summed-logit table for cluster i\n",
    "#     and df_counts_cat_by_cluster[i] is the same collapsed to categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da279-603e-48ee-a1ea-8d0608fec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "global_counts = reduce(\n",
    "    lambda a, b: a.add(b, fill_value=0),\n",
    "    df_counts_cat_by_cluster.values()\n",
    ")\n",
    "\n",
    "# 2. (Optional) fill any NaNs just in case\n",
    "global_counts = global_counts.fillna(0)\n",
    "\n",
    "# 3. If you want the baseline **proportions** (summing across categories at each time step):\n",
    "global_df = global_counts.div(global_counts.sum(axis=1).replace(0, 1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185eeb1-13c1-491e-aa79-b04ef40c6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm, ListedColormap\n",
    "from functools import reduce\n",
    "\n",
    "# --- Prepare colormap & cluster list ---\n",
    "base_cmap     = plt.cm.get_cmap('bwr', 256)\n",
    "base_colors   = base_cmap(np.linspace(0, 1, 256))\n",
    "base_colors[len(base_colors)//2] = [1,1,1,1]          # white at zero\n",
    "cmap_white_center = ListedColormap(base_colors)\n",
    "\n",
    "clusters      = sorted(df_counts_cat_by_cluster.keys())  # e.g. [0,1,2]\n",
    "\n",
    "# pick the same top-categories for all\n",
    "df0     = df_counts_cat_by_cluster[clusters[0]]\n",
    "top6    = df0.sum(axis=0).nlargest(6).index.tolist()\n",
    "_, top5 = top6[0], top6[1:]  # drop the first if desired\n",
    "\n",
    "# --- Make a 3×1 grid, figsize 10×9 ---\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=4, ncols=1,\n",
    "    figsize=(8, 5),\n",
    "    sharex=True,       # align time axis\n",
    "    sharey=False,      # each subplot draws its own y‐labels\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "all_im = None\n",
    "for ax, cluster_i in zip(axes, clusters):\n",
    "    # compute Δ% for this cluster\n",
    "    df_cat      = df_counts_cat_by_cluster[cluster_i][top5].sort_index()\n",
    "    df_norm     = df_cat.div(df_cat.sum(axis=1).replace(0,1), axis=0)\n",
    "    glob_sel    = global_df[top5]\n",
    "    global_norm = glob_sel.div(glob_sel.sum(axis=1).replace(0,1), axis=0)\n",
    "\n",
    "    df_diff = (df_norm - global_norm) * 100\n",
    "    mx      = np.abs(df_diff.values).max()\n",
    "    norm    = TwoSlopeNorm(vmin=-mx, vcenter=0, vmax=mx)\n",
    "\n",
    "    im = ax.imshow(\n",
    "        df_diff.T.values,\n",
    "        cmap=cmap_white_center,\n",
    "        norm=norm,\n",
    "        aspect='auto',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    all_im = im\n",
    "\n",
    "    # **always** draw y‐labels\n",
    "    ax.set_yticks(np.arange(len(top5)))\n",
    "    ax.set_yticklabels(top5, fontsize=6,)\n",
    "\n",
    "    # x‐axis ticks only on bottom subplot\n",
    "    ax.set_xticks(np.arange(len(df_diff.index))[::10])\n",
    "    ax.set_xticklabels(df_diff.index[::10], rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.grid(False)\n",
    "    ax.set_title(f\"Cluster {cluster_i}\", fontsize=12)\n",
    "\n",
    "# common x‐label\n",
    "axes[-1].set_xlabel(\"Time Step\", fontsize=10)\n",
    "\n",
    "# shared colorbar on the right\n",
    "cbar = fig.colorbar(\n",
    "    all_im,\n",
    "    ax=axes,\n",
    "    orientation='vertical',\n",
    "    fraction=0.02,\n",
    "    pad=0.03\n",
    ")\n",
    "cbar.set_label(\"Δ% (Cluster — Global)\", fontsize=10)\n",
    "\n",
    "plt.savefig(\"./cluster_results/SES_combined_heatmaps_3x1_with_ylab.png\", dpi=200)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60449bf-6b80-4f6a-9ac6-910d6c4eb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def find_representative_trajectories_as_arrays(Z, labels, centers, m=750):\n",
    "    \"\"\"\n",
    "    Finds the top 'm' representative trajectories from each cluster and returns\n",
    "    their embeddings and labels as NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        Z (np.ndarray): The full array of latent embeddings.\n",
    "        labels (np.ndarray): The cluster assignment for each embedding in Z.\n",
    "        centers (np.ndarray): The cluster centroid vectors from KMeans.\n",
    "        m (int): The number of representative trajectories to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (Z_representatives, labels_representatives)\n",
    "               - Z_representatives: A NumPy array of the stacked representative embeddings.\n",
    "               - labels_representatives: A NumPy array of the corresponding cluster labels.\n",
    "    \"\"\"\n",
    "    representative_vectors_list = []\n",
    "    representative_labels_list = []\n",
    "    \n",
    "    K = centers.shape[0] # Total number of clusters\n",
    "\n",
    "    for c in tqdm(range(K), desc=\"Finding Representatives per Cluster\"):\n",
    "        # Find the original indices of all members belonging to the current cluster 'c'\n",
    "        original_indices_for_cluster_c = np.where(labels == c)[0]\n",
    "        \n",
    "        # If the cluster is empty, skip it\n",
    "        if len(original_indices_for_cluster_c) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get the latent vectors for this cluster\n",
    "        Zc = Z[original_indices_for_cluster_c]\n",
    "        \n",
    "        # Calculate the Euclidean distance of each member to the cluster's centroid\n",
    "        dists = np.linalg.norm(Zc - centers[c], axis=1)\n",
    "        \n",
    "        # Get the indices of the 'm' closest members *within this cluster*\n",
    "        num_to_select = min(m, len(dists))\n",
    "        closest_indices_within_cluster = np.argsort(dists)[:num_to_select]\n",
    "        \n",
    "        # Use these local indices to find the original indices in the global Z array\n",
    "        original_indices_of_reps = original_indices_for_cluster_c[closest_indices_within_cluster]\n",
    "        \n",
    "        # Select the representative vectors from the original Z array\n",
    "        representative_vectors = Z[original_indices_of_reps]\n",
    "        \n",
    "        # Create the corresponding labels for these representatives\n",
    "        representative_labels = np.full(num_to_select, c)\n",
    "        \n",
    "        # Append the results to our lists\n",
    "        representative_vectors_list.append(representative_vectors)\n",
    "        representative_labels_list.append(representative_labels)\n",
    "        \n",
    "    # Concatenate all the collected vectors and labels into single NumPy arrays\n",
    "    if not representative_vectors_list:\n",
    "        # Handle case where no representatives were found (e.g., all clusters were empty)\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    Z_representatives = np.vstack(representative_vectors_list)\n",
    "    labels_representatives = np.concatenate(representative_labels_list)\n",
    "    \n",
    "    return Z_representatives, labels_representatives\n",
    "\n",
    "# --- How to use the new function ---\n",
    "\n",
    "# Assume Z, labels, and kmeans.cluster_centers_ are already defined from your clustering\n",
    "# Z = Full embedding matrix\n",
    "# labels = Full labels array from KMeans\n",
    "# kmeans = your fitted KMeans model object\n",
    "\n",
    "m = 500\n",
    "print(f\"Selecting top {m} representative trajectories from each cluster...\")\n",
    "\n",
    "# Call the new function to get the data in the desired format\n",
    "Z_reps, labels_reps = find_representative_trajectories_as_arrays(\n",
    "    Z, \n",
    "    labels, \n",
    "    kmeans.cluster_centers_, \n",
    "    m=m\n",
    ")\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n--- Conversion Complete ---\")\n",
    "print(f\"Shape of Z_reps (representative embeddings): {Z_reps.shape}\")\n",
    "print(f\"Shape of labels_reps (representative labels): {labels_reps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00993-d6c5-477a-9d41-c92fdaf7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans # For generating sample data\n",
    "from sklearn.datasets import make_blobs # For generating sample data\n",
    "\n",
    "# --- For Demonstration: Create Sample Data ---\n",
    "# In your actual code, you will use your real 'Z' and 'labels' from KMeans.\n",
    "# Z = a NumPy array of your latent embeddings, shape (n_samples, n_features)\n",
    "# labels = the result of km.labels_, shape (n_samples,)\n",
    "print(\"Generating sample data for demonstration...\")\n",
    "\n",
    "print(\"Sample data generated.\")\n",
    "# Replace Z_sample and labels_sample with your actual data below\n",
    "# --- End of Sample Data Generation ---\n",
    "\n",
    "\n",
    "# 1. Run t-SNE to reduce dimensions\n",
    "# Perplexity is a key hyperparameter; typical values are between 5 and 50.\n",
    "# It's related to the number of nearest neighbors considered for each point.\n",
    "print(\"Running t-SNE... (this may take a moment)\")\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=20,\n",
    "    n_iter=5000,\n",
    "    random_state=42,\n",
    "    init='pca',\n",
    "    learning_rate='auto'\n",
    ")\n",
    "tsne_results = tsne.fit_transform(Z_reps)\n",
    "print(\"t-SNE finished.\")\n",
    "\n",
    "# 2. Create a DataFrame for easy plotting with Seaborn\n",
    "tsne_df = pd.DataFrame({\n",
    "    'tsne_1': tsne_results[:, 0],\n",
    "    'tsne_2': tsne_results[:, 1],\n",
    "    'cluster': labels_reps # Add the cluster labels from your KMeans result\n",
    "})\n",
    "# Make cluster labels categorical for better legend labels\n",
    "tsne_df['cluster'] = tsne_df['cluster'].astype('category')\n",
    "\n",
    "# 3. Plot the results using Seaborn\n",
    "print(\"Generating plot...\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tsne_df,\n",
    "    x='tsne_1',\n",
    "    y='tsne_2',\n",
    "    hue='cluster', # Color points by their assigned cluster\n",
    "    palette=sns.color_palette(\"deep\", n_colors=4), # Use a distinct color palette\n",
    "    s=50,          # Marker size\n",
    "    alpha=0.6,     # Marker transparency\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Customize the plot for clarity\n",
    "#ax.set_title('t-SNE Visualization of Trajectory Clusters', fontsize=20, pad=15)\n",
    "ax.set_xlabel('t-SNE Dimension 1', fontsize=14)\n",
    "ax.set_ylabel('t-SNE Dimension 2', fontsize=14)\n",
    "ax.legend(title='Cluster', fontsize=12, title_fontsize=14)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure in high resolution\n",
    "output_filename = \"tsne_cluster_visualization_3_flat.png\"\n",
    "plt.savefig(output_filename, dpi=300)\n",
    "print(f\"Plot saved successfully to {output_filename}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13362556-d40d-48e7-86ed-aa30fb2bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for x, mask, _ in tqdm(train_loader):\n",
    "        # x: (B, T, F); mask: (B, T) with 1=data, 0=noise\n",
    "        x = x.cuda()\n",
    "        mask = mask.cuda()\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # no need to clamp lengths—mask tells us directly\n",
    "        Lmax = int(mask.sum(dim=1).max().item())  # longest real seq in this batch\n",
    "\n",
    "        # get latent dim D by a quick forward on just t=0\n",
    "        _, z0 = model(x[:, :1, :], torch.ones(B, dtype=torch.long).cuda())\n",
    "        D = z0.shape[1]\n",
    "\n",
    "        Z_batch = torch.zeros(B, D, T, device=\"cpu\")\n",
    "\n",
    "        for t in tqdm(range(Lmax)):\n",
    "            # which trajectories are alive at time t?\n",
    "            active = (mask[:, t] == 1).nonzero(as_tuple=True)[0]\n",
    "            if len(active) == 0:\n",
    "                break\n",
    "\n",
    "            # mask-out future steps for just the active ones\n",
    "            x_sub = x[active].clone()\n",
    "            if t+1 < T:\n",
    "                x_sub[:, t+1:, :] = 0\n",
    "\n",
    "            # compute true lengths up to t for pack_padded_sequence\n",
    "            lengths_sub = mask[active, : t+1].sum(dim=1)\n",
    "\n",
    "            # forward only that subset\n",
    "            _, z_sub = model(x_sub, lengths_sub)\n",
    "            Z_batch[active.cpu(), :, t] = z_sub.cpu()\n",
    "\n",
    "        zs.append(Z_batch)\n",
    "\n",
    "# stitch batches → (num_traj, D, T)\n",
    "Z3 = torch.cat(zs, dim=0).numpy()\n",
    "print(\"Z3 shape:\", Z3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864fb74-4b9f-4152-8d9e-4d562d788541",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"GEOID_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d1fc3-0743-4a9b-a4e3-2286e67ba247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely.wkb\n",
    "import geopandas as gpd\n",
    "clean_joined = pd.read_parquet(\"GEOID_SES_point.parquet\")\n",
    "df = clean_joined.copy()\n",
    "df['geometry'] = df['geometry'].apply(lambda wkb: shapely.wkb.loads(wkb))\n",
    "clean_joined = gpd.GeoDataFrame(df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344a31b-474f-4b8c-902c-f4023827b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"GEOID_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bd89f-ce40-43cb-8a11-a20d3c429d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f50c5-4fed-4293-a39c-b6fda2498794",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[9176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad8c4b-2011-448d-9fe8-d678e4fd81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bf616-49ae-4a53-b7bd-7f8802225f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#64 Dimension Latent Space vector <-> label (SES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5b52f-b022-4c36-816f-d485103dc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"POI_encoded_embeddings.parquet\").isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e65c1-3bce-44d1-ae04-3bad7ba5611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"feature_dict.pkl\", 'rb') as f:\n",
    "    feature_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b64dd2-d708-4390-8173-150897c6778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict['0000a204849023cd902b8c7dd9edc37b8bbc222edbe6620b26b852a3e24b317c'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8d67c-0062-4a10-adc7-9709e2a9e703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44655227-6bbf-4696-98ba-8dd8dbb0f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('hurricane_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50389b-8f08-4750-ac40-9faf89b64492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9be805-9a1c-43d5-8187-db0e6e7171e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load your hurricane matrix and set the ID column as index\n",
    "df = pd.read_csv(\"hurricane_matrix.csv\")\n",
    "df = df.set_index(\"Unnamed: 0\")   # now df.index are the POI‐IDs\n",
    "\n",
    "# 3) Replace coordinates with embeddings, in place\n",
    "for poi_id, emb in feature_dict.items():\n",
    "    # emb has shape (n_steps, 128)\n",
    "    if poi_id not in df.index:\n",
    "        # safety check\n",
    "        continue\n",
    "\n",
    "    row = df.loc[poi_id]\n",
    "    # Which columns have actual coordinates?\n",
    "    valid_cols = row.index[row.notna()]     # Index of columns where row[col] != NaN\n",
    "\n",
    "    # Sanity check\n",
    "    assert emb.shape[0] == len(valid_cols), (\n",
    "        f\"POI {poi_id}: found {len(valid_cols)} data columns, \"\n",
    "        f\"but embedding has {emb.shape[0]} rows\"\n",
    "    )\n",
    "\n",
    "    # Overwrite each non‐NaN cell with the corresponding embedding vector\n",
    "    for i, col in enumerate(valid_cols):\n",
    "        df.at[poi_id, col] = emb[i]    # emb[i] is a length‐128 numpy array\n",
    "\n",
    "# Now df’s cells are either NaN or a length‐128 ndarray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e1191-5ff3-405f-bdc5-a506bcf53105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"POI_embedding_matrix_missing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f527514-ab7f-4afe-b29e-b182cbd9e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8e612-7924-49ba-978f-ea58bddff8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = missing_count.dropna().astype(int)     # convert to int if needed\n",
    "uniques = np.sort(data.unique())\n",
    "\n",
    "# create edges that center each integer in its own bin\n",
    "edges = np.concatenate([uniques - 0.5, [uniques[-1] + 0.5]])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data, bins=edges, rwidth=0.8)\n",
    "plt.xticks(uniques)               # show one tick per unique value\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram with One Bin per Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa0628-6973-482a-8f1c-fce87e7b42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = missing_count.dropna().value_counts()\n",
    "\n",
    "# 2. Bar plot\n",
    "ax = counts.plot(kind=\"bar\", width=0.8)\n",
    "ax.set_xlabel(\"Value\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Frequency of Each Unique Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b49749-f770-42b0-99d2-43950e33554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"POI_embedding_matrix_missing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a616ae-edf9-4d6f-ad71-4907c086a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df.isna().sum()/95000, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4756a-86a5-4e27-8e40-6c0e8a175bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"geometry\"]= gpd.GeoSeries.from_wkb(df_final[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc6984-284a-4442-b2a7-0728af0ea488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589709-344a-464b-bd4d-95004ee44ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traj_latent = pd.read_parquet(\"Full_latent_emb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2cbea-8e5a-49f8-a72d-53cb447048b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traj_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794180fb-f435-475b-bd53-8764e9a7d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Traj_latent.drop(columns=\"cluster\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a982754-ccd6-4c9a-a489-9d3868bd3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689dcfa6-fe21-4e06-b8fe-0a9a3e748a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d95dc-f41e-46c5-90ca-6f728bb3a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_buffer = point_gdf.to_crs(epsg=5070)\n",
    "ses_buffer = ses_gdf.to_crs(epsg=5070)\n",
    "ses_buffer[\"centroid\"] = ses_buffer.centroid\n",
    "ses_gdf = ses_buffer.to_crs(epsg=4326)\n",
    "\n",
    "joined_nearest_ll = gpd.sjoin_nearest(\n",
    "    point_buffer[[\"traj_id\", \"pt_idx\", \"geometry\"]],  # keep only the columns we care about\n",
    "    ses_buffer[[\"geometry\",\"centroid\"]],  \n",
    "    how=\"left\"           # keep all points; hex attributes will be NaN if a point is unmatche\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb9d5a-b528-4bb0-970a-56669632004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nearest = joined_nearest_ll.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dc088-0844-4192-92f4-07ce5d49d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined = joined_nearest.drop_duplicates(subset=[\"traj_id\", \"pt_idx\"])\n",
    "print(clean_joined.crs)\n",
    "\n",
    "print(clean_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92590ed-080d-4f9b-9425-71fcb21c82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = clean_joined.groupby(\"traj_id\")[\"pt_idx\"].idxmin()\n",
    "\n",
    "# select only those rows\n",
    "ses_first_pts = clean_joined.loc[idx].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebecf1-577e-4f46-b55d-a79a92684051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abb53f-8057-428b-a065-7bea94480282",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf3d8c-c1f4-409f-a1c9-526b06bace2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df_full = ses_first_pts.merge(Traj_latent, on = \"traj_id\", how = \"inner\")\n",
    "latent_df_full.rename(columns={\"index_right\":\"hex_id\"},inplace=True)\n",
    "complete_latent_ses_df = latent_df_full.merge(df_final, on =\"hex_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56164841-ae24-4c1b-ae0d-bee01ed9c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df = complete_latent_ses_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22366d77-c6b5-427d-a5c7-2758b854815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df.columns[74:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f53c0-7fcd-462d-b47f-a40b9fc73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142973b4-fe8f-4ed8-ade1-90fa83b33b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254208d4-8d36-42a0-aef0-7509cfa93949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) (Optional) Keep only true numeric columns and drop any rows with NaNs\n",
    "df_num = complete_latent_ses_df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# 2) Slice out y (cols 5–68) and x (cols 74→end)\n",
    "y = df_num.iloc[:, 2:66]\n",
    "x = df_num.iloc[:, 66:]\n",
    "\n",
    "# 3) Compute the full correlation matrix, then take the y vs x block\n",
    "full_corr = pd.concat([y, x], axis=1).corr()\n",
    "corr_yx = full_corr.loc[y.columns, x.columns]\n",
    "\n",
    "# 4) (Optional) Flatten to long form and sort by absolute correlation\n",
    "pairs = (\n",
    "    corr_yx\n",
    "      .abs()                    # comment this out if you want signed values\n",
    "      .stack()                  # turns into a Series with MultiIndex (y, x)\n",
    "      .reset_index()            # makes columns ['level_0','level_1',0]\n",
    "      .rename(columns={\n",
    "          'level_0':'y',\n",
    "          'level_1':'x',\n",
    "          0:'corr'\n",
    "      })\n",
    "      .sort_values('corr', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Results:\n",
    "print(\"Cross‑corr matrix (y vs x):\")\n",
    "print(corr_yx)\n",
    "\n",
    "print(\"\\nLong form sorted by |corr|:\")\n",
    "print(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9baec-8ea4-41be-b939-a5321f036d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.iloc[:,2:(2+64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df4c08-455a-4ad2-8ba3-c9e6aef7f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffcb96-ad9b-4b33-8037-b474dc4b9384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# assume df_num has 90k rows, columns: pt_idx, hex_id, z_0…z_63, and 300 x‑features\n",
    "id_cols = [\"pt_idx\",\"hex_id\"]\n",
    "z_cols  = [f\"z_{i}\" for i in range(64)]\n",
    "x_cols  = [c for c in df_num.columns if c not in id_cols+z_cols]\n",
    "\n",
    "# Prepend a constant column for the intercept\n",
    "X_full = sm.add_constant(X_uncorr)\n",
    "\n",
    "# Dictionary to store summary stats\n",
    "results = {}\n",
    "\n",
    "for z in z_cols:\n",
    "    y = df_num[z]\n",
    "    model = sm.OLS(y, X_full).fit()\n",
    "    \n",
    "    # extract the key statistics\n",
    "    stats = {\n",
    "        \"R2\":        model.rsquared,\n",
    "        \"Adj R2\":    model.rsquared_adj,\n",
    "        \"F-stat\":    model.fvalue,\n",
    "        \"F p‑value\": model.f_pvalue,\n",
    "    }\n",
    "    results[z] = stats\n",
    "    \n",
    "    # Print a brief summary for this target\n",
    "    print(f\"=== {z} ===\")\n",
    "    print(f\" R²={stats['R2']:.4f},  Adj R²={stats['Adj R2']:.4f}\")\n",
    "    print(f\" F={stats['F-stat']:.2f},  p(F)={stats['F p‑value']:.2e}\")\n",
    "    print(f\" Top 5 predictors by |t|:\")\n",
    "    print(model.summary2().tables[1]\n",
    "             .sort_values(\"t\")  # sorts by t‑stat ascending\n",
    "             .abs()\n",
    "             .loc[:, [\"Coef.\", \"Std.Err.\", \"t\", \"P>|t|\"]]\n",
    "             .head(5))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae8e32-6b46-4722-a0ea-f9a6a98bca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pick two targets\n",
    "for zcol in [\"z_0\",\"z_31\"]:\n",
    "    # 1) extract data\n",
    "    y_true = df_num[zcol].values\n",
    "    X       = X_full\n",
    "    y_pred  = model.predict(X)\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    # 2) Pred vs Actual\n",
    "    plt.figure()  # new figure for each plot\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    mn, mx = np.min(y_true), np.max(y_true)\n",
    "    plt.plot([mn, mx], [mn, mx])  # identity line\n",
    "    plt.xlabel(\"Actual \" + zcol)\n",
    "    plt.ylabel(\"Predicted \" + zcol)\n",
    "    plt.title(f\"Predicted vs Actual for {zcol}\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residual histogram\n",
    "    plt.figure()\n",
    "    plt.hist(residuals, bins=30)\n",
    "    plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "    plt.title(f\"Residual Histogram for {zcol}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d6220-bbdb-4bbb-92c1-f9d110a2c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "# 1) Prepare your data\n",
    "X = df_num[x_cols].values       # shape (n_samples, n_features)\n",
    "rf_models = {}                  # to hold the fitted forest for each z\n",
    "r2_scores  = {}                 # to hold in-sample R² for each z\n",
    "\n",
    "# 2) Loop over every target\n",
    "for z in tqdm(z_cols):\n",
    "    y = df_num[z].values        # shape (n_samples,)\n",
    "\n",
    "    # a) instantiate\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # b) fit\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # c) score (in-sample R²)\n",
    "    r2 = rf.score(X, y)\n",
    "\n",
    "    # d) store & print\n",
    "    rf_models[z] = rf\n",
    "    r2_scores[z]  = r2\n",
    "    print(f\"{z:>5}  R² = {r2:.4f}\")\n",
    "\n",
    "# 3) (Optional) Collate all R²s into a DataFrame for easy viewing/sorting\n",
    "r2_df = pd.Series(r2_scores, name=\"R2\").to_frame()\n",
    "print(\"\\nAll targets sorted by R²:\")\n",
    "print(r2_df.sort_values(\"R2\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc5fc4-410f-4de9-b7a6-51cad3f8fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open('/storage1/fs1/nlin/Active/shared_data/rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff8eff-ee7f-410d-8f68-37ae2c6ce58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Choose folder and make sure it exists\n",
    "out_dir = \"model_plots\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 2. Pick how many top‐R² targets you want\n",
    "top_k = 3\n",
    "top = sorted(r2_scores.items(), key=lambda kv: kv[1], reverse=True)[:top_k]\n",
    "top_zs = [z for z, _ in top]\n",
    "\n",
    "# 3. Loop and save\n",
    "for z in top_zs:\n",
    "    y_true   = df_num[z].values\n",
    "    y_pred   = rf_models[z].predict(df_num[x_cols].values)\n",
    "    residual = y_true - y_pred\n",
    "    r2       = r2_scores[z]\n",
    "\n",
    "    # a) Pred vs Actual\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
    "    mn, mx = y_true.min(), y_true.max()\n",
    "    plt.plot([mn, mx], [mn, mx], 'k--', lw=1)\n",
    "    plt.xlabel(f\"Actual {z}\")\n",
    "    plt.ylabel(f\"Predicted {z}\")\n",
    "    plt.title(f\"{z} — Pred vs Actual (R²={r2:.3f})\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{z}_pred_vs_actual.png\"))\n",
    "    plt.close(fig)   # close to free memory\n",
    "\n",
    "    # b) Residuals histogram\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    plt.hist(residual, bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.xlabel(\"Residual (Actual – Predicted)\")\n",
    "    plt.title(f\"{z} — Residuals\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{z}_residuals.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved plots for {top_zs} into ./{out_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05877-eede-4114-8b9a-ed551c83dc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "def max_uncorrelated_features(df: pd.DataFrame,\n",
    "                              threshold: float = 0.9\n",
    "                             ) -> list[str]:\n",
    "    \"\"\"\n",
    "    Greedily select a maximal set of columns from df such that\n",
    "    no pair has abs(corr) > threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, shape (n_samples, p_features)\n",
    "      Only the feature columns (no IDs, no targets).\n",
    "    threshold : float\n",
    "      Drop pairs with |corr| > threshold.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keep : list of column names\n",
    "      Subset of df.columns with no high‑corr pairs.\n",
    "    \"\"\"\n",
    "    # 1) compute absolute correlation matrix\n",
    "    corr = df.corr().abs()\n",
    "    \n",
    "    # 2) build list of conflicting edges\n",
    "    feats = set(df.columns)\n",
    "    edges = [(i, j)\n",
    "             for i, j in combinations(df.columns, 2)\n",
    "             if corr.at[i, j] > threshold]\n",
    "    epoch = 0\n",
    "    # 3) greedy removal\n",
    "    while edges:\n",
    "        epoch +=1\n",
    "        print(f\"Epoch {epoch} started, \")\n",
    "        # compute degrees\n",
    "        deg = {f: 0 for f in feats}\n",
    "        for i, j in edges:\n",
    "            deg[i] += 1\n",
    "            deg[j] += 1\n",
    "        \n",
    "        # pick feature with highest degree\n",
    "        worst = max(deg, key=deg.get)\n",
    "        feats.remove(worst)\n",
    "        \n",
    "        # drop edges incident to that feature\n",
    "        edges = [(i, j) for i, j in edges if i in feats and j in feats]\n",
    "        print(f\"Epoch {epoch} started, edges number : {len(edges)}\")\n",
    "    \n",
    "    # remaining features are non‑collinear\n",
    "    return list(feats)\n",
    "\n",
    "# --- Usage on your X_mat DataFrame ---\n",
    "# X_mat = df_num[x_cols]   # shape (95337, 301)\n",
    "\n",
    "keep = max_uncorrelated_features(X_mat, threshold=0.8)\n",
    "print(f\"Kept {len(keep)}/{X_mat.shape[1]} features:\", keep)\n",
    "\n",
    "# Subset your matrix:\n",
    "X_uncorr = X_mat[keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340933e6-09c4-46b5-867f-40733aea9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# y and X as before; model is your fitted Pipeline\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 1. R²\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# 2. Adjusted R²\n",
    "n, p = X.shape\n",
    "r2_adj = 1 - (1 - r2)*(n - 1)/(n - p - 1)\n",
    "print(f\"Adjusted R²: {r2_adj:.4f}\")\n",
    "\n",
    "# 3. MSE & RMSE\n",
    "mse  = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MSE: {mse:.4g},  RMSE: {rmse:.4g}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
