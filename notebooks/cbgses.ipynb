{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cd420-24ae-471a-8a3c-5a50003bc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1897120-51a9-4aa2-be0d-da6c99011816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "tt_bg_FL = pd.read_excel(\"bg_fl_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f51bd9-8220-4e13-80b0-d2450a738f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_bg_FL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2532c54-4c8e-4ce9-ab79-df632ca9c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_tt_bg_FL = pd.read_csv(\"fl_bg_ses_geom.csv\",delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546d6165-107e-47d9-90c7-ded368318add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13350, 3)\n",
      "          GEOID NAME                                           geometry\n",
      "0  120860001303    3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...\n",
      "1  121030268141    1  MULTIPOLYGON (((-82.70074 28.03389, -82.69772 ...\n",
      "2  120570065041    1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...\n",
      "3  121270803003    3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...\n",
      "4  120710501064    4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Read the file you just wrote in R\n",
    "ses_gdf = gpd.read_file(\"fl_bg.geojson\")\n",
    "\n",
    "# Inspect\n",
    "print(ses_gdf.shape)        # should be (13350, 3) if you had 2 attribute fields + geometry\n",
    "print(ses_gdf.head())\n",
    "\n",
    "# Quick plot\n",
    "ses_gdf.plot(figsize=(8,8), edgecolor=\"black\", linewidth=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52dbb91-8ab0-462a-a5bf-0c267fad25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  # Assuming these might be used later from original imports\n",
    "from peft import PeftModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12044a6b-952c-4631-a8a1-166f2b4a06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG = {\n",
    "    # File Paths\n",
    "    \"HEX_FILE_PATH\": \"Hex_tesse_raw.parquet\",\n",
    "    \"POI_FILE_PATH\": \"Hull_FL_poi_vec_subset.csv\",\n",
    "    \"CHECKPOINT_PATH\": \"bottleneck_mlp_newdata.pth\",\n",
    "    \"OUTPUT_PATH\": \"POI_encoded_embeddings.parquet\",\n",
    "    \n",
    "    # Coordinate Reference Systems\n",
    "    \"CRS_GEOGRAPHIC\": \"EPSG:4326\",\n",
    "    \"CRS_PROJECTED\": \"EPSG:5070\",  # Using an equal-area projection for the US\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    \"LATENT_DIM\": 64,\n",
    "    \"HIDDEN_DIM\": 256,\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"EPOCHS\": 40,\n",
    "    \n",
    "    # System Configuration\n",
    "    \"DEVICE\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"NUM_WORKERS\": 4,\n",
    "}\n",
    "\n",
    "#  PyTorch Model Definition \n",
    "\n",
    "class BottleneckMLP(nn.Module):\n",
    "    \"\"\"A Bottleneck Multi-Layer Perceptron for dimensionality reduction and classification.\"\"\"\n",
    "    def __init__(self, in_dim, hid_dim, lat_dim, n_cls):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.LeakyReLU(0.01, inplace=True),\n",
    "            nn.Linear(hid_dim, lat_dim),\n",
    "            nn.LeakyReLU(0.01, inplace=True)\n",
    "        )\n",
    "        self.head = nn.Linear(lat_dim, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.head(z)\n",
    "        return z, logits\n",
    "\n",
    "#  Data Loading and Preprocessing Functions \n",
    "\n",
    "def load_hexagon_data(file_path, crs):\n",
    "    \"\"\"Loads and preprocesses the hexagon GeoDataFrame.\"\"\"\n",
    "    logging.info(f\"Loading hexagon data from {file_path}...\")\n",
    "    hex_gdf = pd.read_parquet(file_path)\n",
    "    hex_gdf = hex_gdf.reset_index(drop=True)\n",
    "    hex_gdf[\"hex_id\"] = hex_gdf.index.astype(str)\n",
    "    hex_gdf[\"geometry\"] = gpd.GeoSeries.from_wkb(hex_gdf[\"geometry\"])\n",
    "    hex_gdf = gpd.GeoDataFrame(hex_gdf, geometry=\"geometry\", crs=crs)\n",
    "    logging.info(f\"Hexagon data loaded with {len(hex_gdf)} hexagons.\")\n",
    "    return hex_gdf\n",
    "\n",
    "def load_poi_data(file_path, crs):\n",
    "    \"\"\"Loads and preprocesses the POI GeoDataFrame.\"\"\"\n",
    "    logging.info(f\"Loading POI data from {file_path}...\")\n",
    "    table = pv.read_csv(\n",
    "        file_path,\n",
    "        read_options=ReadOptions(block_size=1 << 20),\n",
    "        parse_options=ParseOptions(delimiter=\",\", quote_char='\"', newlines_in_values=True)\n",
    "    )\n",
    "    df = table.to_pandas()\n",
    "    df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads)\n",
    "    poi_gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n",
    "    logging.info(f\"POI data loaded with {len(poi_gdf)} points.\")\n",
    "    return poi_gdf\n",
    "\n",
    "def parse_vector_column(series: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Parses a string representation of vectors into a stacked NumPy array.\"\"\"\n",
    "    logging.info(\"Parsing string vectors into NumPy array...\")\n",
    "    def parse_vec(s: str) -> np.ndarray:\n",
    "        if isinstance(s, (list, np.ndarray)):\n",
    "            return np.array(s, dtype=np.float32)\n",
    "        return np.fromstring(s.strip(\"[]\"), sep=\" \", dtype=np.float32)\n",
    "    \n",
    "    vecs = np.stack(series.map(parse_vec).values)\n",
    "    return vecs\n",
    "\n",
    "#  Model Training and Inference Functions \n",
    "\n",
    "def train_or_load_model(config, loader, n_classes, class_labels):\n",
    "    \"\"\"Instantiates the model and optimizer, then loads from checkpoint or trains.\"\"\"\n",
    "    logging.info(\"Initializing model, optimizer, and criterion...\")\n",
    "    model = BottleneckMLP(\n",
    "        in_dim=loader.dataset.tensors[0].shape[1],\n",
    "        hid_dim=config[\"HIDDEN_DIM\"],\n",
    "        lat_dim=config[\"LATENT_DIM\"],\n",
    "        n_cls=n_classes\n",
    "    ).to(config[\"DEVICE\"])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if os.path.exists(config[\"CHECKPOINT_PATH\"]):\n",
    "        logging.info(f\"Loading pretrained model from {config['CHECKPOINT_PATH']}\")\n",
    "        ckpt = torch.load(config[\"CHECKPOINT_PATH\"], map_location=config[\"DEVICE\"])\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        logging.info(\"No checkpoint foundstarting training from scratch.\")\n",
    "        for epoch in range(1, config[\"EPOCHS\"] + 1):\n",
    "            model.train()\n",
    "            loop = tqdm(loader, desc=f\"Epoch {epoch}/{config['EPOCHS']}\", unit=\"batch\")\n",
    "            total_loss = 0.0\n",
    "            for xb, yb in loop:\n",
    "                xb, yb = xb.to(config[\"DEVICE\"]), yb.to(config[\"DEVICE\"])\n",
    "                optimizer.zero_grad()\n",
    "                _, logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * xb.size(0)\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            avg_loss = total_loss / len(loader.dataset)\n",
    "            print(f\" Epoch {epoch:2d}: avg loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        logging.info(f\"Training completesaving checkpoint to {config['CHECKPOINT_PATH']}\")\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"classes\": class_labels\n",
    "        }, config[\"CHECKPOINT_PATH\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def encode_features(model, loader, device):\n",
    "    \"\"\"Runs inference to generate latent embeddings for the input data.\"\"\"\n",
    "    logging.info(\"Encoding features to generate latent vectors (Z)...\")\n",
    "    model.eval()\n",
    "    all_z = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in tqdm(loader, desc=\"Encoding\"):\n",
    "            xb = xb.to(device)\n",
    "            z = model.encoder(xb)\n",
    "            all_z.append(z.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(all_z)\n",
    "\n",
    "#  Geospatial Processing Function \n",
    "\n",
    "def assign_pois_to_hexagons(poi_gdf, hex_gdf):\n",
    "    \"\"\"Reprojects and performs a nearest-neighbor join to assign POIs to hexagons.\"\"\"\n",
    "    logging.info(\"Reprojecting GeoDataFrames to equal-area CRS for accurate nearest-neighbor search...\")\n",
    "    poi_proj = poi_gdf.to_crs(epsg=CONFIG[\"CRS_PROJECTED\"])\n",
    "    hex_proj = hex_gdf.to_crs(epsg=CONFIG[\"CRS_PROJECTED\"])\n",
    "\n",
    "    logging.info(\"Assigning POIs to nearest hexagon...\")\n",
    "    joined_gdf = gpd.sjoin_nearest(\n",
    "        poi_proj,\n",
    "        hex_proj[[\"hex_id\", \"geometry\"]],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Join completed. Matched points: {joined_gdf['hex_id'].notna().sum()}/{len(poi_gdf)}\")\n",
    "    \n",
    "    # Reproject final result back to geographic coordinates\n",
    "    joined_gdf = joined_gdf.to_crs(epsg=CONFIG[\"CRS_GEOGRAPHIC\"])\n",
    "    return joined_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00b89ba-8a9f-48eb-b4ef-7e2125435db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_gdf = load_hexagon_data(\"Hex_tesse_raw.parquet\",\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35134c8c-9b15-4852-99c6-63dad1b9d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                geometry hex_id\n",
      "0      POLYGON ((-88.55028 30.36403, -88.54055 30.359...      0\n",
      "1      POLYGON ((-88.55028 30.37372, -88.55028 30.364...      1\n",
      "2      POLYGON ((-88.55028 30.3931, -88.54055 30.3882...      2\n",
      "3      POLYGON ((-88.55028 30.40278, -88.55028 30.393...      3\n",
      "4      POLYGON ((-88.55028 30.42215, -88.54055 30.417...      4\n",
      "...                                                  ...    ...\n",
      "67963  POLYGON ((-79.95377 26.33337, -79.95377 26.343...  67963\n",
      "67964  POLYGON ((-79.95377 26.36356, -79.95377 26.373...  67964\n",
      "67965  POLYGON ((-79.94405 26.37865, -79.94405 26.388...  67965\n",
      "67966  POLYGON ((-79.94405 26.38871, -79.95377 26.393...  67966\n",
      "67967  POLYGON ((-79.95377 26.42391, -79.95377 26.433...  67967\n",
      "\n",
      "[67968 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    hex_gdf = hex_gdf.drop(columns=\"hexid\")\n",
    "except Exception as e:\n",
    "    print(\"deleted\")\n",
    "print(hex_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e61296-8d2a-4b3f-a18e-ea95f7833406",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf = ses_gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7b245-6626-47c3-ad8c-02b86bbfefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14609ddd-a2f9-41bc-84fb-53eeb5bbb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "hex_gdf.boundary.plot(ax=ax, linewidth=0.05, edgecolor=\"gray\",alpha=0.5)\n",
    "states = gpd.read_file('cb_2018_us_state_500k.shp')\n",
    "#state_plot = states.to_crs(epsg=3857)\n",
    "states[states.STUSPS == \"FL\"].boundary.plot(\n",
    "    ax=ax, linewidth=1, color=\"black\"\n",
    ")\n",
    "ses_gdf.plot(ax=ax,cmap = \"tab20\", alpha = 0.9)\n",
    "xmin, ymin, xmax, ymax = (-82.5, 27.9, -82.3, 28.1)  # example in EPSG:3857 coords\n",
    "\n",
    "# 6) Create an inset axes for the zoom\n",
    "axins = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"lower left\", borderpad=1)\n",
    "axins.set_xlim(xmin, xmax)\n",
    "axins.set_ylim(ymin, ymax)\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"red\", lw=1)\n",
    "hex_gdf.boundary.plot(ax=axins, linewidth=0.1, edgecolor=\"black\",alpha=0.9)\n",
    "#ax.axes(False)\n",
    "states[states.STUSPS == \"FL\"].boundary.plot(\n",
    "    ax=axins, linewidth=1, color=\"black\"\n",
    ")\n",
    "ses_gdf.plot(ax=axins,cmap = \"tab20\", alpha = 0.9)\n",
    "plt.savefig(\"hex_tess_ses.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa105bbd-d9f4-4502-b347-c014bfaef893",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_parquet(\"POI_encoded_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963b2bce-c3ea-4f0d-af32-7c20ab29e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Expand the `z` list/array into its own DataFrame of shape (N, D)\n",
    "#    so each dimension becomes a column z0, z1, ..., z{D-1}\n",
    "z_expanded = pd.DataFrame(\n",
    "    gdf[\"z\"].tolist(),\n",
    "    index=gdf.index\n",
    ")\n",
    "z_expanded.columns = [f\"z{i}\" for i in range(z_expanded.shape[1])]\n",
    "\n",
    "# 3) Combine back with the labels\n",
    "df_expanded = pd.concat([gdf[\"label_pair\"], z_expanded], axis=1)\n",
    "\n",
    "# 4) Group by label_pair and take the mean  this is your center per class\n",
    "centers_df = df_expanded.groupby(\"label_pair\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24663f09-505d-4799-81b5-9fbd8d3529a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>geometry</th>\n",
       "      <th>hex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120860001303</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121030268141</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120570065041</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121270803003</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120710501064</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>120710104151</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.06879 26.56344, -82.06437 ...</td>\n",
       "      <td>13345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>120990075043</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.09112 26.33261, -80.08951 ...</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>120310144132</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((-81.55911 30.18003, -81.55849 ...</td>\n",
       "      <td>13347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13348</th>\n",
       "      <td>120190307061</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-81.71425 30.08813, -81.71339 ...</td>\n",
       "      <td>13348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>120174504011</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.52519 29.02283, -82.52312 ...</td>\n",
       "      <td>13349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13350 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GEOID NAME                                           geometry  \\\n",
       "0      120860001303    3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...   \n",
       "1      121030268141    1  MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...   \n",
       "2      120570065041    1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...   \n",
       "3      121270803003    3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...   \n",
       "4      120710501064    4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...   \n",
       "...             ...  ...                                                ...   \n",
       "13345  120710104151    1  MULTIPOLYGON (((-82.06879 26.56344, -82.06437 ...   \n",
       "13346  120990075043    3  MULTIPOLYGON (((-80.09112 26.33261, -80.08951 ...   \n",
       "13347  120310144132    2  MULTIPOLYGON (((-81.55911 30.18003, -81.55849 ...   \n",
       "13348  120190307061    1  MULTIPOLYGON (((-81.71425 30.08813, -81.71339 ...   \n",
       "13349  120174504011    1  MULTIPOLYGON (((-82.52519 29.02283, -82.52312 ...   \n",
       "\n",
       "       hex_id  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  \n",
       "...       ...  \n",
       "13345   13345  \n",
       "13346   13346  \n",
       "13347   13347  \n",
       "13348   13348  \n",
       "13349   13349  \n",
       "\n",
       "[13350 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ses_gdf = ses_gdf.reset_index(drop=True)\n",
    "\n",
    "# 2) copy that index into your new hex_id column\n",
    "ses_gdf[\"hex_id\"] = ses_gdf.index\n",
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb00715-af42-4fd0-80f4-9c77140fcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47a02ce-e439-43a4-9e37-a0af27a5a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                label_pair  \\\n",
      "0        Activities Related to Real Estate[sep]Resident...   \n",
      "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
      "3              Offices of Dentists[sep]Offices of Dentists   \n",
      "4        Museums, Historical Sites, and Similar Institu...   \n",
      "...                                                    ...   \n",
      "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
      "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "\n",
      "                                                         z  \\\n",
      "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
      "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
      "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
      "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
      "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
      "...                                                    ...   \n",
      "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
      "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
      "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
      "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
      "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
      "\n",
      "                           geometry  \\\n",
      "0        POINT (-82.52482 27.94908)   \n",
      "1        POINT (-81.38077 30.19916)   \n",
      "2         POINT (-81.76929 24.5666)   \n",
      "3        POINT (-81.68255 30.20312)   \n",
      "4        POINT (-81.84711 26.64202)   \n",
      "...                             ...   \n",
      "1548012  POINT (-81.42641 29.78401)   \n",
      "1548013  POINT (-81.07024 29.21795)   \n",
      "1548014  POINT (-81.32279 29.04255)   \n",
      "1548015  POINT (-81.01938 29.24983)   \n",
      "1548016  POINT (-80.98888 29.14597)   \n",
      "\n",
      "                                                  cat_name  cat_count  weight  \\\n",
      "0                        Activities Related to Real Estate         24     576   \n",
      "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
      "3                                      Offices of Dentists         70    4900   \n",
      "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
      "...                                                    ...        ...     ...   \n",
      "1548012                            Home Furnishings Stores          1       1   \n",
      "1548013                              Urban Transit Systems         16     256   \n",
      "1548014                              Urban Transit Systems          8      64   \n",
      "1548015                              Urban Transit Systems         30     900   \n",
      "1548016                              Urban Transit Systems         33    1089   \n",
      "\n",
      "         hex_id_right  \n",
      "0              9375.0  \n",
      "1              2887.0  \n",
      "2              7375.0  \n",
      "3             10516.0  \n",
      "4              5089.0  \n",
      "...               ...  \n",
      "1548012       12446.0  \n",
      "1548013        1150.0  \n",
      "1548014       10826.0  \n",
      "1548015        4902.0  \n",
      "1548016        9483.0  \n",
      "\n",
      "[1678168 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#ses_gdf.to_crs(ESPG:5070)\n",
    "gdf = gdf.to_crs(ses_gdf.crs)\n",
    "#gdf = gdf.drop(columns=[\"hex_id\"])\n",
    "# 2) keep only the hex_id + geometry in the hexgrid\n",
    "hexes = ses_gdf[[\"hex_id\", \"geometry\"]]\n",
    "\n",
    "# 3) spatial join: for each point, find the hex whose polygon it lies within\n",
    "#     predicate=\"within\" for GeoPandas  0.10, or op=\"within\" for older versions\n",
    "joined = gpd.sjoin(\n",
    "    gdf,\n",
    "    hexes,\n",
    "    how=\"left\",          # keep all points, even those that fall outside\n",
    "    #predicate=\"within\"   # use \"op='within'\" if your GeoPandas is <0.10\n",
    ")\n",
    "\n",
    "# 4) clean up the result: drop the autoadded index_right column\n",
    "joined = joined.drop(columns=[\"hex_id_left\",\"index_right\"])\n",
    "\n",
    "# now `joined` has all of your original point columns **plus** a `hex_id` column\n",
    "print(joined)\n",
    "joined = joined.rename(columns={\"hex_id_right\":\"hex_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75a7d2c-92ed-48d7-b3fd-0654ff0db909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "                                                label_pair  \\\n",
      "0        Activities Related to Real Estate[sep]Resident...   \n",
      "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
      "3              Offices of Dentists[sep]Offices of Dentists   \n",
      "4        Museums, Historical Sites, and Similar Institu...   \n",
      "...                                                    ...   \n",
      "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
      "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
      "\n",
      "                                                         z  \\\n",
      "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
      "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
      "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
      "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
      "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
      "...                                                    ...   \n",
      "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
      "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
      "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
      "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
      "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
      "\n",
      "                           geometry  \\\n",
      "0        POINT (-82.52482 27.94908)   \n",
      "1        POINT (-81.38077 30.19916)   \n",
      "2         POINT (-81.76929 24.5666)   \n",
      "3        POINT (-81.68255 30.20312)   \n",
      "4        POINT (-81.84711 26.64202)   \n",
      "...                             ...   \n",
      "1548012  POINT (-81.42641 29.78401)   \n",
      "1548013  POINT (-81.07024 29.21795)   \n",
      "1548014  POINT (-81.32279 29.04255)   \n",
      "1548015  POINT (-81.01938 29.24983)   \n",
      "1548016  POINT (-80.98888 29.14597)   \n",
      "\n",
      "                                                  cat_name  cat_count  weight  \\\n",
      "0                        Activities Related to Real Estate         24     576   \n",
      "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
      "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
      "3                                      Offices of Dentists         70    4900   \n",
      "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
      "...                                                    ...        ...     ...   \n",
      "1548012                            Home Furnishings Stores          1       1   \n",
      "1548013                              Urban Transit Systems         16     256   \n",
      "1548014                              Urban Transit Systems          8      64   \n",
      "1548015                              Urban Transit Systems         30     900   \n",
      "1548016                              Urban Transit Systems         33    1089   \n",
      "\n",
      "          hex_id  \n",
      "0         9375.0  \n",
      "1         2887.0  \n",
      "2         7375.0  \n",
      "3        10516.0  \n",
      "4         5089.0  \n",
      "...          ...  \n",
      "1548012  12446.0  \n",
      "1548013   1150.0  \n",
      "1548014  10826.0  \n",
      "1548015   4902.0  \n",
      "1548016   9483.0  \n",
      "\n",
      "[1590667 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sum(joined[\"hex_id\"].isna())/len(joined))\n",
    "joined = joined.dropna(subset=[\"hex_id\"])\n",
    "joined.to_crs(\"EPSG:4326\")\n",
    "print(joined)\n",
    "#joined[\"hex_id\"] = joined[\"hex_id\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accc464d-7b3d-4290-ac7e-394787419225",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vecs = (\n",
    "    joined\n",
    "    .groupby('hex_id')['z']\n",
    "    .agg(lambda arrs: np.mean(np.stack(arrs.values), axis=0))\n",
    ")\n",
    "# mean_vecs is a Series: index=hex_id, value=np.ndarray(1152,)\n",
    "\n",
    "# 2a) merge into hex_gdf\n",
    "ses_gdf = ses_gdf.merge(\n",
    "    mean_vecs.rename('vec_mean'),\n",
    "    left_on='hex_id',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff83f48-50d6-4377-81f9-2f636cd4b00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13350, 308)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME_x</th>\n",
       "      <th>geometry</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>vec_mean_x</th>\n",
       "      <th>vec_mean_y</th>\n",
       "      <th>NAME_y</th>\n",
       "      <th>Total:</th>\n",
       "      <th>Total: Under .50</th>\n",
       "      <th>Total: .50 to .99</th>\n",
       "      <th>...</th>\n",
       "      <th>Total: With an Internet subscription Broadband of any type</th>\n",
       "      <th>Total: With an Internet subscription Cellular data plan</th>\n",
       "      <th>Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Broadband such as cable, fiber optic or DSL</th>\n",
       "      <th>Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Satellite Internet service</th>\n",
       "      <th>Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription</th>\n",
       "      <th>Total: With an Internet subscription Other service with no other type of Internet subscription</th>\n",
       "      <th>Total: Internet access without a subscription</th>\n",
       "      <th>Total: No Internet access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120860001303</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[33.6305, 35.814537, 14.019923, 40.46885, 28.7...</td>\n",
       "      <td>[33.6305, 35.814537, 14.019923, 40.46885, 28.7...</td>\n",
       "      <td>Block Group 3; Census Tract 1.30; Miami-Dade C...</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121030268141</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[28.050043, 36.334988, 19.818258, 34.684147, 3...</td>\n",
       "      <td>[28.050043, 36.334988, 19.818258, 34.684147, 3...</td>\n",
       "      <td>Block Group 1; Census Tract 268.14; Pinellas C...</td>\n",
       "      <td>992</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>429</td>\n",
       "      <td>392</td>\n",
       "      <td>46</td>\n",
       "      <td>375</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120570065041</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[37.87849, 41.17299, 24.685835, 38.813133, 35....</td>\n",
       "      <td>[37.87849, 41.17299, 24.685835, 38.813133, 35....</td>\n",
       "      <td>Block Group 1; Census Tract 65.04; Hillsboroug...</td>\n",
       "      <td>411</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121270803003</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[46.378544, 34.71072, 28.458584, 43.096386, 30...</td>\n",
       "      <td>[46.378544, 34.71072, 28.458584, 43.096386, 30...</td>\n",
       "      <td>Block Group 3; Census Tract 803; Volusia Count...</td>\n",
       "      <td>1024</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>465</td>\n",
       "      <td>346</td>\n",
       "      <td>18</td>\n",
       "      <td>400</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120710501064</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[39.790993, 35.508392, 29.290495, 40.39536, 39...</td>\n",
       "      <td>[39.790993, 35.508392, 29.290495, 40.39536, 39...</td>\n",
       "      <td>Block Group 4; Census Tract 501.06; Lee County...</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>350</td>\n",
       "      <td>334</td>\n",
       "      <td>33</td>\n",
       "      <td>317</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID NAME_x                                           geometry  \\\n",
       "0  120860001303      3  MULTIPOLYGON (((-80.12204 25.92989, -80.12043 ...   \n",
       "1  121030268141      1  MULTIPOLYGON (((-82.70074 28.03389, -82.69771 ...   \n",
       "2  120570065041      1  MULTIPOLYGON (((-82.53205 27.89599, -82.53192 ...   \n",
       "3  121270803003      3  MULTIPOLYGON (((-81.06403 29.32267, -81.06218 ...   \n",
       "4  120710501064      4  MULTIPOLYGON (((-81.85447 26.49909, -81.85401 ...   \n",
       "\n",
       "   hex_id                                         vec_mean_x  \\\n",
       "0       0  [33.6305, 35.814537, 14.019923, 40.46885, 28.7...   \n",
       "1       1  [28.050043, 36.334988, 19.818258, 34.684147, 3...   \n",
       "2       2  [37.87849, 41.17299, 24.685835, 38.813133, 35....   \n",
       "3       3  [46.378544, 34.71072, 28.458584, 43.096386, 30...   \n",
       "4       4  [39.790993, 35.508392, 29.290495, 40.39536, 39...   \n",
       "\n",
       "                                          vec_mean_y  \\\n",
       "0  [33.6305, 35.814537, 14.019923, 40.46885, 28.7...   \n",
       "1  [28.050043, 36.334988, 19.818258, 34.684147, 3...   \n",
       "2  [37.87849, 41.17299, 24.685835, 38.813133, 35....   \n",
       "3  [46.378544, 34.71072, 28.458584, 43.096386, 30...   \n",
       "4  [39.790993, 35.508392, 29.290495, 40.39536, 39...   \n",
       "\n",
       "                                              NAME_y  Total:  \\\n",
       "0  Block Group 3; Census Tract 1.30; Miami-Dade C...     279   \n",
       "1  Block Group 1; Census Tract 268.14; Pinellas C...     992   \n",
       "2  Block Group 1; Census Tract 65.04; Hillsboroug...     411   \n",
       "3  Block Group 3; Census Tract 803; Volusia Count...    1024   \n",
       "4  Block Group 4; Census Tract 501.06; Lee County...     582   \n",
       "\n",
       "   Total: Under .50  Total: .50 to .99  ...  \\\n",
       "0                 0                 42  ...   \n",
       "1                16                 19  ...   \n",
       "2                17                 55  ...   \n",
       "3                69                  2  ...   \n",
       "4                 0                 40  ...   \n",
       "\n",
       "   Total: With an Internet subscription Broadband of any type  \\\n",
       "0                                                183            \n",
       "1                                                429            \n",
       "2                                                198            \n",
       "3                                                465            \n",
       "4                                                350            \n",
       "\n",
       "   Total: With an Internet subscription Cellular data plan  \\\n",
       "0                                                183         \n",
       "1                                                392         \n",
       "2                                                177         \n",
       "3                                                346         \n",
       "4                                                334         \n",
       "\n",
       "   Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                 46                                                                        \n",
       "2                                                  2                                                                        \n",
       "3                                                 18                                                                        \n",
       "4                                                 33                                                                        \n",
       "\n",
       "   Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
       "0                                                160                                  \n",
       "1                                                375                                  \n",
       "2                                                166                                  \n",
       "3                                                400                                  \n",
       "4                                                317                                  \n",
       "\n",
       "   Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                                                                          \n",
       "1                                                 29                                                                                                                          \n",
       "2                                                 21                                                                                                                          \n",
       "3                                                119                                                                                                                          \n",
       "4                                                 16                                                                                                                          \n",
       "\n",
       "   Total: With an Internet subscription Satellite Internet service  \\\n",
       "0                                                 33                 \n",
       "1                                                  0                 \n",
       "2                                                 28                 \n",
       "3                                                 11                 \n",
       "4                                                  0                 \n",
       "\n",
       "   Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
       "0                                                  0                                                \n",
       "1                                                  8                                                \n",
       "2                                                  0                                                \n",
       "3                                                  0                                                \n",
       "4                                                  0                                                \n",
       "\n",
       "   Total: Internet access without a subscription  Total: No Internet access  \n",
       "0                                             14                          0  \n",
       "1                                              0                          5  \n",
       "2                                             11                         52  \n",
       "3                                             60                        139  \n",
       "4                                             35                         17  \n",
       "\n",
       "[5 rows x 308 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_bg_FL[\"GEOID\"] = tt_bg_FL[\"GEOID\"].astype(str)\n",
    "\n",
    "# (optional) also ensure ses_gdf.GEOID is string\n",
    "ses_gdf[\"GEOID\"] = ses_gdf[\"GEOID\"].astype(str)\n",
    "\n",
    "# 3) now do the merge\n",
    "merged = ses_gdf.merge(\n",
    "    tt_bg_FL,\n",
    "    on=\"GEOID\",\n",
    "    how=\"left\"   # or \"inner\" if you only want matching IDs\n",
    ")\n",
    "\n",
    "# 4) merged is still a GeoDataFrame with geometry + your new columns\n",
    "print(merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490fe94-e498-40c0-97df-ecfda5997af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Suppose df is your original GeoDataFrame with 307 cols:\n",
    "df = merged.copy()\n",
    "\n",
    "# 1) Pick off the columns you want to exempt (by name or by position)\n",
    "exempt = list(df.columns[:7])   # e.g. first four columns\n",
    "to_impute = df.columns.difference(exempt)\n",
    "\n",
    "# 2) Fit & transform only the to_impute slice\n",
    "imp = IterativeImputer(random_state=0)\n",
    "imputed_vals = imp.fit_transform(df[to_impute])\n",
    "\n",
    "# 3) Rebuild a new DataFrame for the imputed part\n",
    "df_imp = pd.DataFrame(imputed_vals,\n",
    "                      columns=to_impute,\n",
    "                      index=df.index)\n",
    "\n",
    "# 4) Concatenate the exempted + imputed parts, preserving original order\n",
    "df_final = pd.concat([df[exempt], df_imp], axis=1)[df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae60d38-c44b-495f-a685-b227db221416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(\"imputed_ses.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c93b6035-01cf-41fd-b601-ce4d10d43129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_parquet(\"imputed_ses.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c55682-506b-43d0-a21e-9a6a91b112d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7976d1fb-b31c-4f27-be1c-b026f64d0d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_1281/588510722.py:11: FutureWarning: `idVariable` is deprecated and will be removed in future. Use `ids` instead.\n",
      "  wq = Queen.from_dataframe(\n",
      "/storage1/fs1/nlin/Active/sizhe/sizhe/envs/geospatial/lib/python3.12/site-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 10 disconnected components.\n",
      " There are 6 islands with ids: 6126, 9175, 9234, 10256, 11174, 11374.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example neighbors for one cell: [(0, [4164, 8852, 3276, 3229, 12463]), (1, [12610, 3145, 10207, 10205, 3183]), (2, [6353, 9719, 7245, 766, 5711])]\n",
      "10 components total\n",
      "Singleton islands: [6126, 9175, 9234, 10256, 11174, 11374]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from libpysal.weights import Queen\n",
    "import networkx as nx\n",
    "\n",
    "# 1) (Optional) make sure your geometries are in a planar CRS\n",
    "#    Queen contiguity only makes sense in projected (not geographic) coordinates:\n",
    "merged = merged.to_crs(epsg=3857)\n",
    "\n",
    "# 2) build a Queencontiguity weight object,\n",
    "#    telling PySAL which column holds the unique ID (here hex_id) and which holds the geometry:\n",
    "wq = Queen.from_dataframe(\n",
    "    merged,\n",
    "    idVariable=\"hex_id\",\n",
    "    geom_col=\"geometry\"\n",
    ")\n",
    "\n",
    "# 3) if you want the raw neighbor lists:\n",
    "#    wq.neighbors is a dict: { hex_id_1: [nbr1, nbr2,], hex_id_2: [],  }\n",
    "print(\"example neighbors for one cell:\", list(wq.neighbors.items())[:3])\n",
    "\n",
    "# 4) to turn that into a NetworkX graph:\n",
    "G = wq.to_networkx()\n",
    "\n",
    "# 5) now you can check connectivity exactly as before\n",
    "comps = list(nx.connected_components(G))\n",
    "print(f\"{len(comps)} components total\")\n",
    "islands = [c.pop() for c in comps if len(c)==1]\n",
    "print(\"Singleton islands:\", islands)\n",
    "merged['centroid'] = merged.geometry.centroid\n",
    "centroids = merged.set_index('hex_id')['centroid']\n",
    "\n",
    "# 2) for each island, find its nearest neighbour and add an edge\n",
    "for iso in islands:\n",
    "    # distances to all other centroids\n",
    "    dists = centroids.distance(centroids.loc[iso]).drop(index=iso)\n",
    "    nearest = dists.idxmin()\n",
    "    G.add_edge(iso, nearest)\n",
    "\n",
    "comps   = list(nx.connected_components(G))\n",
    "islands = [next(iter(c)) for c in comps if len(c) == 1]\n",
    "\n",
    "# 2) compute centroids (once)\n",
    "merged = merged.to_crs(epsg=3857)\n",
    "merged['centroid'] = merged.geometry.centroid\n",
    "centroids = merged.set_index('hex_id')['centroid']\n",
    "\n",
    "# 3) stitch each singleton onto its nearest neighbor:\n",
    "for iso in islands:\n",
    "    dists   = centroids.distance(centroids.loc[iso]).drop(index=iso)\n",
    "    nearest = dists.idxmin()\n",
    "    G.add_edge(iso, nearest)\n",
    "\n",
    "# 4) now recompute & sort your components\n",
    "comps = list(nx.connected_components(G))\n",
    "comps = sorted(comps, key=len, reverse=True)\n",
    "main_comp = list(comps[0])\n",
    "\n",
    "# 5) bridge every other component into the main one\n",
    "for comp in comps[1:]:\n",
    "    comp = list(comp)\n",
    "    best_pair = None\n",
    "    best_dist = float('inf')\n",
    "    for hid in comp:\n",
    "        dists = centroids.loc[main_comp].distance(centroids.loc[hid])\n",
    "        j     = dists.idxmin()\n",
    "        d     = dists.min()\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_pair = (hid, j)\n",
    "    # now best_pair is guaranteed to be a 2tuple\n",
    "    G.add_edge(*best_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9dd22-27f5-4183-9d34-5468213409e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = list(nx.connected_components(G))\n",
    "len(comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d157d-803c-4a15-92c3-8c64c8c29045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ses_graph.pickle\",\"wb\") as f:\n",
    "    pickle.dump(G,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca8c0a6-8d24-4a42-b1ae-18e9f45ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ses_graph.pickle\",\"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767a135-ea60-4de8-b339-c0654f781216",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = \"models/ses.emb\"\n",
    "EMBEDDING_MODEL_FILENAME = \"models/ses_model_embeddings.model\"\n",
    "# Load model after Node2Vec.save\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=128, num_walks=16, workers=10)  # Use temp_folder for big graphs\n",
    "model = node2vec.fit(vector_size=64, window=16, min_count=3, workers=8)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n",
    "\n",
    "# Save model for later use\n",
    "model.save(EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656de50-3b0c-4958-bc8e-a02f194821d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!    pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d330c-1704-4c42-87fd-abdaf869926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y k-means-constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db187164-0a5f-4e3e-b775-d97a1854cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y gensim\n",
    "!pip install --no-cache-dir --force-reinstall \"gensim==4.3.3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d1d86-36d6-4910-b3e3-bd6202d65fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "print(sys.version)\n",
    "print(\"numpy:\", np.__version__)\n",
    "# import gensim  # will fail right now, that's the point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb14b2a-fbd3-482c-bb8e-bb1828ce573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = \"models/ses.emb\"\n",
    "EMBEDDING_MODEL_FILENAME = \"models/ses_model_embeddings.model\"\n",
    "# Load model after Node2Vec.save\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "vec_model = Word2Vec.load(EMBEDDING_MODEL_FILENAME)\n",
    "embeddings = {node: vec_model.wv[node] for node in G.nodes()}\n",
    "emb_dataframe = pd.DataFrame.from_dict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef012d5d-938f-4063-9a69-0bb41b740eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = emb_dataframe.to_numpy().T   # shape (N, D)\n",
    "\n",
    "# 2) turn each row into a Python list\n",
    "vec_lists = vecs.tolist()           # [ [float,,float],  ]\n",
    "\n",
    "# 3) assign by position (assuming hex_gdf is already sorted by hex_id 0N-1)\n",
    "ses_gdf['graph_embedding'] = vec_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630cb64-7efe-425c-b590-a8896fa21bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbf28b96-e349-4323-8c2f-7f1a56c41416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage1/fs1/nlin/Active/sizhe/sizhe/envs/geospatial/lib/python3.12/site-packages/peft/peft_model.py:565: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "# 4) Move to GPU/CPU and set eval mode:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 1) Where you saved your LoRA adapters after training:\n",
    "CHECKPOINT = \"/storage1/fs1/nlin/Active/sizhe/FO_DATA/checkpoint-dir/checkpoint-551\"\n",
    "\n",
    "# 2) Load the tokenizer from that folder (it contains tokenizer.json + vocab.txt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "base_name = \"google/gemma-3-1b-it\"     # < exactly what you passed in your training script\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-3-1b-it\",\n",
    "    attn_implementation=\"eager\"\n",
    ").to(device)\n",
    "\n",
    "# 3) Now graft the adapter weights:\n",
    "llm_model = PeftModel.from_pretrained(base, CHECKPOINT,strict=False)\n",
    "\n",
    "\n",
    "#llm_model.to(device).eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15342185-40d4-46ae-8c89-f0c3d4a4a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    texts: a Python list of strings (each may contain literal \"[sep]\").\n",
    "    example: [\"[Museums, Historical Sites,...<sep>Museums, Historical Sites<sep>Natural History museum]\",...]\n",
    "    In the format of [<category><sep><subcategory><sep><name>]\n",
    "    Returns: a GPU tensor of shape (len(texts), hidden_size) containing the\n",
    "             finaltoken embedding for each string.\n",
    "    \"\"\"\n",
    "    # 2.1) Clean & force everything to str, replacing None/NaN with \"\"\n",
    "    clean_texts=[]\n",
    "    for t in texts:\n",
    "        if t is None:\n",
    "            clean_texts.append(\"\")\n",
    "        else:\n",
    "            clean_texts.append(str(t))\n",
    "    sep = tokenizer.sep_token  # e.g. \"[SEP]\" for BERTstyle; whatever your tokenizer.sep_token is\n",
    "    clean_texts = [t.replace(\"[sep]\", sep) for t in clean_texts]\n",
    "    \n",
    "    # 2.3) Batchtokenize all strings onto GPU\n",
    "    enc = tokenizer(\n",
    "        clean_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_token_type_ids=False,\n",
    "    ).to(device)\n",
    "    #print(\"Batch input_ids are on:\", enc.input_ids.device)\n",
    "    # Now enc.input_ids and enc.attention_mask live on GPU.\n",
    "\n",
    "    # 2.4) Forwardpass (no gradients) to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = llm_model.base_model(\n",
    "            input_ids=enc.input_ids,\n",
    "            attention_mask=enc.attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        # `outputs.hidden_states` is a tuple of length (num_layers+1);\n",
    "        # each element has shape (batch_size, seq_len, hidden_size).\n",
    "        last_hidden = outputs.hidden_states[-1]  # (batch_size, seq_len, hidden_size) on GPU\n",
    "\n",
    "    # 2.5) For each sequence, pick out the final nonpad token embedding\n",
    "    seq_lens = enc.attention_mask.sum(dim=1) - 1  # (batch_size,) on GPU, index of last non-pad\n",
    "    batch_size, hidden_size = last_hidden.size(0), last_hidden.size(2)\n",
    "\n",
    "    # Gather the embedding at position (i, seq_lens[i], :)\n",
    "    final_embs = last_hidden[torch.arange(batch_size), seq_lens, :]  # (batch_size, hidden_size) on GPU\n",
    "    #print((final_embs))\n",
    "    return final_embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ff2419f-79bc-42ba-a15f-a1e0dfa41d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 1152]) cuda:0\n",
      "tensor([[[ 1.4538, -8.0599,  0.6345,  ..., -0.2421,  0.9947,  0.2485]]],\n",
      "       device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "null_emb   = embed_texts([\"<null_val>[sep]<null_val>\"]) \n",
    "# null_emb is already a tensor\n",
    "print(type(null_emb), null_emb.shape, null_emb.device)\n",
    "\n",
    "# add the batchdim, cast & move to DEVICE\n",
    "null_tensor = null_emb.float().unsqueeze(0).to(DEVICE)\n",
    "print(null_tensor, null_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc2a7a44-af28-4112-9044-1f8d8ea17379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottleneckMLP(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (head): Linear(in_features=64, out_features=751, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ckpt = torch.load(\"bottleneck_mlp_newdata.pth\",map_location = \"cuda\",weights_only=False)\n",
    "\n",
    "raw_classes = ckpt.get(\"classes\", None)\n",
    "# Determine number of classes\n",
    "n_old = len(raw_classes) if raw_classes is not None else ckpt[\"model_state_dict\"][\"head.bias\"].shape[0]\n",
    "\n",
    "# Convert classes to Python list\n",
    "if raw_classes is None:\n",
    "    classes = [f\"class_{{i}}\" for i in range(n_old)]\n",
    "elif isinstance(raw_classes, np.ndarray):\n",
    "    classes = raw_classes.tolist()\n",
    "else:\n",
    "    classes = list(raw_classes)\n",
    "# Recreate and load your original BottleneckMLP\n",
    "class BottleneckMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, lat_dim, n_cls):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, lat_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(lat_dim, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.head(z)\n",
    "        return z, logits\n",
    "\n",
    "# Extract dims from checkpoint\n",
    "in_dim     = ckpt[\"model_state_dict\"][\"encoder.0.weight\"].shape[1]\n",
    "hid_dim    = ckpt[\"model_state_dict\"][\"encoder.0.weight\"].shape[0]\n",
    "lat_dim    = ckpt[\"model_state_dict\"][\"encoder.2.weight\"].shape[0]\n",
    "\n",
    "# Instantiate and load weights\n",
    "bottleneck_model = BottleneckMLP(in_dim, hid_dim, lat_dim, n_old).to(device)\n",
    "bottleneck_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "bottleneck_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "513325d2-d77b-4dd3-af72-354941db61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "# 2) grab the weightrow (and optional bias)\n",
    "with torch.no_grad():\n",
    "    w_cls = bottleneck_model.head.weight[idx]     # torch.Tensor of shape (latent_dim,)\n",
    "    b_cls = bottleneck_model.head.bias[idx]       # scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d799955f-7c28-4fee-b150-26596336542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_pair</th>\n",
       "      <th>z</th>\n",
       "      <th>geometry</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>cat_count</th>\n",
       "      <th>weight</th>\n",
       "      <th>hex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activities Related to Real Estate[sep]Resident...</td>\n",
       "      <td>[61.499184, 25.730932, 28.544409, 16.33576, 38...</td>\n",
       "      <td>POINT (-82.52482 27.94908)</td>\n",
       "      <td>Activities Related to Real Estate</td>\n",
       "      <td>24</td>\n",
       "      <td>576</td>\n",
       "      <td>33561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offices of Real Estate Agents and Brokers[sep]...</td>\n",
       "      <td>[10.239435, 8.276576, 44.785103, 72.61034, 19....</td>\n",
       "      <td>POINT (-81.38077 30.19916)</td>\n",
       "      <td>Offices of Real Estate Agents and Brokers</td>\n",
       "      <td>107</td>\n",
       "      <td>11449</td>\n",
       "      <td>52159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sporting Goods, Hobby, and Musical Instrument ...</td>\n",
       "      <td>[23.133112, 20.673256, 16.964842, 24.288828, 2...</td>\n",
       "      <td>POINT (-81.76929 24.5666)</td>\n",
       "      <td>Sporting Goods, Hobby, and Musical Instrument ...</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>44888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offices of Dentists[sep]Offices of Dentists</td>\n",
       "      <td>[21.774567, 62.81708, 77.10956, 94.822975, 61....</td>\n",
       "      <td>POINT (-81.68255 30.20312)</td>\n",
       "      <td>Offices of Dentists</td>\n",
       "      <td>70</td>\n",
       "      <td>4900</td>\n",
       "      <td>46628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Museums, Historical Sites, and Similar Institu...</td>\n",
       "      <td>[48.68053, 51.811516, -0.24616693, 46.184406, ...</td>\n",
       "      <td>POINT (-81.84711 26.64202)</td>\n",
       "      <td>Museums, Historical Sites, and Similar Institu...</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>43514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548012</th>\n",
       "      <td>Home Furnishings Stores[sep]All Other Home Fur...</td>\n",
       "      <td>[33.14433, -0.046613265, 46.66763, 36.16918, 2...</td>\n",
       "      <td>POINT (-81.42641 29.78401)</td>\n",
       "      <td>Home Furnishings Stores</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548013</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[10.560505, 53.101013, 18.382906, 5.375622, 64...</td>\n",
       "      <td>POINT (-81.07024 29.21795)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>56590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548014</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[5.115786, 64.99983, 25.311647, 19.811197, 78....</td>\n",
       "      <td>POINT (-81.32279 29.04255)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>52995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548015</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[13.166652, 72.90378, 16.78043, -0.050964173, ...</td>\n",
       "      <td>POINT (-81.01938 29.24983)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>57118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548016</th>\n",
       "      <td>Urban Transit Systems[sep]Bus and Other Motor ...</td>\n",
       "      <td>[-0.007572128, 67.07022, -0.05944693, 4.877822...</td>\n",
       "      <td>POINT (-80.98888 29.14597)</td>\n",
       "      <td>Urban Transit Systems</td>\n",
       "      <td>33</td>\n",
       "      <td>1089</td>\n",
       "      <td>57647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1678168 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                label_pair  \\\n",
       "0        Activities Related to Real Estate[sep]Resident...   \n",
       "1        Offices of Real Estate Agents and Brokers[sep]...   \n",
       "2        Sporting Goods, Hobby, and Musical Instrument ...   \n",
       "3              Offices of Dentists[sep]Offices of Dentists   \n",
       "4        Museums, Historical Sites, and Similar Institu...   \n",
       "...                                                    ...   \n",
       "1548012  Home Furnishings Stores[sep]All Other Home Fur...   \n",
       "1548013  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548014  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548015  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "1548016  Urban Transit Systems[sep]Bus and Other Motor ...   \n",
       "\n",
       "                                                         z  \\\n",
       "0        [61.499184, 25.730932, 28.544409, 16.33576, 38...   \n",
       "1        [10.239435, 8.276576, 44.785103, 72.61034, 19....   \n",
       "2        [23.133112, 20.673256, 16.964842, 24.288828, 2...   \n",
       "3        [21.774567, 62.81708, 77.10956, 94.822975, 61....   \n",
       "4        [48.68053, 51.811516, -0.24616693, 46.184406, ...   \n",
       "...                                                    ...   \n",
       "1548012  [33.14433, -0.046613265, 46.66763, 36.16918, 2...   \n",
       "1548013  [10.560505, 53.101013, 18.382906, 5.375622, 64...   \n",
       "1548014  [5.115786, 64.99983, 25.311647, 19.811197, 78....   \n",
       "1548015  [13.166652, 72.90378, 16.78043, -0.050964173, ...   \n",
       "1548016  [-0.007572128, 67.07022, -0.05944693, 4.877822...   \n",
       "\n",
       "                           geometry  \\\n",
       "0        POINT (-82.52482 27.94908)   \n",
       "1        POINT (-81.38077 30.19916)   \n",
       "2         POINT (-81.76929 24.5666)   \n",
       "3        POINT (-81.68255 30.20312)   \n",
       "4        POINT (-81.84711 26.64202)   \n",
       "...                             ...   \n",
       "1548012  POINT (-81.42641 29.78401)   \n",
       "1548013  POINT (-81.07024 29.21795)   \n",
       "1548014  POINT (-81.32279 29.04255)   \n",
       "1548015  POINT (-81.01938 29.24983)   \n",
       "1548016  POINT (-80.98888 29.14597)   \n",
       "\n",
       "                                                  cat_name  cat_count  weight  \\\n",
       "0                        Activities Related to Real Estate         24     576   \n",
       "1                Offices of Real Estate Agents and Brokers        107   11449   \n",
       "2        Sporting Goods, Hobby, and Musical Instrument ...          7      49   \n",
       "3                                      Offices of Dentists         70    4900   \n",
       "4        Museums, Historical Sites, and Similar Institu...          8      64   \n",
       "...                                                    ...        ...     ...   \n",
       "1548012                            Home Furnishings Stores          1       1   \n",
       "1548013                              Urban Transit Systems         16     256   \n",
       "1548014                              Urban Transit Systems          8      64   \n",
       "1548015                              Urban Transit Systems         30     900   \n",
       "1548016                              Urban Transit Systems         33    1089   \n",
       "\n",
       "        hex_id  \n",
       "0        33561  \n",
       "1        52159  \n",
       "2        44888  \n",
       "3        46628  \n",
       "4        43514  \n",
       "...        ...  \n",
       "1548012  51477  \n",
       "1548013  56590  \n",
       "1548014  52995  \n",
       "1548015  57118  \n",
       "1548016  57647  \n",
       "\n",
       "[1678168 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a250c7-1f4d-4d20-a17a-6e1188765df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_vec(x):\n",
    "    # detect the NaN (it's a float)\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return (w_cls+b_cls).cpu().detach().numpy()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#ses_gdf['vec_mean'] = ses_gdf['vec_mean'].apply(fill_vec)\n",
    "\n",
    "\n",
    "#hex_gdf['vec_max'] = hex_gdf['vec_max'].apply(fill_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b919cf-c6af-49af-b0ff-173c83e75918",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c331c1fd-16ab-46dd-aee4-36bf27d7c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"point_gdf_raw.pickle\",\"rb\") as f:\n",
    "    point_gdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95879bfe-2c37-4197-9341-f2cd5ebdac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf = gpd.read_parquet(\"simulated_traj_points.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd438a72-9923-4558-971a-e3f4d6ad0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "377d6b12-3aa3-4e53-9288-8fc578355dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_2673/3162613191.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted_avg = ( joined .groupby('hex_id') .apply(lambda df: (np.stack(df['z'].values) * df['weight'].values[:, None]).sum(axis=0) / df['weight'].sum() ) )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# 1) extract just the category name (before [sep]) \n",
    "joined = joined.copy()\n",
    "joined['cat_name'] = joined['label_pair'].str.split(r'\\[sep\\]').str[0] \n",
    "# 2) compute the count per (hex_id, cat_name) and square it \n",
    "joined['cat_count'] = joined.groupby(['hex_id','cat_name'])['z'].transform('count') \n",
    "joined['weight'] = joined['cat_count'] ** 2 \n",
    "# 4) (optional) weightedaverage instead of sum \n",
    "weighted_avg = ( joined .groupby('hex_id') .apply(lambda df: (np.stack(df['z'].values) * df['weight'].values[:, None]).sum(axis=0) / df['weight'].sum() ) )\n",
    "\n",
    "# 5) merge back into your hex_gdf \n",
    "ses_gdf = ses_gdf.merge( weighted_avg.rename('vec_weighted_avg'), left_on='hex_id', right_index=True, how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "299851ce-0e6a-4583-9e97-6c7182190d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf['vec_weighted_avg'] = ses_gdf['vec_weighted_avg'].apply(fill_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd0330-99e3-4c1d-81f8-e5ce127eda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2e0ea77-2704-48b8-802a-f1b0617ca63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = ses_gdf.merge(merged, on=\"hex_id\", how=\"left\",suffixes=(None,\"_y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68f025c5-85b7-4361-91c9-5c3648bd2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.loc[:, ~new_df.columns.str.endswith(\"_y\")]   # drop all right duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d2291-f9fa-4d2b-9678-fd97efa1911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08221c88-2b96-48a4-8d08-25f019d2e713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   traj_id  pt_idx  \\\n",
      "0        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       1   \n",
      "1        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       3   \n",
      "2        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       5   \n",
      "3        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      20   \n",
      "4        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      21   \n",
      "...                                                    ...     ...   \n",
      "1677305  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     130   \n",
      "1677306  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     133   \n",
      "1677307  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     134   \n",
      "1677308  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     140   \n",
      "1677309  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     141   \n",
      "\n",
      "                           geometry  index_right         GEOID NAME  hex_id  \\\n",
      "0        POINT (-81.79671 24.54831)         9176  120879724002    2    9176   \n",
      "1        POINT (-81.79674 24.54832)         9176  120879724002    2    9176   \n",
      "2        POINT (-81.79665 24.54831)         9176  120879724002    2    9176   \n",
      "3        POINT (-81.94936 26.45101)         8345  120710601021    1    8345   \n",
      "4         POINT (-81.9493 26.45101)         8345  120710601021    1    8345   \n",
      "...                             ...          ...           ...  ...     ...   \n",
      "1677305  POINT (-81.50477 29.94249)        11002  121090209054    4   11002   \n",
      "1677306        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677307        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677308  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "1677309  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "\n",
      "                                                vec_mean_x  \\\n",
      "0        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "1        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "2        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "3        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "4        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "...                                                    ...   \n",
      "1677305  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677306  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677307  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677308  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677309  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "\n",
      "                                           graph_embedding  \\\n",
      "0        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "1        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "2        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "3        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "4        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "...                                                    ...   \n",
      "1677305  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677306  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677307  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677308  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677309  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "\n",
      "                                          vec_weighted_avg  ...  \\\n",
      "0        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "1        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "2        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "3        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "4        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "...                                                    ...  ...   \n",
      "1677305  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677306  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677307  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677308  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677309  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan  \\\n",
      "0                                                      170         \n",
      "1                                                      170         \n",
      "2                                                      170         \n",
      "3                                                      151         \n",
      "4                                                      151         \n",
      "...                                                    ...         \n",
      "1677305                                                775         \n",
      "1677306                                               2033         \n",
      "1677307                                               2033         \n",
      "1677308                                                775         \n",
      "1677309                                                775         \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                        \n",
      "1                                                        0                                                                        \n",
      "2                                                        0                                                                        \n",
      "3                                                       21                                                                        \n",
      "4                                                       21                                                                        \n",
      "...                                                    ...                                                                        \n",
      "1677305                                                 19                                                                        \n",
      "1677306                                                267                                                                        \n",
      "1677307                                                267                                                                        \n",
      "1677308                                                 19                                                                        \n",
      "1677309                                                 19                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
      "0                                                      197                                  \n",
      "1                                                      197                                  \n",
      "2                                                      197                                  \n",
      "3                                                      130                                  \n",
      "4                                                      130                                  \n",
      "...                                                    ...                                  \n",
      "1677305                                                722                                  \n",
      "1677306                                               1850                                  \n",
      "1677307                                               1850                                  \n",
      "1677308                                                722                                  \n",
      "1677309                                                722                                  \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
      "0                                                       46                                                                                                                          \n",
      "1                                                       46                                                                                                                          \n",
      "2                                                       46                                                                                                                          \n",
      "3                                                        0                                                                                                                          \n",
      "4                                                        0                                                                                                                          \n",
      "...                                                    ...                                                                                                                          \n",
      "1677305                                                 12                                                                                                                          \n",
      "1677306                                                 84                                                                                                                          \n",
      "1677307                                                 84                                                                                                                          \n",
      "1677308                                                 12                                                                                                                          \n",
      "1677309                                                 12                                                                                                                          \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service  \\\n",
      "0                                                       19                 \n",
      "1                                                       19                 \n",
      "2                                                       19                 \n",
      "3                                                        0                 \n",
      "4                                                        0                 \n",
      "...                                                    ...                 \n",
      "1677305                                                 64                 \n",
      "1677306                                                135                 \n",
      "1677307                                                135                 \n",
      "1677308                                                 64                 \n",
      "1677309                                                 64                 \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                                        \n",
      "1                                                        0                                                                                        \n",
      "2                                                        0                                                                                        \n",
      "3                                                        0                                                                                        \n",
      "4                                                        0                                                                                        \n",
      "...                                                    ...                                                                                        \n",
      "1677305                                                  0                                                                                        \n",
      "1677306                                                 51                                                                                        \n",
      "1677307                                                 51                                                                                        \n",
      "1677308                                                  0                                                                                        \n",
      "1677309                                                  0                                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                \n",
      "1                                                        0                                                \n",
      "2                                                        0                                                \n",
      "3                                                        0                                                \n",
      "4                                                        0                                                \n",
      "...                                                    ...                                                \n",
      "1677305                                                  0                                                \n",
      "1677306                                                  0                                                \n",
      "1677307                                                  0                                                \n",
      "1677308                                                  0                                                \n",
      "1677309                                                  0                                                \n",
      "\n",
      "         Total: Internet access without a subscription  \\\n",
      "0                                                   24   \n",
      "1                                                   24   \n",
      "2                                                   24   \n",
      "3                                                    0   \n",
      "4                                                    0   \n",
      "...                                                ...   \n",
      "1677305                                              0   \n",
      "1677306                                              0   \n",
      "1677307                                              0   \n",
      "1677308                                              0   \n",
      "1677309                                              0   \n",
      "\n",
      "         Total: No Internet access                        centroid  \n",
      "0                               64  POINT (1453140.506 277480.406)  \n",
      "1                               64  POINT (1453140.506 277480.406)  \n",
      "2                               64  POINT (1453140.506 277480.406)  \n",
      "3                               11   POINT (1407206.808 481749.98)  \n",
      "4                               11   POINT (1407206.808 481749.98)  \n",
      "...                            ...                             ...  \n",
      "1677305                         97   POINT (1392576.532 868512.68)  \n",
      "1677306                         20  POINT (1384276.061 882178.015)  \n",
      "1677307                         20  POINT (1384276.061 882178.015)  \n",
      "1677308                         97   POINT (1392576.532 868512.68)  \n",
      "1677309                         97   POINT (1392576.532 868512.68)  \n",
      "\n",
      "[1677317 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "point_buffer = point_gdf.to_crs(epsg=5070)\n",
    "ses_buffer = new_df.to_crs(epsg=5070)\n",
    "ses_buffer[\"centroid\"] = ses_buffer.centroid\n",
    "ses_gdf = ses_buffer.to_crs(epsg=4326)\n",
    "\n",
    "joined_nearest_ll = gpd.sjoin_nearest(\n",
    "    point_buffer[[\"traj_id\", \"pt_idx\", \"geometry\"]],  # keep only the columns we care about\n",
    "    ses_buffer.loc[:, ses_buffer.columns != 'NAME_x'],\n",
    "    how=\"left\"           # keep all points; hex attributes will be NaN if a point is unmatche\n",
    ")\n",
    "joined_nearest = joined_nearest_ll.to_crs(epsg=4326)\n",
    "print(joined_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41337ed5-63ed-4227-8feb-580cc0926c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n",
      "                                                   traj_id  pt_idx  \\\n",
      "0        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       1   \n",
      "1        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       3   \n",
      "2        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...       5   \n",
      "3        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      20   \n",
      "4        e464d76fd1b9ea6e0c135c0292581eccc3f27306fb76af...      21   \n",
      "...                                                    ...     ...   \n",
      "1677305  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     130   \n",
      "1677306  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     133   \n",
      "1677307  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     134   \n",
      "1677308  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     140   \n",
      "1677309  559f9e9acaaf7e32ea1c7b2616af890a63a5fd8ebd2a54...     141   \n",
      "\n",
      "                           geometry  index_right         GEOID NAME  hex_id  \\\n",
      "0        POINT (-81.79671 24.54831)         9176  120879724002    2    9176   \n",
      "1        POINT (-81.79674 24.54832)         9176  120879724002    2    9176   \n",
      "2        POINT (-81.79665 24.54831)         9176  120879724002    2    9176   \n",
      "3        POINT (-81.94936 26.45101)         8345  120710601021    1    8345   \n",
      "4         POINT (-81.9493 26.45101)         8345  120710601021    1    8345   \n",
      "...                             ...          ...           ...  ...     ...   \n",
      "1677305  POINT (-81.50477 29.94249)        11002  121090209054    4   11002   \n",
      "1677306        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677307        POINT (-81.55 30.08)         7464  121090208101    1    7464   \n",
      "1677308  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "1677309  POINT (-81.51031 29.94435)        11002  121090209054    4   11002   \n",
      "\n",
      "                                                vec_mean_x  \\\n",
      "0        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "1        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "2        [39.898567, 29.886007, 28.239742, 34.788887, 3...   \n",
      "3        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "4        [38.080627, 36.839676, 27.342834, 41.295727, 3...   \n",
      "...                                                    ...   \n",
      "1677305  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677306  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677307  [36.006824, 36.27089, 22.879541, 44.129734, 32...   \n",
      "1677308  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "1677309  [42.32178, 33.864525, 27.697332, 40.768707, 34...   \n",
      "\n",
      "                                           graph_embedding  \\\n",
      "0        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "1        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "2        [0.48170986771583557, -0.4748258888721466, 1.1...   \n",
      "3        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "4        [0.5281789302825928, -0.45248809456825256, 0.2...   \n",
      "...                                                    ...   \n",
      "1677305  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677306  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677307  [0.2619738280773163, -1.6541885137557983, 0.12...   \n",
      "1677308  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "1677309  [0.6872388124465942, 0.08394274860620499, 0.18...   \n",
      "\n",
      "                                          vec_weighted_avg  ...  \\\n",
      "0        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "1        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "2        [45.11307119630071, 35.11725188464218, 26.1997...  ...   \n",
      "3        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "4        [53.609417053751564, 52.95326092408832, 32.942...  ...   \n",
      "...                                                    ...  ...   \n",
      "1677305  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677306  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677307  [29.38034627414709, 33.97991262758591, 14.3839...  ...   \n",
      "1677308  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "1677309  [41.46378429641826, 32.18224331231042, 21.6450...  ...   \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan  \\\n",
      "0                                                      170         \n",
      "1                                                      170         \n",
      "2                                                      170         \n",
      "3                                                      151         \n",
      "4                                                      151         \n",
      "...                                                    ...         \n",
      "1677305                                                775         \n",
      "1677306                                               2033         \n",
      "1677307                                               2033         \n",
      "1677308                                                775         \n",
      "1677309                                                775         \n",
      "\n",
      "         Total: With an Internet subscription Cellular data plan Cellular data plan with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                        \n",
      "1                                                        0                                                                        \n",
      "2                                                        0                                                                        \n",
      "3                                                       21                                                                        \n",
      "4                                                       21                                                                        \n",
      "...                                                    ...                                                                        \n",
      "1677305                                                 19                                                                        \n",
      "1677306                                                267                                                                        \n",
      "1677307                                                267                                                                        \n",
      "1677308                                                 19                                                                        \n",
      "1677309                                                 19                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL  \\\n",
      "0                                                      197                                  \n",
      "1                                                      197                                  \n",
      "2                                                      197                                  \n",
      "3                                                      130                                  \n",
      "4                                                      130                                  \n",
      "...                                                    ...                                  \n",
      "1677305                                                722                                  \n",
      "1677306                                               1850                                  \n",
      "1677307                                               1850                                  \n",
      "1677308                                                722                                  \n",
      "1677309                                                722                                  \n",
      "\n",
      "         Total: With an Internet subscription Broadband such as cable, fiber optic or DSL Broadband such as cable, fiber optic or DSL with no other type of Internet subscription  \\\n",
      "0                                                       46                                                                                                                          \n",
      "1                                                       46                                                                                                                          \n",
      "2                                                       46                                                                                                                          \n",
      "3                                                        0                                                                                                                          \n",
      "4                                                        0                                                                                                                          \n",
      "...                                                    ...                                                                                                                          \n",
      "1677305                                                 12                                                                                                                          \n",
      "1677306                                                 84                                                                                                                          \n",
      "1677307                                                 84                                                                                                                          \n",
      "1677308                                                 12                                                                                                                          \n",
      "1677309                                                 12                                                                                                                          \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service  \\\n",
      "0                                                       19                 \n",
      "1                                                       19                 \n",
      "2                                                       19                 \n",
      "3                                                        0                 \n",
      "4                                                        0                 \n",
      "...                                                    ...                 \n",
      "1677305                                                 64                 \n",
      "1677306                                                135                 \n",
      "1677307                                                135                 \n",
      "1677308                                                 64                 \n",
      "1677309                                                 64                 \n",
      "\n",
      "         Total: With an Internet subscription Satellite Internet service Satellite Internet service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                                                        \n",
      "1                                                        0                                                                                        \n",
      "2                                                        0                                                                                        \n",
      "3                                                        0                                                                                        \n",
      "4                                                        0                                                                                        \n",
      "...                                                    ...                                                                                        \n",
      "1677305                                                  0                                                                                        \n",
      "1677306                                                 51                                                                                        \n",
      "1677307                                                 51                                                                                        \n",
      "1677308                                                  0                                                                                        \n",
      "1677309                                                  0                                                                                        \n",
      "\n",
      "         Total: With an Internet subscription Other service with no other type of Internet subscription  \\\n",
      "0                                                        0                                                \n",
      "1                                                        0                                                \n",
      "2                                                        0                                                \n",
      "3                                                        0                                                \n",
      "4                                                        0                                                \n",
      "...                                                    ...                                                \n",
      "1677305                                                  0                                                \n",
      "1677306                                                  0                                                \n",
      "1677307                                                  0                                                \n",
      "1677308                                                  0                                                \n",
      "1677309                                                  0                                                \n",
      "\n",
      "         Total: Internet access without a subscription  \\\n",
      "0                                                   24   \n",
      "1                                                   24   \n",
      "2                                                   24   \n",
      "3                                                    0   \n",
      "4                                                    0   \n",
      "...                                                ...   \n",
      "1677305                                              0   \n",
      "1677306                                              0   \n",
      "1677307                                              0   \n",
      "1677308                                              0   \n",
      "1677309                                              0   \n",
      "\n",
      "         Total: No Internet access                        centroid  \n",
      "0                               64  POINT (1453140.506 277480.406)  \n",
      "1                               64  POINT (1453140.506 277480.406)  \n",
      "2                               64  POINT (1453140.506 277480.406)  \n",
      "3                               11   POINT (1407206.808 481749.98)  \n",
      "4                               11   POINT (1407206.808 481749.98)  \n",
      "...                            ...                             ...  \n",
      "1677305                         97   POINT (1392576.532 868512.68)  \n",
      "1677306                         20  POINT (1384276.061 882178.015)  \n",
      "1677307                         20  POINT (1384276.061 882178.015)  \n",
      "1677308                         97   POINT (1392576.532 868512.68)  \n",
      "1677309                         97   POINT (1392576.532 868512.68)  \n",
      "\n",
      "[1677310 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "clean_joined = joined_nearest.drop_duplicates(subset=[\"traj_id\", \"pt_idx\"])\n",
    "print(clean_joined.crs)\n",
    "\n",
    "print(clean_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb138ab1-8a2b-4b11-a2f4-349d9a506084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d1903-6a37-4e87-8e0d-65f64cb48a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined.vec_weighted_avg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2a150-40c0-47dd-aca1-467fbc157bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "373d28eb-de49-4e85-8747-cdfb3d1275ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_joined.copy()\n",
    "feature_dict = {}\n",
    "timeidx_dict = {}\n",
    "df[\"vec_weighted_avg\"] = df[\"vec_weighted_avg\"].apply(fill_vec)\n",
    "FIXED_LEN=143\n",
    "for traj_id, group in df.groupby('traj_id'):\n",
    "    grp = group.sort_values('pt_idx')\n",
    "    embs = np.stack(grp['graph_embedding'].values)    # (L, E)\n",
    "    vecs = np.stack(grp['vec_weighted_avg'].values)   # (L, V)\n",
    "    feature_dict[traj_id] = np.concatenate([embs, vecs], axis=1)  # (L, E+V)\n",
    "    # time indices must be integers in [0..FIXED_LEN-1]\n",
    "    # if pt_idx is 1-based you may want pt_idx-1; also clamp to FIXED_LEN-1\n",
    "    times = grp['pt_idx'].to_numpy().astype(int) - 1      \n",
    "    times = np.clip(times, 0, FIXED_LEN-1)\n",
    "    timeidx_dict[traj_id] = times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b5a459-4796-4a53-953e-cd239525a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajDatasetWithTimes(Dataset):\n",
    "    def __init__(self, feature_dict, timeidx_dict):\n",
    "        self.ids       = list(feature_dict.keys())\n",
    "        self.features  = feature_dict\n",
    "        self.times     = timeidx_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        traj_id = self.ids[i]\n",
    "        feat    = torch.from_numpy(self.features[traj_id]).float()  # (L, D)\n",
    "        times   = torch.from_numpy(self.times[traj_id]).long()     # (L,)\n",
    "        return feat, times, i, traj_id\n",
    "\n",
    "# 3) Custom collate that scatters each sample into its true time slots\n",
    "def collate_fn_time(batch):\n",
    "    B = len(batch)\n",
    "    feats, times_list, idxs = zip(*batch)\n",
    "    D = feats[0].size(1)\n",
    "\n",
    "    padded   = torch.zeros(B, FIXED_LEN, D, dtype=torch.float)\n",
    "    pad_mask = torch.ones (B, FIXED_LEN,    dtype=torch.bool)\n",
    "\n",
    "    for i, (feat, times) in enumerate(zip(feats, times_list)):\n",
    "        valid     = times < FIXED_LEN\n",
    "        t_idx     = times[valid]\n",
    "        f_vec     = feat[valid]         # shape (L_valid, D)\n",
    "        padded[i, t_idx]   = f_vec\n",
    "        pad_mask[i, t_idx] = False\n",
    "\n",
    "    idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "    return padded, pad_mask, idxs\n",
    "\n",
    "# 4) Build loaders\n",
    "\n",
    "\n",
    "#  Positional Encoding \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                        -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]  # broadcast-add\n",
    "\n",
    "\n",
    "#  DEC Loss Components \n",
    "def student_t_distribution(z, centers, alpha=1.0):\n",
    "    diff = z.unsqueeze(1) - centers.unsqueeze(0)\n",
    "    dist2 = diff.pow(2).sum(-1)\n",
    "    num = (1 + dist2/alpha).pow(-(alpha+1)/2)\n",
    "    return num / num.sum(1, keepdim=True)\n",
    "\n",
    "def target_distribution(q):\n",
    "    weight = q.pow(2) / q.sum(0, keepdim=True)\n",
    "    return (weight / weight.sum(1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2faa5509-a944-405f-9574-a873760f1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# ---- Positional encoding with 24h time-of-day ----\n",
    "class PositionalEncodingTimeOfDay(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 500, hod_harmonics: int = 1):\n",
    "        \"\"\"\n",
    "        d_model: model dimension\n",
    "        max_len: max sequence length for absolute PE\n",
    "        hod_harmonics: number of 24h harmonics (1 => sin/cos; 2+ adds higher freq)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Absolute sinusoidal PE (as you had)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float)\n",
    "            * (-(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)  # (1, max_len, d_model)\n",
    "\n",
    "        # 24h cyclic features -> project to d_model, then add\n",
    "        self.hod_harmonics = int(hod_harmonics)\n",
    "        self.hod_proj = nn.Linear(2 * self.hod_harmonics, d_model, bias=False)\n",
    "        # learnable gate so the model can scale this signal\n",
    "        self.hod_scale = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _hours_from_start(self, B, L, device, start_hour):\n",
    "        idx = torch.arange(L, device=device).view(1, L)  # 0..L-1\n",
    "        if isinstance(start_hour, int):\n",
    "            start = torch.full((B, 1), start_hour, device=device, dtype=torch.long)\n",
    "        else:\n",
    "            start = torch.as_tensor(start_hour, device=device).view(B, 1).long()\n",
    "        return (start + idx) % 24  # (B, L)\n",
    "\n",
    "    def forward(self, x, *, hours: torch.Tensor = None, start_hour=None):\n",
    "        \"\"\"\n",
    "        x: (B, L, d_model)\n",
    "        hours: optional (B, L) int tensor in [0..23]\n",
    "        start_hour: optional int or (B,) tensor; used if `hours` is None\n",
    "        \"\"\"\n",
    "        B, L, D = x.shape\n",
    "\n",
    "        # absolute PE\n",
    "        out = x + self.pe[:, :L]\n",
    "\n",
    "        # time-of-day PE\n",
    "        if hours is None:\n",
    "            if start_hour is None:\n",
    "                raise ValueError(\"Provide `hours` (B,L ints 0..23) or `start_hour` (int or (B,) tensor).\")\n",
    "            hours = self._hours_from_start(B, L, x.device, start_hour)\n",
    "        else:\n",
    "            hours = torch.as_tensor(hours, device=x.device).long()\n",
    "            if hours.shape != (B, L):\n",
    "                raise ValueError(f\"`hours` must be (B, L), got {hours.shape}\")\n",
    "\n",
    "        phase = 2 * math.pi * (hours.float() / 24.0)  # (B, L)\n",
    "        feats = []\n",
    "        for m in range(1, self.hod_harmonics + 1):\n",
    "            feats.append(torch.sin(m * phase))\n",
    "            feats.append(torch.cos(m * phase))\n",
    "        hod = torch.stack(feats, dim=-1)              # (B, L, 2*M)\n",
    "        hod = self.hod_proj(hod) * self.hod_scale     # (B, L, d_model)\n",
    "\n",
    "        return out + hod\n",
    "\n",
    "\n",
    "# ---- Your model, modified to accept hours/start_hour and lengths ----\n",
    "class TrajTransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=16, num_layers=3, dropout=0.1,\n",
    "                 max_len=500, hod_harmonics=1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # replace with time-of-day aware PE\n",
    "        self.pos_enc = PositionalEncodingTimeOfDay(d_model, max_len=max_len,\n",
    "                                                   hod_harmonics=hod_harmonics)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward=512, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model, nhead, dim_feedforward=512, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def _make_padding_mask(self, lengths, L, device):\n",
    "        # True where we want to MASK (i.e., padding positions)\n",
    "        if lengths is None:\n",
    "            return None\n",
    "        lengths = torch.as_tensor(lengths, device=device).long()  # (B,)\n",
    "        idx = torch.arange(L, device=device).unsqueeze(0)         # (1, L)\n",
    "        return (idx >= lengths.unsqueeze(1))                      # (B, L) boolean\n",
    "\n",
    "    def forward(self, x, lengths=None, src_key_padding_mask=None,\n",
    "                hours: torch.Tensor = None, start_hour=None):\n",
    "        \"\"\"\n",
    "        x: (B, L, D_in)\n",
    "        lengths: optional (B,) true lengths (for masks)\n",
    "        hours: optional (B, L) integers 0..23 (time-of-day for each token)\n",
    "        start_hour: optional int or (B,) if `hours` not provided\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # masks\n",
    "        if src_key_padding_mask is None:\n",
    "            src_key_padding_mask = self._make_padding_mask(lengths, L, device)\n",
    "\n",
    "        # ---- Encoder path\n",
    "        src_emb = self.input_proj(x)  # (B, L, d_model)\n",
    "        src_emb = self.pos_enc(src_emb, hours=hours, start_hour=start_hour)  # add abs + 24h\n",
    "        memory = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # ---- Decoder input: zeros + SAME positions & hours (we reconstruct x at same steps)\n",
    "        tgt_emb = torch.zeros(B, L, memory.size(-1), device=device)\n",
    "        # pass the same hours/start_hour so decoder knows positions and day phase, too\n",
    "        tgt_emb = self.pos_enc(tgt_emb, hours=hours, start_hour=start_hour)\n",
    "\n",
    "        # If you have padding, use the same mask for tgt and memory padding mask\n",
    "        output_seq = self.decoder(tgt_emb, memory,\n",
    "                                  tgt_key_padding_mask=src_key_padding_mask,\n",
    "                                  memory_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        recon = self.output_layer(output_seq)  # (B, L, input_dim)\n",
    "        z = memory.mean(dim=1)                 # (B, d_model) latent embedding\n",
    "        return recon, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eb5a488-12cb-4b86-99c0-415f03f9f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "FIXED_LEN = 143\n",
    "\n",
    "class TrajDatasetWithTimes(Dataset):\n",
    "    def __init__(self, feature_dict, timeidx_dict):\n",
    "        self.ids       = list(feature_dict.keys())\n",
    "        self.features  = feature_dict\n",
    "        self.times     = timeidx_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        traj_id = self.ids[i]\n",
    "        feat    = torch.from_numpy(self.features[traj_id]).float()  # (L, D) may contain NaNs\n",
    "        times   = torch.from_numpy(self.times[traj_id]).long()      # (L,)\n",
    "        return feat, times, i, traj_id\n",
    "\n",
    "\n",
    "def make_collate_fn_time(fixed_len=143, start_hour=0, fill_value=0.0):\n",
    "    def collate_fn_time(batch):\n",
    "        B = len(batch)\n",
    "        feats, times_list, idxs, traj_ids = zip(*batch)\n",
    "        D = feats[0].size(1)\n",
    "\n",
    "        padded   = torch.full((B, fixed_len, D), fill_value, dtype=torch.float)\n",
    "        pad_mask = torch.ones (B, fixed_len,      dtype=torch.bool)\n",
    "        obs_mask = torch.zeros(B, fixed_len, D,   dtype=torch.bool)\n",
    "\n",
    "        for i, (feat, times) in enumerate(zip(feats, times_list)):\n",
    "            # 1) keep only indices within range\n",
    "            valid = (times >= 0) & (times < fixed_len)\n",
    "            t = times[valid]           # (N,)\n",
    "            f = feat[valid]            # (N, D)\n",
    "\n",
    "            if t.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            # 2) per-row observed flags and NaN-safe features\n",
    "            obs_row   = torch.isfinite(f).to(f.dtype)         # (N, D) 1.0 where observed\n",
    "            f_clean   = torch.nan_to_num(f, nan=0.0)          # (N, D)\n",
    "\n",
    "            # 3) aggregate duplicates by unique time index\n",
    "            uniq, inv = torch.unique(t, return_inverse=True)  # uniq: (M,), inv: (N,)\n",
    "            M = uniq.numel()\n",
    "\n",
    "            # sum of values per (uniq time, feature)\n",
    "            sum_feat = torch.zeros(M, D, dtype=f.dtype)\n",
    "            sum_feat.index_add_(0, inv, f_clean)\n",
    "\n",
    "            # count of observed entries per (uniq time, feature)\n",
    "            cnt_feat = torch.zeros(M, D, dtype=f.dtype)\n",
    "            cnt_feat.index_add_(0, inv, obs_row)\n",
    "\n",
    "            # mean over observed entries (stay 0 where count==0)\n",
    "            mean_feat = sum_feat / cnt_feat.clamp_min(1.0)    # (M, D)\n",
    "            obs_u     = cnt_feat > 0                           # (M, D) bool\n",
    "\n",
    "            # 4) write once per unique index (no overlapping writes)\n",
    "            padded[i, uniq]   = mean_feat\n",
    "            obs_mask[i, uniq] = obs_u\n",
    "            pad_mask[i, uniq] = False\n",
    "\n",
    "        # hours-of-day (independent storage; safe even if later modified)\n",
    "        hours_row = (torch.arange(fixed_len) + int(start_hour)) % 24  # (fixed_len,)\n",
    "        hours = hours_row.unsqueeze(0).repeat(B, 1).long()            # (B, L)\n",
    "\n",
    "        idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "        return padded, pad_mask, obs_mask, hours, idxs, list(traj_ids)\n",
    "    return collate_fn_time\n",
    "\n",
    "\n",
    "# ---- Build loader ----\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = TrajDatasetWithTimes(feature_dict, timeidx_dict)\n",
    "\n",
    "collate_fn = make_collate_fn_time(fixed_len=FIXED_LEN, start_hour=0)  # all sequences start at 01 AM\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,                 # better for SGD\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=(DEVICE.type == 'cuda'),\n",
    "    # num_workers=4,              # enable if your environment supports it\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29676d93-9cfc-47b7-bc8d-c815a2c55791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92ccde80-af02-4e97-98c1-0534b70784da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/582147.tmpdir/ipykernel_2014/2710695643.py:58: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Assumes:\n",
    "#  - TrajDatasetWithTimes + make_collate_fn_time defined as in your last message\n",
    "#  - TrajTransformerAutoencoder uses the time-of-day PE (accepts hours=... or start_hour=...)\n",
    "#  - feature_dict, timeidx_dict already built\n",
    "\n",
    "# -------------------- SPLIT --------------------\n",
    "dataset = TrajDatasetWithTimes(feature_dict, timeidx_dict)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "all_idx = np.arange(len(dataset))\n",
    "rng.shuffle(all_idx)\n",
    "\n",
    "n = len(all_idx)\n",
    "n_train = int(0.80 * n)\n",
    "n_val   = int(0.10 * n)\n",
    "idx_train = all_idx[:n_train]\n",
    "idx_val   = all_idx[n_train:n_train+n_val]\n",
    "idx_test  = all_idx[n_train+n_val:]\n",
    "\n",
    "train_ds = Subset(dataset, idx_train)\n",
    "val_ds   = Subset(dataset, idx_val)\n",
    "test_ds  = Subset(dataset, idx_test)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "collate_fn = make_collate_fn_time(fixed_len=143, start_hour=0)\n",
    "\n",
    "BS = 128\n",
    "train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BS, shuffle=False,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BS, shuffle=False,\n",
    "                          collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda'))\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "model = TrajTransformerAutoencoder(\n",
    "    input_dim=128, d_model=64, nhead=8, num_layers=4, dropout=0.1,\n",
    "    max_len=143, hod_harmonics=1\n",
    ").to(DEVICE)\n",
    "\n",
    "# -------------------- TRAINING CONFIG --------------------\n",
    "num_epochs       = 1000\n",
    "warmup_epochs    = 100\n",
    "lambda_l2_target = 1.0\n",
    "patience         = 30\n",
    "checkpoint_path  = \"./models/best_model_tod_2.pth\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "opt       = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epochs)\n",
    "use_amp   = (DEVICE.type == \"cuda\")\n",
    "scaler    = GradScaler(enabled=use_amp)\n",
    "max_grad  = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7b76c1c-ef28-476c-8d10-c2d434a9c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== helpers (MSE path) ====================================================\n",
    "@torch.no_grad()\n",
    "def estimate_feature_stats(loader, device):\n",
    "    \"\"\"Per-feature mean/std over observed, non-padded entries only.\"\"\"\n",
    "    sum_, sumsq, count = None, None, None\n",
    "    for x, pad_mask, obs_mask, *_ in loader:\n",
    "        x        = x.to(device)                  # (B,L,D)\n",
    "        pad_mask = pad_mask.to(device).bool()    # (B,L)\n",
    "        obs_mask = obs_mask.to(device).bool()    # (B,L,D)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)   # (B,L,D)\n",
    "        v = valid.float()\n",
    "        if sum_ is None:\n",
    "            D = x.size(-1)\n",
    "            sum_  = torch.zeros(D, device=device)\n",
    "            sumsq = torch.zeros(D, device=device)\n",
    "            count = torch.zeros(D, device=device)\n",
    "        sum_  += (x * v).sum(dim=(0,1))\n",
    "        sumsq += ((x * x) * v).sum(dim=(0,1))\n",
    "        count += v.sum(dim=(0,1))\n",
    "    mean = sum_ / count.clamp_min(1.0)\n",
    "    var  = (sumsq / count.clamp_min(1.0)) - mean.pow(2)\n",
    "    std  = var.clamp_min(1e-6).sqrt()\n",
    "    return mean.detach(), std.detach()\n",
    "def standardize_batch(x, obs_mask, mean, std, pad_mask=None):\n",
    "    \"\"\"Return (x_in_for_model, x_std_target) in standardized units.\"\"\"\n",
    "    x_std = (x - mean.view(1,1,-1)) / std.view(1,1,-1)\n",
    "    x_in  = x_std.masked_fill(~obs_mask, 0.0)\n",
    "    if pad_mask is not None:\n",
    "        x_in = x_in.masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "    return x_in, x_std\n",
    "\n",
    "def masked_mse(recon, x_std_target, pad_mask, obs_mask):\n",
    "    valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "    diff  = (recon - x_std_target)[valid]\n",
    "    return (diff * diff).mean()\n",
    "\n",
    "def masked_huber(recon, x_std_target, pad_mask, obs_mask, delta=1.0):\n",
    "    valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "    diff  = (recon - x_std_target)[valid]\n",
    "    absd  = diff.abs()\n",
    "    quad  = torch.minimum(absd, torch.tensor(delta, device=diff.device))\n",
    "    return (0.5 * quad.pow(2) + delta * (absd - quad)).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"Standardized MSE over observed & non-padded entries.\"\"\"\n",
    "    model.eval()\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "        recon, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (recon - x_std_tgt)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_original_scale(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"MSE in ORIGINAL units; inputs preprocessed same as training (std + zeros).\"\"\"\n",
    "    model.eval()\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_in, _ = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "        recon_std, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        recon = recon_std * feat_std.view(1,1,-1) + feat_mean.view(1,1,-1)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (recon - x)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_null_zero(loader, device, feat_mean, feat_std):\n",
    "    total_sse, total_n = 0.0, 0.0\n",
    "    for x, pad_mask, obs_mask, *_ in loader:\n",
    "        x, pad_mask, obs_mask = x.to(device), pad_mask.to(device).bool(), obs_mask.to(device).bool()\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        pred  = torch.zeros_like(x_std)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        diff  = (pred - x_std)[valid]\n",
    "        total_sse += float((diff * diff).sum().item())\n",
    "        total_n   += float(valid.sum().item())\n",
    "    return total_sse / max(1.0, total_n)\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "837a5c90-b42a-4283-8e18-6d9ab3da3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume] Loaded checkpoint from './models/best_model_tod_3.pth' at epoch 303, best_val=0.123534\n",
      " Test MSE (std): 0.123172   |  Test MSE (orig): 5.906412\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# ---- build your model exactly as before ----\n",
    "DEVICE   = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "use_amp  = (DEVICE.type == 'cuda')\n",
    "model    = TrajTransformerAutoencoder(input_dim=128, d_model=64, nhead=8, num_layers=4, dropout=0.15).to(DEVICE)\n",
    "\n",
    "# ---- optimizer / scheduler (same hyperparams as before) ----\n",
    "num_epochs = 1000\n",
    "opt        = optim.Adam(model.parameters(), lr=5e-4, weight_decay=2e-5)\n",
    "scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epochs)\n",
    "scaler     = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "checkpoint_path = \"./models/best_model_tod_3.pth\"\n",
    "#checkpoint_path  = \"./models/best_model_tod_finetune_2_simulation.pth\"\n",
    "def _move_opt_state_to_device(optimizer, device):\n",
    "    # Adam stores running stats as tensors; move them to the active device.\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "def resume_or_init(checkpoint_path, model, opt, scheduler=None, scaler=None, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Returns: start_epoch, best_val, feat_mean, feat_std\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    best_val    = float('inf')\n",
    "    feat_mean = None\n",
    "    feat_std  = None\n",
    "\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        # Model weights (allow non-strict in case you added buffers/PE params)\n",
    "        missing, unexpected = model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
    "        if missing or unexpected:\n",
    "            print(f\"[resume] missing keys: {missing}\\n[resume] unexpected keys: {unexpected}\")\n",
    "\n",
    "        # Optimizer / scheduler / scaler\n",
    "        if 'optimizer_state_dict' in ckpt:\n",
    "            opt.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "            _move_opt_state_to_device(opt, device)\n",
    "        if scheduler is not None and 'scheduler_state_dict' in ckpt:\n",
    "            scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n",
    "        if scaler is not None and 'scaler_state_dict' in ckpt:\n",
    "            try:\n",
    "                scaler.load_state_dict(ckpt['scaler_state_dict'])\n",
    "            except Exception:\n",
    "                pass  # scaler might not have been saved previously\n",
    "\n",
    "        # Epoch & metrics (support old/new key names)\n",
    "        start_epoch = int(ckpt.get('epoch', -1)) + 1\n",
    "        best_val    = float(ckpt.get('best_val_mse', ckpt.get('best_train_loss', float('inf'))))\n",
    "\n",
    "        # Feature standardization (if saved)\n",
    "        if 'feat_mean' in ckpt and 'feat_std' in ckpt:\n",
    "            feat_mean = ckpt['feat_mean'].to(device)\n",
    "            feat_std  = ckpt['feat_std'].to(device)\n",
    "\n",
    "        print(f\"[resume] Loaded checkpoint from '{checkpoint_path}' at epoch {start_epoch}, best_val={best_val:.6f}\")\n",
    "    else:\n",
    "        print(f\"[resume] No checkpoint found at '{checkpoint_path}'. Starting fresh.\")\n",
    "\n",
    "    return start_epoch, best_val, feat_mean, feat_std\n",
    "\n",
    "# ---- if you need train-only stats but checkpoint doesn't have them ----\n",
    "def estimate_feature_stats_once(train_loader, device):\n",
    "    x_sum = None; x_sqsum = None; n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, pad, obs, *_ in train_loader:\n",
    "            x = x.to(device)\n",
    "            valid = obs.to(device).bool() & (~pad.to(device).bool()).unsqueeze(-1)\n",
    "            xs = x[valid]\n",
    "            if x_sum is None:\n",
    "                D = x.shape[-1]\n",
    "                x_sum   = xs.sum(dim=0)\n",
    "                x_sqsum = (xs*xs).sum(dim=0)\n",
    "            else:\n",
    "                x_sum   += xs.sum(dim=0)\n",
    "                x_sqsum += (xs*xs).sum(dim=0)\n",
    "            n += xs.shape[0]\n",
    "    mean = x_sum / max(1, n)\n",
    "    var  = x_sqsum / max(1, n) - mean*mean\n",
    "    std  = torch.sqrt(torch.clamp(var, min=1e-8))\n",
    "    return mean, std\n",
    "\n",
    "# ---------- RESUME ----------\n",
    "start_epoch, best_val, ckpt_mean, ckpt_std = resume_or_init(\n",
    "    checkpoint_path, model, opt, scheduler, scaler, DEVICE\n",
    ")\n",
    "\n",
    "# If the checkpoint did not include feature stats, compute them now\n",
    "if ckpt_mean is not None and ckpt_std is not None:\n",
    "    feat_mean, feat_std = ckpt_mean, ckpt_std\n",
    "else:\n",
    "    # you already computed these above; if not:\n",
    "    # feat_mean, feat_std = estimate_feature_stats_once(train_loader, DEVICE)\n",
    "    feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "# ---------- (OPTIONAL) evaluate right after loading ----------\n",
    "test_mse_std = evaluate(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "test_mse_org = evaluate_original_scale(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "print(f\" Test MSE (std): {test_mse_std:.6f}   |  Test MSE (orig): {test_mse_org:.6f}\")\n",
    "\n",
    "# ---------- CONTINUE TRAINING ----------\n",
    "# Use star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13f736c7-7ef5-4bf9-8daf-ebfd46498d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, logging\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(\"train\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# avoid duplicate handlers if you re-run cells\n",
    "logger.handlers.clear()\n",
    "\n",
    "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "                        datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "fh = logging.FileHandler(\"logs/train_log.txt\", encoding=\"utf-8\")\n",
    "fh.setFormatter(fmt); fh.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(fmt); ch.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(fh); logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ee41078-ce84-4a5c-914c-910d71426bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11791a1f77c4ce8b35512625675a3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:54:36 | INFO | Epoch 000  train_mse(std): 0.657968  val_mse(std): 0.398767  val_ema: 0.657968  last l2: 0.001594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 000  train_mse(std): 0.657968  val_mse(std): 0.398767  val_ema: 0.657968  last l2: 0.001594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:54:36 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:55:25 | INFO | Epoch 001  train_mse(std): 0.356456  val_mse(std): 0.232869  val_ema: 0.356456  last l2: 0.000903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 001  train_mse(std): 0.356456  val_mse(std): 0.232869  val_ema: 0.356456  last l2: 0.000903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:55:25 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:56:14 | INFO | Epoch 002  train_mse(std): 0.251370  val_mse(std): 0.176105  val_ema: 0.251370  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 002  train_mse(std): 0.251370  val_mse(std): 0.176105  val_ema: 0.251370  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:56:14 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:04 | INFO | Epoch 003  train_mse(std): 0.211749  val_mse(std): 0.154745  val_ema: 0.211749  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 003  train_mse(std): 0.211749  val_mse(std): 0.154745  val_ema: 0.211749  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:05 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:55 | INFO | Epoch 004  train_mse(std): 0.193569  val_mse(std): 0.146567  val_ema: 0.193569  last l2: 0.000532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 004  train_mse(std): 0.193569  val_mse(std): 0.146567  val_ema: 0.193569  last l2: 0.000532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:57:55 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:58:45 | INFO | Epoch 005  train_mse(std): 0.182340  val_mse(std): 0.140709  val_ema: 0.182340  last l2: 0.000504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 005  train_mse(std): 0.182340  val_mse(std): 0.140709  val_ema: 0.182340  last l2: 0.000504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:58:45 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:59:34 | INFO | Epoch 006  train_mse(std): 0.175548  val_mse(std): 0.136471  val_ema: 0.175548  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 006  train_mse(std): 0.175548  val_mse(std): 0.136471  val_ema: 0.175548  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 21:59:34 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:00:23 | INFO | Epoch 007  train_mse(std): 0.169993  val_mse(std): 0.133248  val_ema: 0.169993  last l2: 0.000509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 007  train_mse(std): 0.169993  val_mse(std): 0.133248  val_ema: 0.169993  last l2: 0.000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:00:23 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:01:12 | INFO | Epoch 008  train_mse(std): 0.166767  val_mse(std): 0.131351  val_ema: 0.166767  last l2: 0.000641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 008  train_mse(std): 0.166767  val_mse(std): 0.131351  val_ema: 0.166767  last l2: 0.000641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:01:12 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:01 | INFO | Epoch 009  train_mse(std): 0.163981  val_mse(std): 0.129934  val_ema: 0.163981  last l2: 0.000645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 009  train_mse(std): 0.163981  val_mse(std): 0.129934  val_ema: 0.163981  last l2: 0.000645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:01 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:50 | INFO | Epoch 010  train_mse(std): 0.161740  val_mse(std): 0.127993  val_ema: 0.161740  last l2: 0.000580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 010  train_mse(std): 0.161740  val_mse(std): 0.127993  val_ema: 0.161740  last l2: 0.000580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:02:50 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:03:38 | INFO | Epoch 011  train_mse(std): 0.159046  val_mse(std): 0.126898  val_ema: 0.159046  last l2: 0.000654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 011  train_mse(std): 0.159046  val_mse(std): 0.126898  val_ema: 0.159046  last l2: 0.000654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:03:38 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:04:27 | INFO | Epoch 012  train_mse(std): 0.156910  val_mse(std): 0.126340  val_ema: 0.156910  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 012  train_mse(std): 0.156910  val_mse(std): 0.126340  val_ema: 0.156910  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:04:27 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:05:17 | INFO | Epoch 013  train_mse(std): 0.155779  val_mse(std): 0.124418  val_ema: 0.155779  last l2: 0.000820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 013  train_mse(std): 0.155779  val_mse(std): 0.124418  val_ema: 0.155779  last l2: 0.000820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:05:17 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:07 | INFO | Epoch 014  train_mse(std): 0.154636  val_mse(std): 0.125700  val_ema: 0.154636  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 014  train_mse(std): 0.154636  val_mse(std): 0.125700  val_ema: 0.154636  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:07 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:58 | INFO | Epoch 015  train_mse(std): 0.152880  val_mse(std): 0.123939  val_ema: 0.152880  last l2: 0.000687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 015  train_mse(std): 0.152880  val_mse(std): 0.123939  val_ema: 0.152880  last l2: 0.000687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:06:58 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:07:47 | INFO | Epoch 016  train_mse(std): 0.152070  val_mse(std): 0.123013  val_ema: 0.152070  last l2: 0.000714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 016  train_mse(std): 0.152070  val_mse(std): 0.123013  val_ema: 0.152070  last l2: 0.000714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:07:47 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:08:37 | INFO | Epoch 017  train_mse(std): 0.151241  val_mse(std): 0.123075  val_ema: 0.151241  last l2: 0.000853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 017  train_mse(std): 0.151241  val_mse(std): 0.123075  val_ema: 0.151241  last l2: 0.000853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:08:37 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:09:27 | INFO | Epoch 018  train_mse(std): 0.150740  val_mse(std): 0.122094  val_ema: 0.150740  last l2: 0.001127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 018  train_mse(std): 0.150740  val_mse(std): 0.122094  val_ema: 0.150740  last l2: 0.001127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:09:27 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:10:17 | INFO | Epoch 019  train_mse(std): 0.149966  val_mse(std): 0.124055  val_ema: 0.149966  last l2: 0.001263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 019  train_mse(std): 0.149966  val_mse(std): 0.124055  val_ema: 0.149966  last l2: 0.001263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:10:17 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:07 | INFO | Epoch 020  train_mse(std): 0.149710  val_mse(std): 0.122020  val_ema: 0.149710  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 020  train_mse(std): 0.149710  val_mse(std): 0.122020  val_ema: 0.149710  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:07 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:57 | INFO | Epoch 021  train_mse(std): 0.148886  val_mse(std): 0.121973  val_ema: 0.148886  last l2: 0.000826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 021  train_mse(std): 0.148886  val_mse(std): 0.121973  val_ema: 0.148886  last l2: 0.000826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:11:57 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:12:46 | INFO | Epoch 022  train_mse(std): 0.148518  val_mse(std): 0.121442  val_ema: 0.148518  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 022  train_mse(std): 0.148518  val_mse(std): 0.121442  val_ema: 0.148518  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:12:47 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:13:36 | INFO | Epoch 023  train_mse(std): 0.148065  val_mse(std): 0.121496  val_ema: 0.148065  last l2: 0.001157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 023  train_mse(std): 0.148065  val_mse(std): 0.121496  val_ema: 0.148065  last l2: 0.001157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:13:36 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:14:25 | INFO | Epoch 024  train_mse(std): 0.147480  val_mse(std): 0.120894  val_ema: 0.147480  last l2: 0.001517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 024  train_mse(std): 0.147480  val_mse(std): 0.120894  val_ema: 0.147480  last l2: 0.001517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:14:25 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:15:14 | INFO | Epoch 025  train_mse(std): 0.147261  val_mse(std): 0.122632  val_ema: 0.147261  last l2: 0.001348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 025  train_mse(std): 0.147261  val_mse(std): 0.122632  val_ema: 0.147261  last l2: 0.001348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:15:14 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:02 | INFO | Epoch 026  train_mse(std): 0.148065  val_mse(std): 0.120654  val_ema: 0.148065  last l2: 0.000843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 026  train_mse(std): 0.148065  val_mse(std): 0.120654  val_ema: 0.148065  last l2: 0.000843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:51 | INFO | Epoch 027  train_mse(std): 0.146942  val_mse(std): 0.120430  val_ema: 0.146942  last l2: 0.001107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 027  train_mse(std): 0.146942  val_mse(std): 0.120430  val_ema: 0.146942  last l2: 0.001107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:16:51 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:17:39 | INFO | Epoch 028  train_mse(std): 0.146430  val_mse(std): 0.123608  val_ema: 0.146430  last l2: 0.001690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 028  train_mse(std): 0.146430  val_mse(std): 0.123608  val_ema: 0.146430  last l2: 0.001690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:17:39 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:18:28 | INFO | Epoch 029  train_mse(std): 0.146033  val_mse(std): 0.120278  val_ema: 0.146033  last l2: 0.001318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 029  train_mse(std): 0.146033  val_mse(std): 0.120278  val_ema: 0.146033  last l2: 0.001318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:18:28 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:19:17 | INFO | Epoch 030  train_mse(std): 0.147227  val_mse(std): 0.120477  val_ema: 0.147227  last l2: 0.001134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 030  train_mse(std): 0.147227  val_mse(std): 0.120477  val_ema: 0.147227  last l2: 0.001134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:05 | INFO | Epoch 031  train_mse(std): 0.145493  val_mse(std): 0.120019  val_ema: 0.145493  last l2: 0.000901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 031  train_mse(std): 0.145493  val_mse(std): 0.120019  val_ema: 0.145493  last l2: 0.000901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:05 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:20:53 | INFO | Epoch 032  train_mse(std): 0.145444  val_mse(std): 0.122823  val_ema: 0.145444  last l2: 0.000980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 032  train_mse(std): 0.145444  val_mse(std): 0.122823  val_ema: 0.145444  last l2: 0.000980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:21:41 | INFO | Epoch 033  train_mse(std): 0.145667  val_mse(std): 0.119850  val_ema: 0.145667  last l2: 0.001444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 033  train_mse(std): 0.145667  val_mse(std): 0.119850  val_ema: 0.145667  last l2: 0.001444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:22:31 | INFO | Epoch 034  train_mse(std): 0.145077  val_mse(std): 0.119917  val_ema: 0.145077  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 034  train_mse(std): 0.145077  val_mse(std): 0.119917  val_ema: 0.145077  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:22:31 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:23:21 | INFO | Epoch 035  train_mse(std): 0.145271  val_mse(std): 0.120079  val_ema: 0.145271  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 035  train_mse(std): 0.145271  val_mse(std): 0.120079  val_ema: 0.145271  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:24:10 | INFO | Epoch 036  train_mse(std): 0.145010  val_mse(std): 0.119868  val_ema: 0.145010  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 036  train_mse(std): 0.145010  val_mse(std): 0.119868  val_ema: 0.145010  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:00 | INFO | Epoch 037  train_mse(std): 0.144819  val_mse(std): 0.124801  val_ema: 0.144819  last l2: 0.001709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 037  train_mse(std): 0.144819  val_mse(std): 0.124801  val_ema: 0.144819  last l2: 0.001709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:00 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:25:49 | INFO | Epoch 038  train_mse(std): 0.145099  val_mse(std): 0.119710  val_ema: 0.145099  last l2: 0.000998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 038  train_mse(std): 0.145099  val_mse(std): 0.119710  val_ema: 0.145099  last l2: 0.000998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:26:39 | INFO | Epoch 039  train_mse(std): 0.144176  val_mse(std): 0.119724  val_ema: 0.144176  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 039  train_mse(std): 0.144176  val_mse(std): 0.119724  val_ema: 0.144176  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:26:39 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:27:28 | INFO | Epoch 040  train_mse(std): 0.143993  val_mse(std): 0.119417  val_ema: 0.143993  last l2: 0.001391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 040  train_mse(std): 0.143993  val_mse(std): 0.119417  val_ema: 0.143993  last l2: 0.001391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:27:28 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:28:17 | INFO | Epoch 041  train_mse(std): 0.144166  val_mse(std): 0.119564  val_ema: 0.144166  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 041  train_mse(std): 0.144166  val_mse(std): 0.119564  val_ema: 0.144166  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:29:07 | INFO | Epoch 042  train_mse(std): 0.144874  val_mse(std): 0.123009  val_ema: 0.144874  last l2: 0.000996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 042  train_mse(std): 0.144874  val_mse(std): 0.123009  val_ema: 0.144874  last l2: 0.000996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:29:56 | INFO | Epoch 043  train_mse(std): 0.144414  val_mse(std): 0.119315  val_ema: 0.144414  last l2: 0.000749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 043  train_mse(std): 0.144414  val_mse(std): 0.119315  val_ema: 0.144414  last l2: 0.000749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:30:45 | INFO | Epoch 044  train_mse(std): 0.143427  val_mse(std): 0.121894  val_ema: 0.143427  last l2: 0.001353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 044  train_mse(std): 0.143427  val_mse(std): 0.121894  val_ema: 0.143427  last l2: 0.001353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:30:45 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:31:35 | INFO | Epoch 045  train_mse(std): 0.144043  val_mse(std): 0.119630  val_ema: 0.144043  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 045  train_mse(std): 0.144043  val_mse(std): 0.119630  val_ema: 0.144043  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:32:25 | INFO | Epoch 046  train_mse(std): 0.143026  val_mse(std): 0.119075  val_ema: 0.143026  last l2: 0.001100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 046  train_mse(std): 0.143026  val_mse(std): 0.119075  val_ema: 0.143026  last l2: 0.001100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:32:25 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:33:15 | INFO | Epoch 047  train_mse(std): 0.142840  val_mse(std): 0.119132  val_ema: 0.142840  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 047  train_mse(std): 0.142840  val_mse(std): 0.119132  val_ema: 0.142840  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:33:15 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:05 | INFO | Epoch 048  train_mse(std): 0.143125  val_mse(std): 0.119211  val_ema: 0.143125  last l2: 0.000823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 048  train_mse(std): 0.143125  val_mse(std): 0.119211  val_ema: 0.143125  last l2: 0.000823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:56 | INFO | Epoch 049  train_mse(std): 0.142567  val_mse(std): 0.119013  val_ema: 0.142567  last l2: 0.000897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 049  train_mse(std): 0.142567  val_mse(std): 0.119013  val_ema: 0.142567  last l2: 0.000897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:34:56 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:35:45 | INFO | Epoch 050  train_mse(std): 0.142618  val_mse(std): 0.119318  val_ema: 0.142618  last l2: 0.001303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 050  train_mse(std): 0.142618  val_mse(std): 0.119318  val_ema: 0.142618  last l2: 0.001303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:36:35 | INFO | Epoch 051  train_mse(std): 0.144058  val_mse(std): 0.119228  val_ema: 0.144058  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 051  train_mse(std): 0.144058  val_mse(std): 0.119228  val_ema: 0.144058  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:37:25 | INFO | Epoch 052  train_mse(std): 0.142197  val_mse(std): 0.118797  val_ema: 0.142197  last l2: 0.000644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 052  train_mse(std): 0.142197  val_mse(std): 0.118797  val_ema: 0.142197  last l2: 0.000644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:37:25 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:38:15 | INFO | Epoch 053  train_mse(std): 0.142041  val_mse(std): 0.118939  val_ema: 0.142041  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 053  train_mse(std): 0.142041  val_mse(std): 0.118939  val_ema: 0.142041  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:38:15 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:39:05 | INFO | Epoch 054  train_mse(std): 0.142668  val_mse(std): 0.122709  val_ema: 0.142668  last l2: 0.001189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 054  train_mse(std): 0.142668  val_mse(std): 0.122709  val_ema: 0.142668  last l2: 0.001189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:39:54 | INFO | Epoch 055  train_mse(std): 0.142625  val_mse(std): 0.118877  val_ema: 0.142625  last l2: 0.001010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 055  train_mse(std): 0.142625  val_mse(std): 0.118877  val_ema: 0.142625  last l2: 0.001010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:40:43 | INFO | Epoch 056  train_mse(std): 0.141836  val_mse(std): 0.119269  val_ema: 0.141836  last l2: 0.001061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 056  train_mse(std): 0.141836  val_mse(std): 0.119269  val_ema: 0.141836  last l2: 0.001061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:40:43 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:41:31 | INFO | Epoch 057  train_mse(std): 0.141793  val_mse(std): 0.120463  val_ema: 0.141793  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 057  train_mse(std): 0.141793  val_mse(std): 0.120463  val_ema: 0.141793  last l2: 0.000992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:42:20 | INFO | Epoch 058  train_mse(std): 0.142440  val_mse(std): 0.118697  val_ema: 0.142440  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 058  train_mse(std): 0.142440  val_mse(std): 0.118697  val_ema: 0.142440  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:08 | INFO | Epoch 059  train_mse(std): 0.141606  val_mse(std): 0.118625  val_ema: 0.141606  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 059  train_mse(std): 0.141606  val_mse(std): 0.118625  val_ema: 0.141606  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:08 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:43:58 | INFO | Epoch 060  train_mse(std): 0.141523  val_mse(std): 0.118701  val_ema: 0.141523  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 060  train_mse(std): 0.141523  val_mse(std): 0.118701  val_ema: 0.141523  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:44:48 | INFO | Epoch 061  train_mse(std): 0.142802  val_mse(std): 0.119269  val_ema: 0.142802  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 061  train_mse(std): 0.142802  val_mse(std): 0.119269  val_ema: 0.142802  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:45:37 | INFO | Epoch 062  train_mse(std): 0.141424  val_mse(std): 0.118808  val_ema: 0.141424  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 062  train_mse(std): 0.141424  val_mse(std): 0.118808  val_ema: 0.141424  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:45:37 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:46:26 | INFO | Epoch 063  train_mse(std): 0.141317  val_mse(std): 0.118593  val_ema: 0.141317  last l2: 0.001043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 063  train_mse(std): 0.141317  val_mse(std): 0.118593  val_ema: 0.141317  last l2: 0.001043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:46:26 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:47:16 | INFO | Epoch 064  train_mse(std): 0.142075  val_mse(std): 0.118469  val_ema: 0.142075  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 064  train_mse(std): 0.142075  val_mse(std): 0.118469  val_ema: 0.142075  last l2: 0.000558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:05 | INFO | Epoch 065  train_mse(std): 0.141190  val_mse(std): 0.118838  val_ema: 0.141190  last l2: 0.001360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 065  train_mse(std): 0.141190  val_mse(std): 0.118838  val_ema: 0.141190  last l2: 0.001360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:05 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:48:55 | INFO | Epoch 066  train_mse(std): 0.141148  val_mse(std): 0.118634  val_ema: 0.141148  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 066  train_mse(std): 0.141148  val_mse(std): 0.118634  val_ema: 0.141148  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:49:44 | INFO | Epoch 067  train_mse(std): 0.141630  val_mse(std): 0.118601  val_ema: 0.141630  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 067  train_mse(std): 0.141630  val_mse(std): 0.118601  val_ema: 0.141630  last l2: 0.000969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:50:34 | INFO | Epoch 068  train_mse(std): 0.142085  val_mse(std): 0.118897  val_ema: 0.142085  last l2: 0.000479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 068  train_mse(std): 0.142085  val_mse(std): 0.118897  val_ema: 0.142085  last l2: 0.000479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:51:24 | INFO | Epoch 069  train_mse(std): 0.140955  val_mse(std): 0.118513  val_ema: 0.140955  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 069  train_mse(std): 0.140955  val_mse(std): 0.118513  val_ema: 0.140955  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:51:24 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:52:12 | INFO | Epoch 070  train_mse(std): 0.141749  val_mse(std): 0.120252  val_ema: 0.141749  last l2: 0.000799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 070  train_mse(std): 0.141749  val_mse(std): 0.120252  val_ema: 0.141749  last l2: 0.000799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:53:01 | INFO | Epoch 071  train_mse(std): 0.141340  val_mse(std): 0.118620  val_ema: 0.141340  last l2: 0.000564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 071  train_mse(std): 0.141340  val_mse(std): 0.118620  val_ema: 0.141340  last l2: 0.000564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:53:49 | INFO | Epoch 072  train_mse(std): 0.140894  val_mse(std): 0.118880  val_ema: 0.140894  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 072  train_mse(std): 0.140894  val_mse(std): 0.118880  val_ema: 0.140894  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:54:37 | INFO | Epoch 073  train_mse(std): 0.140832  val_mse(std): 0.118653  val_ema: 0.140832  last l2: 0.000713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 073  train_mse(std): 0.140832  val_mse(std): 0.118653  val_ema: 0.140832  last l2: 0.000713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:54:37 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:55:25 | INFO | Epoch 074  train_mse(std): 0.140831  val_mse(std): 0.118943  val_ema: 0.140831  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 074  train_mse(std): 0.140831  val_mse(std): 0.118943  val_ema: 0.140831  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:56:13 | INFO | Epoch 075  train_mse(std): 0.141569  val_mse(std): 0.118393  val_ema: 0.141569  last l2: 0.000934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 075  train_mse(std): 0.141569  val_mse(std): 0.118393  val_ema: 0.141569  last l2: 0.000934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:02 | INFO | Epoch 076  train_mse(std): 0.141859  val_mse(std): 0.118570  val_ema: 0.141859  last l2: 0.000660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 076  train_mse(std): 0.141859  val_mse(std): 0.118570  val_ema: 0.141859  last l2: 0.000660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:49 | INFO | Epoch 077  train_mse(std): 0.140596  val_mse(std): 0.118748  val_ema: 0.140596  last l2: 0.000808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 077  train_mse(std): 0.140596  val_mse(std): 0.118748  val_ema: 0.140596  last l2: 0.000808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:57:49 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:58:37 | INFO | Epoch 078  train_mse(std): 0.140850  val_mse(std): 0.119147  val_ema: 0.140850  last l2: 0.000617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 078  train_mse(std): 0.140850  val_mse(std): 0.119147  val_ema: 0.140850  last l2: 0.000617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 22:59:25 | INFO | Epoch 079  train_mse(std): 0.140776  val_mse(std): 0.118857  val_ema: 0.140776  last l2: 0.000817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 079  train_mse(std): 0.140776  val_mse(std): 0.118857  val_ema: 0.140776  last l2: 0.000817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:00:13 | INFO | Epoch 080  train_mse(std): 0.140785  val_mse(std): 0.118799  val_ema: 0.140785  last l2: 0.000596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 080  train_mse(std): 0.140785  val_mse(std): 0.118799  val_ema: 0.140785  last l2: 0.000596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:01 | INFO | Epoch 081  train_mse(std): 0.140685  val_mse(std): 0.119386  val_ema: 0.140685  last l2: 0.000869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 081  train_mse(std): 0.140685  val_mse(std): 0.119386  val_ema: 0.140685  last l2: 0.000869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:49 | INFO | Epoch 082  train_mse(std): 0.140488  val_mse(std): 0.118929  val_ema: 0.140488  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 082  train_mse(std): 0.140488  val_mse(std): 0.118929  val_ema: 0.140488  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:01:49 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:02:37 | INFO | Epoch 083  train_mse(std): 0.140356  val_mse(std): 0.118639  val_ema: 0.140356  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 083  train_mse(std): 0.140356  val_mse(std): 0.118639  val_ema: 0.140356  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:02:37 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:03:25 | INFO | Epoch 084  train_mse(std): 0.141092  val_mse(std): 0.118931  val_ema: 0.141092  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 084  train_mse(std): 0.141092  val_mse(std): 0.118931  val_ema: 0.141092  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:04:14 | INFO | Epoch 085  train_mse(std): 0.140290  val_mse(std): 0.118749  val_ema: 0.140290  last l2: 0.000560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 085  train_mse(std): 0.140290  val_mse(std): 0.118749  val_ema: 0.140290  last l2: 0.000560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:05:02 | INFO | Epoch 086  train_mse(std): 0.140464  val_mse(std): 0.118968  val_ema: 0.140464  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 086  train_mse(std): 0.140464  val_mse(std): 0.118968  val_ema: 0.140464  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:05:51 | INFO | Epoch 087  train_mse(std): 0.141237  val_mse(std): 0.119306  val_ema: 0.141237  last l2: 0.000880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 087  train_mse(std): 0.141237  val_mse(std): 0.119306  val_ema: 0.141237  last l2: 0.000880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:06:40 | INFO | Epoch 088  train_mse(std): 0.140284  val_mse(std): 0.118867  val_ema: 0.140284  last l2: 0.000975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 088  train_mse(std): 0.140284  val_mse(std): 0.118867  val_ema: 0.140284  last l2: 0.000975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:07:30 | INFO | Epoch 089  train_mse(std): 0.140511  val_mse(std): 0.119445  val_ema: 0.140511  last l2: 0.000750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 089  train_mse(std): 0.140511  val_mse(std): 0.119445  val_ema: 0.140511  last l2: 0.000750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:08:19 | INFO | Epoch 090  train_mse(std): 0.140187  val_mse(std): 0.119114  val_ema: 0.140187  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 090  train_mse(std): 0.140187  val_mse(std): 0.119114  val_ema: 0.140187  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:08:19 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:09:09 | INFO | Epoch 091  train_mse(std): 0.140484  val_mse(std): 0.120274  val_ema: 0.140484  last l2: 0.001185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 091  train_mse(std): 0.140484  val_mse(std): 0.120274  val_ema: 0.140484  last l2: 0.001185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:09:59 | INFO | Epoch 092  train_mse(std): 0.140220  val_mse(std): 0.118732  val_ema: 0.140220  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 092  train_mse(std): 0.140220  val_mse(std): 0.118732  val_ema: 0.140220  last l2: 0.000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:10:47 | INFO | Epoch 093  train_mse(std): 0.140071  val_mse(std): 0.118931  val_ema: 0.140071  last l2: 0.000690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 093  train_mse(std): 0.140071  val_mse(std): 0.118931  val_ema: 0.140071  last l2: 0.000690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:10:47 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:11:35 | INFO | Epoch 094  train_mse(std): 0.140164  val_mse(std): 0.119307  val_ema: 0.140164  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 094  train_mse(std): 0.140164  val_mse(std): 0.119307  val_ema: 0.140164  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:12:24 | INFO | Epoch 095  train_mse(std): 0.139907  val_mse(std): 0.119035  val_ema: 0.139907  last l2: 0.000582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 095  train_mse(std): 0.139907  val_mse(std): 0.119035  val_ema: 0.139907  last l2: 0.000582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:12:24 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:13:13 | INFO | Epoch 096  train_mse(std): 0.139957  val_mse(std): 0.119088  val_ema: 0.139957  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 096  train_mse(std): 0.139957  val_mse(std): 0.119088  val_ema: 0.139957  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:02 | INFO | Epoch 097  train_mse(std): 0.139975  val_mse(std): 0.119151  val_ema: 0.139975  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 097  train_mse(std): 0.139975  val_mse(std): 0.119151  val_ema: 0.139975  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:51 | INFO | Epoch 098  train_mse(std): 0.139773  val_mse(std): 0.119013  val_ema: 0.139773  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 098  train_mse(std): 0.139773  val_mse(std): 0.119013  val_ema: 0.139773  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:14:51 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:15:40 | INFO | Epoch 099  train_mse(std): 0.139881  val_mse(std): 0.119633  val_ema: 0.139881  last l2: 0.000977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 099  train_mse(std): 0.139881  val_mse(std): 0.119633  val_ema: 0.139881  last l2: 0.000977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:16:28 | INFO | Epoch 100  train_mse(std): 0.139653  val_mse(std): 0.119164  val_ema: 0.139653  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 100  train_mse(std): 0.139653  val_mse(std): 0.119164  val_ema: 0.139653  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:16:28 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:17:17 | INFO | Epoch 101  train_mse(std): 0.140206  val_mse(std): 0.118987  val_ema: 0.140206  last l2: 0.000621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 101  train_mse(std): 0.140206  val_mse(std): 0.118987  val_ema: 0.140206  last l2: 0.000621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:05 | INFO | Epoch 102  train_mse(std): 0.139545  val_mse(std): 0.119602  val_ema: 0.139545  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 102  train_mse(std): 0.139545  val_mse(std): 0.119602  val_ema: 0.139545  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:05 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:18:53 | INFO | Epoch 103  train_mse(std): 0.139564  val_mse(std): 0.119144  val_ema: 0.139564  last l2: 0.000589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 103  train_mse(std): 0.139564  val_mse(std): 0.119144  val_ema: 0.139564  last l2: 0.000589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:19:41 | INFO | Epoch 104  train_mse(std): 0.140558  val_mse(std): 0.119921  val_ema: 0.140558  last l2: 0.000555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 104  train_mse(std): 0.140558  val_mse(std): 0.119921  val_ema: 0.140558  last l2: 0.000555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:20:31 | INFO | Epoch 105  train_mse(std): 0.140321  val_mse(std): 0.119385  val_ema: 0.140321  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 105  train_mse(std): 0.140321  val_mse(std): 0.119385  val_ema: 0.140321  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:21:20 | INFO | Epoch 106  train_mse(std): 0.139471  val_mse(std): 0.119729  val_ema: 0.139471  last l2: 0.001036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 106  train_mse(std): 0.139471  val_mse(std): 0.119729  val_ema: 0.139471  last l2: 0.001036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:09 | INFO | Epoch 107  train_mse(std): 0.139419  val_mse(std): 0.119356  val_ema: 0.139419  last l2: 0.000536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 107  train_mse(std): 0.139419  val_mse(std): 0.119356  val_ema: 0.139419  last l2: 0.000536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:09 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:22:58 | INFO | Epoch 108  train_mse(std): 0.139426  val_mse(std): 0.121143  val_ema: 0.139426  last l2: 0.001171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 108  train_mse(std): 0.139426  val_mse(std): 0.121143  val_ema: 0.139426  last l2: 0.001171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:23:48 | INFO | Epoch 109  train_mse(std): 0.139678  val_mse(std): 0.119115  val_ema: 0.139678  last l2: 0.000971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 109  train_mse(std): 0.139678  val_mse(std): 0.119115  val_ema: 0.139678  last l2: 0.000971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:24:36 | INFO | Epoch 110  train_mse(std): 0.139411  val_mse(std): 0.119651  val_ema: 0.139411  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 110  train_mse(std): 0.139411  val_mse(std): 0.119651  val_ema: 0.139411  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:25:25 | INFO | Epoch 111  train_mse(std): 0.140045  val_mse(std): 0.120271  val_ema: 0.140045  last l2: 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 111  train_mse(std): 0.140045  val_mse(std): 0.120271  val_ema: 0.140045  last l2: 0.000772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:26:14 | INFO | Epoch 112  train_mse(std): 0.139504  val_mse(std): 0.120671  val_ema: 0.139504  last l2: 0.000595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 112  train_mse(std): 0.139504  val_mse(std): 0.120671  val_ema: 0.139504  last l2: 0.000595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:02 | INFO | Epoch 113  train_mse(std): 0.140152  val_mse(std): 0.119239  val_ema: 0.140152  last l2: 0.000691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 113  train_mse(std): 0.140152  val_mse(std): 0.119239  val_ema: 0.140152  last l2: 0.000691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:51 | INFO | Epoch 114  train_mse(std): 0.139264  val_mse(std): 0.119132  val_ema: 0.139264  last l2: 0.000525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 114  train_mse(std): 0.139264  val_mse(std): 0.119132  val_ema: 0.139264  last l2: 0.000525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:27:51 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:28:40 | INFO | Epoch 115  train_mse(std): 0.139879  val_mse(std): 0.119567  val_ema: 0.139879  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 115  train_mse(std): 0.139879  val_mse(std): 0.119567  val_ema: 0.139879  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:29:29 | INFO | Epoch 116  train_mse(std): 0.139375  val_mse(std): 0.118979  val_ema: 0.139375  last l2: 0.000571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 116  train_mse(std): 0.139375  val_mse(std): 0.118979  val_ema: 0.139375  last l2: 0.000571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:30:17 | INFO | Epoch 117  train_mse(std): 0.139391  val_mse(std): 0.119209  val_ema: 0.139391  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 117  train_mse(std): 0.139391  val_mse(std): 0.119209  val_ema: 0.139391  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:31:06 | INFO | Epoch 118  train_mse(std): 0.139677  val_mse(std): 0.119714  val_ema: 0.139677  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 118  train_mse(std): 0.139677  val_mse(std): 0.119714  val_ema: 0.139677  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:31:54 | INFO | Epoch 119  train_mse(std): 0.139249  val_mse(std): 0.119220  val_ema: 0.139249  last l2: 0.000635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 119  train_mse(std): 0.139249  val_mse(std): 0.119220  val_ema: 0.139249  last l2: 0.000635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:32:43 | INFO | Epoch 120  train_mse(std): 0.139553  val_mse(std): 0.121011  val_ema: 0.139553  last l2: 0.000729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 120  train_mse(std): 0.139553  val_mse(std): 0.121011  val_ema: 0.139553  last l2: 0.000729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:33:32 | INFO | Epoch 121  train_mse(std): 0.139383  val_mse(std): 0.119094  val_ema: 0.139383  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 121  train_mse(std): 0.139383  val_mse(std): 0.119094  val_ema: 0.139383  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:34:20 | INFO | Epoch 122  train_mse(std): 0.139544  val_mse(std): 0.120566  val_ema: 0.139544  last l2: 0.000874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 122  train_mse(std): 0.139544  val_mse(std): 0.120566  val_ema: 0.139544  last l2: 0.000874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:35:09 | INFO | Epoch 123  train_mse(std): 0.139437  val_mse(std): 0.120219  val_ema: 0.139437  last l2: 0.000979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 123  train_mse(std): 0.139437  val_mse(std): 0.120219  val_ema: 0.139437  last l2: 0.000979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:35:58 | INFO | Epoch 124  train_mse(std): 0.139292  val_mse(std): 0.119557  val_ema: 0.139292  last l2: 0.000905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 124  train_mse(std): 0.139292  val_mse(std): 0.119557  val_ema: 0.139292  last l2: 0.000905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:36:47 | INFO | Epoch 125  train_mse(std): 0.139275  val_mse(std): 0.119805  val_ema: 0.139275  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 125  train_mse(std): 0.139275  val_mse(std): 0.119805  val_ema: 0.139275  last l2: 0.000960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:37:36 | INFO | Epoch 126  train_mse(std): 0.139582  val_mse(std): 0.120172  val_ema: 0.139582  last l2: 0.000761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 126  train_mse(std): 0.139582  val_mse(std): 0.120172  val_ema: 0.139582  last l2: 0.000761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:38:25 | INFO | Epoch 127  train_mse(std): 0.139401  val_mse(std): 0.120163  val_ema: 0.139401  last l2: 0.000956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 127  train_mse(std): 0.139401  val_mse(std): 0.120163  val_ema: 0.139401  last l2: 0.000956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:39:14 | INFO | Epoch 128  train_mse(std): 0.139426  val_mse(std): 0.119285  val_ema: 0.139426  last l2: 0.000620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 128  train_mse(std): 0.139426  val_mse(std): 0.119285  val_ema: 0.139426  last l2: 0.000620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:03 | INFO | Epoch 129  train_mse(std): 0.139028  val_mse(std): 0.119481  val_ema: 0.139028  last l2: 0.000626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 129  train_mse(std): 0.139028  val_mse(std): 0.119481  val_ema: 0.139028  last l2: 0.000626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:03 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:40:53 | INFO | Epoch 130  train_mse(std): 0.139136  val_mse(std): 0.119774  val_ema: 0.139136  last l2: 0.000686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 130  train_mse(std): 0.139136  val_mse(std): 0.119774  val_ema: 0.139136  last l2: 0.000686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:41:41 | INFO | Epoch 131  train_mse(std): 0.139548  val_mse(std): 0.119418  val_ema: 0.139548  last l2: 0.000503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 131  train_mse(std): 0.139548  val_mse(std): 0.119418  val_ema: 0.139548  last l2: 0.000503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:42:31 | INFO | Epoch 132  train_mse(std): 0.139149  val_mse(std): 0.119545  val_ema: 0.139149  last l2: 0.001082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 132  train_mse(std): 0.139149  val_mse(std): 0.119545  val_ema: 0.139149  last l2: 0.001082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:43:20 | INFO | Epoch 133  train_mse(std): 0.139097  val_mse(std): 0.119828  val_ema: 0.139097  last l2: 0.001150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 133  train_mse(std): 0.139097  val_mse(std): 0.119828  val_ema: 0.139097  last l2: 0.001150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:44:09 | INFO | Epoch 134  train_mse(std): 0.139489  val_mse(std): 0.119413  val_ema: 0.139489  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 134  train_mse(std): 0.139489  val_mse(std): 0.119413  val_ema: 0.139489  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:44:57 | INFO | Epoch 135  train_mse(std): 0.139340  val_mse(std): 0.119443  val_ema: 0.139340  last l2: 0.000858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 135  train_mse(std): 0.139340  val_mse(std): 0.119443  val_ema: 0.139340  last l2: 0.000858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:45:46 | INFO | Epoch 136  train_mse(std): 0.138900  val_mse(std): 0.119632  val_ema: 0.138900  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 136  train_mse(std): 0.138900  val_mse(std): 0.119632  val_ema: 0.138900  last l2: 0.001040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:45:47 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:46:35 | INFO | Epoch 137  train_mse(std): 0.138968  val_mse(std): 0.119322  val_ema: 0.138968  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 137  train_mse(std): 0.138968  val_mse(std): 0.119322  val_ema: 0.138968  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:47:23 | INFO | Epoch 138  train_mse(std): 0.139339  val_mse(std): 0.121323  val_ema: 0.139339  last l2: 0.000717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 138  train_mse(std): 0.139339  val_mse(std): 0.121323  val_ema: 0.139339  last l2: 0.000717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:48:11 | INFO | Epoch 139  train_mse(std): 0.139113  val_mse(std): 0.119289  val_ema: 0.139113  last l2: 0.000444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 139  train_mse(std): 0.139113  val_mse(std): 0.119289  val_ema: 0.139113  last l2: 0.000444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:49:01 | INFO | Epoch 140  train_mse(std): 0.139049  val_mse(std): 0.119654  val_ema: 0.139049  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 140  train_mse(std): 0.139049  val_mse(std): 0.119654  val_ema: 0.139049  last l2: 0.000515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:49:50 | INFO | Epoch 141  train_mse(std): 0.138955  val_mse(std): 0.119233  val_ema: 0.138955  last l2: 0.000827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 141  train_mse(std): 0.138955  val_mse(std): 0.119233  val_ema: 0.138955  last l2: 0.000827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:50:38 | INFO | Epoch 142  train_mse(std): 0.139072  val_mse(std): 0.119506  val_ema: 0.139072  last l2: 0.000657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 142  train_mse(std): 0.139072  val_mse(std): 0.119506  val_ema: 0.139072  last l2: 0.000657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:51:27 | INFO | Epoch 143  train_mse(std): 0.138957  val_mse(std): 0.119169  val_ema: 0.138957  last l2: 0.000496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 143  train_mse(std): 0.138957  val_mse(std): 0.119169  val_ema: 0.138957  last l2: 0.000496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:52:16 | INFO | Epoch 144  train_mse(std): 0.139119  val_mse(std): 0.119390  val_ema: 0.139119  last l2: 0.000942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 144  train_mse(std): 0.139119  val_mse(std): 0.119390  val_ema: 0.139119  last l2: 0.000942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:53:05 | INFO | Epoch 145  train_mse(std): 0.139307  val_mse(std): 0.119261  val_ema: 0.139307  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 145  train_mse(std): 0.139307  val_mse(std): 0.119261  val_ema: 0.139307  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:53:54 | INFO | Epoch 146  train_mse(std): 0.139591  val_mse(std): 0.118808  val_ema: 0.139591  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 146  train_mse(std): 0.139591  val_mse(std): 0.118808  val_ema: 0.139591  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:54:43 | INFO | Epoch 147  train_mse(std): 0.138875  val_mse(std): 0.118912  val_ema: 0.138875  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 147  train_mse(std): 0.138875  val_mse(std): 0.118912  val_ema: 0.138875  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:55:33 | INFO | Epoch 148  train_mse(std): 0.138912  val_mse(std): 0.119083  val_ema: 0.138912  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 148  train_mse(std): 0.138912  val_mse(std): 0.119083  val_ema: 0.138912  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:56:22 | INFO | Epoch 149  train_mse(std): 0.138888  val_mse(std): 0.118839  val_ema: 0.138888  last l2: 0.000609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 149  train_mse(std): 0.138888  val_mse(std): 0.118839  val_ema: 0.138888  last l2: 0.000609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:57:12 | INFO | Epoch 150  train_mse(std): 0.139389  val_mse(std): 0.118809  val_ema: 0.139389  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 150  train_mse(std): 0.139389  val_mse(std): 0.118809  val_ema: 0.139389  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:00 | INFO | Epoch 151  train_mse(std): 0.138774  val_mse(std): 0.118816  val_ema: 0.138774  last l2: 0.000633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 151  train_mse(std): 0.138774  val_mse(std): 0.118816  val_ema: 0.138774  last l2: 0.000633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:00 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:58:48 | INFO | Epoch 152  train_mse(std): 0.138798  val_mse(std): 0.118779  val_ema: 0.138798  last l2: 0.000816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 152  train_mse(std): 0.138798  val_mse(std): 0.118779  val_ema: 0.138798  last l2: 0.000816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 23:59:37 | INFO | Epoch 153  train_mse(std): 0.139160  val_mse(std): 0.121257  val_ema: 0.139160  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 153  train_mse(std): 0.139160  val_mse(std): 0.121257  val_ema: 0.139160  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:00:25 | INFO | Epoch 154  train_mse(std): 0.139142  val_mse(std): 0.118815  val_ema: 0.139142  last l2: 0.000538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 154  train_mse(std): 0.139142  val_mse(std): 0.118815  val_ema: 0.139142  last l2: 0.000538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:01:14 | INFO | Epoch 155  train_mse(std): 0.138711  val_mse(std): 0.118909  val_ema: 0.138711  last l2: 0.000951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 155  train_mse(std): 0.138711  val_mse(std): 0.118909  val_ema: 0.138711  last l2: 0.000951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:02:02 | INFO | Epoch 156  train_mse(std): 0.138714  val_mse(std): 0.118941  val_ema: 0.138714  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 156  train_mse(std): 0.138714  val_mse(std): 0.118941  val_ema: 0.138714  last l2: 0.000742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:02:51 | INFO | Epoch 157  train_mse(std): 0.138879  val_mse(std): 0.119378  val_ema: 0.138879  last l2: 0.000860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 157  train_mse(std): 0.138879  val_mse(std): 0.119378  val_ema: 0.138879  last l2: 0.000860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:03:40 | INFO | Epoch 158  train_mse(std): 0.138839  val_mse(std): 0.118874  val_ema: 0.138839  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 158  train_mse(std): 0.138839  val_mse(std): 0.118874  val_ema: 0.138839  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:04:29 | INFO | Epoch 159  train_mse(std): 0.138782  val_mse(std): 0.120255  val_ema: 0.138782  last l2: 0.000950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 159  train_mse(std): 0.138782  val_mse(std): 0.120255  val_ema: 0.138782  last l2: 0.000950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:05:17 | INFO | Epoch 160  train_mse(std): 0.139146  val_mse(std): 0.118762  val_ema: 0.139146  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 160  train_mse(std): 0.139146  val_mse(std): 0.118762  val_ema: 0.139146  last l2: 0.000662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:05 | INFO | Epoch 161  train_mse(std): 0.138610  val_mse(std): 0.118674  val_ema: 0.138610  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 161  train_mse(std): 0.138610  val_mse(std): 0.118674  val_ema: 0.138610  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:05 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:06:53 | INFO | Epoch 162  train_mse(std): 0.138730  val_mse(std): 0.118633  val_ema: 0.138730  last l2: 0.000779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 162  train_mse(std): 0.138730  val_mse(std): 0.118633  val_ema: 0.138730  last l2: 0.000779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:07:41 | INFO | Epoch 163  train_mse(std): 0.138625  val_mse(std): 0.118914  val_ema: 0.138625  last l2: 0.001065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 163  train_mse(std): 0.138625  val_mse(std): 0.118914  val_ema: 0.138625  last l2: 0.001065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:08:29 | INFO | Epoch 164  train_mse(std): 0.138699  val_mse(std): 0.118695  val_ema: 0.138699  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 164  train_mse(std): 0.138699  val_mse(std): 0.118695  val_ema: 0.138699  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:09:17 | INFO | Epoch 165  train_mse(std): 0.139157  val_mse(std): 0.119164  val_ema: 0.139157  last l2: 0.000694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 165  train_mse(std): 0.139157  val_mse(std): 0.119164  val_ema: 0.139157  last l2: 0.000694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:10:04 | INFO | Epoch 166  train_mse(std): 0.138777  val_mse(std): 0.118651  val_ema: 0.138777  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 166  train_mse(std): 0.138777  val_mse(std): 0.118651  val_ema: 0.138777  last l2: 0.000829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:10:54 | INFO | Epoch 167  train_mse(std): 0.138569  val_mse(std): 0.118900  val_ema: 0.138569  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 167  train_mse(std): 0.138569  val_mse(std): 0.118900  val_ema: 0.138569  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:11:42 | INFO | Epoch 168  train_mse(std): 0.138970  val_mse(std): 0.118961  val_ema: 0.138970  last l2: 0.000561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 168  train_mse(std): 0.138970  val_mse(std): 0.118961  val_ema: 0.138970  last l2: 0.000561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:12:30 | INFO | Epoch 169  train_mse(std): 0.138588  val_mse(std): 0.118590  val_ema: 0.138588  last l2: 0.000684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 169  train_mse(std): 0.138588  val_mse(std): 0.118590  val_ema: 0.138588  last l2: 0.000684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:13:19 | INFO | Epoch 170  train_mse(std): 0.138563  val_mse(std): 0.119115  val_ema: 0.138563  last l2: 0.000511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 170  train_mse(std): 0.138563  val_mse(std): 0.119115  val_ema: 0.138563  last l2: 0.000511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:14:08 | INFO | Epoch 171  train_mse(std): 0.139056  val_mse(std): 0.120301  val_ema: 0.139056  last l2: 0.000947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 171  train_mse(std): 0.139056  val_mse(std): 0.120301  val_ema: 0.139056  last l2: 0.000947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:14:57 | INFO | Epoch 172  train_mse(std): 0.138802  val_mse(std): 0.118797  val_ema: 0.138802  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 172  train_mse(std): 0.138802  val_mse(std): 0.118797  val_ema: 0.138802  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:15:46 | INFO | Epoch 173  train_mse(std): 0.138711  val_mse(std): 0.118799  val_ema: 0.138711  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 173  train_mse(std): 0.138711  val_mse(std): 0.118799  val_ema: 0.138711  last l2: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:16:34 | INFO | Epoch 174  train_mse(std): 0.138488  val_mse(std): 0.118929  val_ema: 0.138488  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 174  train_mse(std): 0.138488  val_mse(std): 0.118929  val_ema: 0.138488  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:16:34 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:17:22 | INFO | Epoch 175  train_mse(std): 0.138658  val_mse(std): 0.119109  val_ema: 0.138658  last l2: 0.000757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 175  train_mse(std): 0.138658  val_mse(std): 0.119109  val_ema: 0.138658  last l2: 0.000757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:18:10 | INFO | Epoch 176  train_mse(std): 0.138969  val_mse(std): 0.119113  val_ema: 0.138969  last l2: 0.000565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 176  train_mse(std): 0.138969  val_mse(std): 0.119113  val_ema: 0.138969  last l2: 0.000565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:18:59 | INFO | Epoch 177  train_mse(std): 0.138462  val_mse(std): 0.119006  val_ema: 0.138462  last l2: 0.001059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 177  train_mse(std): 0.138462  val_mse(std): 0.119006  val_ema: 0.138462  last l2: 0.001059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:19:48 | INFO | Epoch 178  train_mse(std): 0.138538  val_mse(std): 0.118961  val_ema: 0.138538  last l2: 0.000778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 178  train_mse(std): 0.138538  val_mse(std): 0.118961  val_ema: 0.138538  last l2: 0.000778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:20:37 | INFO | Epoch 179  train_mse(std): 0.139650  val_mse(std): 0.118900  val_ema: 0.139650  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 179  train_mse(std): 0.139650  val_mse(std): 0.118900  val_ema: 0.139650  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:21:26 | INFO | Epoch 180  train_mse(std): 0.138450  val_mse(std): 0.118704  val_ema: 0.138450  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 180  train_mse(std): 0.138450  val_mse(std): 0.118704  val_ema: 0.138450  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:22:15 | INFO | Epoch 181  train_mse(std): 0.138387  val_mse(std): 0.119307  val_ema: 0.138387  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 181  train_mse(std): 0.138387  val_mse(std): 0.119307  val_ema: 0.138387  last l2: 0.000667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:22:15 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:23:04 | INFO | Epoch 182  train_mse(std): 0.138476  val_mse(std): 0.119204  val_ema: 0.138476  last l2: 0.000594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 182  train_mse(std): 0.138476  val_mse(std): 0.119204  val_ema: 0.138476  last l2: 0.000594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:23:53 | INFO | Epoch 183  train_mse(std): 0.138623  val_mse(std): 0.118832  val_ema: 0.138623  last l2: 0.000751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 183  train_mse(std): 0.138623  val_mse(std): 0.118832  val_ema: 0.138623  last l2: 0.000751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:24:42 | INFO | Epoch 184  train_mse(std): 0.139383  val_mse(std): 0.119713  val_ema: 0.139383  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 184  train_mse(std): 0.139383  val_mse(std): 0.119713  val_ema: 0.139383  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:25:31 | INFO | Epoch 185  train_mse(std): 0.138874  val_mse(std): 0.119561  val_ema: 0.138874  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 185  train_mse(std): 0.138874  val_mse(std): 0.119561  val_ema: 0.138874  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:26:20 | INFO | Epoch 186  train_mse(std): 0.138489  val_mse(std): 0.119076  val_ema: 0.138489  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 186  train_mse(std): 0.138489  val_mse(std): 0.119076  val_ema: 0.138489  last l2: 0.000653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:27:10 | INFO | Epoch 187  train_mse(std): 0.138512  val_mse(std): 0.119713  val_ema: 0.138512  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 187  train_mse(std): 0.138512  val_mse(std): 0.119713  val_ema: 0.138512  last l2: 0.000764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:27:59 | INFO | Epoch 188  train_mse(std): 0.138606  val_mse(std): 0.118944  val_ema: 0.138606  last l2: 0.000550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 188  train_mse(std): 0.138606  val_mse(std): 0.118944  val_ema: 0.138606  last l2: 0.000550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:28:47 | INFO | Epoch 189  train_mse(std): 0.138940  val_mse(std): 0.118880  val_ema: 0.138940  last l2: 0.001011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 189  train_mse(std): 0.138940  val_mse(std): 0.118880  val_ema: 0.138940  last l2: 0.001011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:29:36 | INFO | Epoch 190  train_mse(std): 0.138397  val_mse(std): 0.119753  val_ema: 0.138397  last l2: 0.000735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 190  train_mse(std): 0.138397  val_mse(std): 0.119753  val_ema: 0.138397  last l2: 0.000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:30:24 | INFO | Epoch 191  train_mse(std): 0.138348  val_mse(std): 0.119565  val_ema: 0.138348  last l2: 0.000762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 191  train_mse(std): 0.138348  val_mse(std): 0.119565  val_ema: 0.138348  last l2: 0.000762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:31:13 | INFO | Epoch 192  train_mse(std): 0.138612  val_mse(std): 0.119810  val_ema: 0.138612  last l2: 0.000578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 192  train_mse(std): 0.138612  val_mse(std): 0.119810  val_ema: 0.138612  last l2: 0.000578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:32:02 | INFO | Epoch 193  train_mse(std): 0.138337  val_mse(std): 0.119583  val_ema: 0.138337  last l2: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 193  train_mse(std): 0.138337  val_mse(std): 0.119583  val_ema: 0.138337  last l2: 0.000832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:32:50 | INFO | Epoch 194  train_mse(std): 0.138347  val_mse(std): 0.119774  val_ema: 0.138347  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 194  train_mse(std): 0.138347  val_mse(std): 0.119774  val_ema: 0.138347  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:33:38 | INFO | Epoch 195  train_mse(std): 0.138900  val_mse(std): 0.119295  val_ema: 0.138900  last l2: 0.000698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 195  train_mse(std): 0.138900  val_mse(std): 0.119295  val_ema: 0.138900  last l2: 0.000698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:34:28 | INFO | Epoch 196  train_mse(std): 0.138363  val_mse(std): 0.119582  val_ema: 0.138363  last l2: 0.000848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 196  train_mse(std): 0.138363  val_mse(std): 0.119582  val_ema: 0.138363  last l2: 0.000848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:35:17 | INFO | Epoch 197  train_mse(std): 0.138698  val_mse(std): 0.120201  val_ema: 0.138698  last l2: 0.000527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 197  train_mse(std): 0.138698  val_mse(std): 0.120201  val_ema: 0.138698  last l2: 0.000527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:36:07 | INFO | Epoch 198  train_mse(std): 0.138391  val_mse(std): 0.120141  val_ema: 0.138391  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 198  train_mse(std): 0.138391  val_mse(std): 0.120141  val_ema: 0.138391  last l2: 0.000923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:36:56 | INFO | Epoch 199  train_mse(std): 0.138305  val_mse(std): 0.119546  val_ema: 0.138305  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 199  train_mse(std): 0.138305  val_mse(std): 0.119546  val_ema: 0.138305  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:37:45 | INFO | Epoch 200  train_mse(std): 0.138412  val_mse(std): 0.120111  val_ema: 0.138412  last l2: 0.001037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 200  train_mse(std): 0.138412  val_mse(std): 0.120111  val_ema: 0.138412  last l2: 0.001037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:38:35 | INFO | Epoch 201  train_mse(std): 0.138505  val_mse(std): 0.119832  val_ema: 0.138505  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 201  train_mse(std): 0.138505  val_mse(std): 0.119832  val_ema: 0.138505  last l2: 0.000721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:39:24 | INFO | Epoch 202  train_mse(std): 0.138372  val_mse(std): 0.119658  val_ema: 0.138372  last l2: 0.000588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 202  train_mse(std): 0.138372  val_mse(std): 0.119658  val_ema: 0.138372  last l2: 0.000588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:40:12 | INFO | Epoch 203  train_mse(std): 0.138522  val_mse(std): 0.120157  val_ema: 0.138522  last l2: 0.000745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 203  train_mse(std): 0.138522  val_mse(std): 0.120157  val_ema: 0.138522  last l2: 0.000745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:00 | INFO | Epoch 204  train_mse(std): 0.138993  val_mse(std): 0.119856  val_ema: 0.138993  last l2: 0.000669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 204  train_mse(std): 0.138993  val_mse(std): 0.119856  val_ema: 0.138993  last l2: 0.000669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:47 | INFO | Epoch 205  train_mse(std): 0.138255  val_mse(std): 0.120004  val_ema: 0.138255  last l2: 0.000507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 205  train_mse(std): 0.138255  val_mse(std): 0.120004  val_ema: 0.138255  last l2: 0.000507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:41:47 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:42:35 | INFO | Epoch 206  train_mse(std): 0.138342  val_mse(std): 0.119247  val_ema: 0.138342  last l2: 0.000546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 206  train_mse(std): 0.138342  val_mse(std): 0.119247  val_ema: 0.138342  last l2: 0.000546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:43:23 | INFO | Epoch 207  train_mse(std): 0.138467  val_mse(std): 0.119620  val_ema: 0.138467  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 207  train_mse(std): 0.138467  val_mse(std): 0.119620  val_ema: 0.138467  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:44:10 | INFO | Epoch 208  train_mse(std): 0.138397  val_mse(std): 0.120117  val_ema: 0.138397  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 208  train_mse(std): 0.138397  val_mse(std): 0.120117  val_ema: 0.138397  last l2: 0.000679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:44:58 | INFO | Epoch 209  train_mse(std): 0.138267  val_mse(std): 0.120339  val_ema: 0.138267  last l2: 0.000737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 209  train_mse(std): 0.138267  val_mse(std): 0.120339  val_ema: 0.138267  last l2: 0.000737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:45:46 | INFO | Epoch 210  train_mse(std): 0.138342  val_mse(std): 0.121189  val_ema: 0.138342  last l2: 0.000911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 210  train_mse(std): 0.138342  val_mse(std): 0.121189  val_ema: 0.138342  last l2: 0.000911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:46:33 | INFO | Epoch 211  train_mse(std): 0.138293  val_mse(std): 0.119818  val_ema: 0.138293  last l2: 0.001329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 211  train_mse(std): 0.138293  val_mse(std): 0.119818  val_ema: 0.138293  last l2: 0.001329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:47:20 | INFO | Epoch 212  train_mse(std): 0.138756  val_mse(std): 0.120569  val_ema: 0.138756  last l2: 0.000672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 212  train_mse(std): 0.138756  val_mse(std): 0.120569  val_ema: 0.138756  last l2: 0.000672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:48:08 | INFO | Epoch 213  train_mse(std): 0.138300  val_mse(std): 0.120690  val_ema: 0.138300  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 213  train_mse(std): 0.138300  val_mse(std): 0.120690  val_ema: 0.138300  last l2: 0.000706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:48:55 | INFO | Epoch 214  train_mse(std): 0.138560  val_mse(std): 0.120750  val_ema: 0.138560  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 214  train_mse(std): 0.138560  val_mse(std): 0.120750  val_ema: 0.138560  last l2: 0.000763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:49:43 | INFO | Epoch 215  train_mse(std): 0.138464  val_mse(std): 0.120705  val_ema: 0.138464  last l2: 0.000867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 215  train_mse(std): 0.138464  val_mse(std): 0.120705  val_ema: 0.138464  last l2: 0.000867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:50:30 | INFO | Epoch 216  train_mse(std): 0.138170  val_mse(std): 0.119588  val_ema: 0.138170  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 216  train_mse(std): 0.138170  val_mse(std): 0.119588  val_ema: 0.138170  last l2: 0.000785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:51:18 | INFO | Epoch 217  train_mse(std): 0.138388  val_mse(std): 0.121753  val_ema: 0.138388  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 217  train_mse(std): 0.138388  val_mse(std): 0.121753  val_ema: 0.138388  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:52:07 | INFO | Epoch 218  train_mse(std): 0.138343  val_mse(std): 0.120919  val_ema: 0.138343  last l2: 0.000743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 218  train_mse(std): 0.138343  val_mse(std): 0.120919  val_ema: 0.138343  last l2: 0.000743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:52:56 | INFO | Epoch 219  train_mse(std): 0.138344  val_mse(std): 0.120470  val_ema: 0.138344  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 219  train_mse(std): 0.138344  val_mse(std): 0.120470  val_ema: 0.138344  last l2: 0.000814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:53:44 | INFO | Epoch 220  train_mse(std): 0.138478  val_mse(std): 0.120818  val_ema: 0.138478  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 220  train_mse(std): 0.138478  val_mse(std): 0.120818  val_ema: 0.138478  last l2: 0.000941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:54:32 | INFO | Epoch 221  train_mse(std): 0.138213  val_mse(std): 0.120658  val_ema: 0.138213  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 221  train_mse(std): 0.138213  val_mse(std): 0.120658  val_ema: 0.138213  last l2: 0.001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:55:20 | INFO | Epoch 222  train_mse(std): 0.138118  val_mse(std): 0.120881  val_ema: 0.138118  last l2: 0.000614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 222  train_mse(std): 0.138118  val_mse(std): 0.120881  val_ema: 0.138118  last l2: 0.000614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:55:20 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:56:08 | INFO | Epoch 223  train_mse(std): 0.138343  val_mse(std): 0.120808  val_ema: 0.138343  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 223  train_mse(std): 0.138343  val_mse(std): 0.120808  val_ema: 0.138343  last l2: 0.000906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:56:57 | INFO | Epoch 224  train_mse(std): 0.138353  val_mse(std): 0.121462  val_ema: 0.138353  last l2: 0.000851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 224  train_mse(std): 0.138353  val_mse(std): 0.121462  val_ema: 0.138353  last l2: 0.000851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:57:45 | INFO | Epoch 225  train_mse(std): 0.138490  val_mse(std): 0.120684  val_ema: 0.138490  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 225  train_mse(std): 0.138490  val_mse(std): 0.120684  val_ema: 0.138490  last l2: 0.000728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:58:33 | INFO | Epoch 226  train_mse(std): 0.138098  val_mse(std): 0.121131  val_ema: 0.138098  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 226  train_mse(std): 0.138098  val_mse(std): 0.121131  val_ema: 0.138098  last l2: 0.000834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 00:59:21 | INFO | Epoch 227  train_mse(std): 0.138422  val_mse(std): 0.121319  val_ema: 0.138422  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 227  train_mse(std): 0.138422  val_mse(std): 0.121319  val_ema: 0.138422  last l2: 0.000702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:00:09 | INFO | Epoch 228  train_mse(std): 0.138316  val_mse(std): 0.120924  val_ema: 0.138316  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 228  train_mse(std): 0.138316  val_mse(std): 0.120924  val_ema: 0.138316  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:00:57 | INFO | Epoch 229  train_mse(std): 0.138248  val_mse(std): 0.121040  val_ema: 0.138248  last l2: 0.000892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 229  train_mse(std): 0.138248  val_mse(std): 0.121040  val_ema: 0.138248  last l2: 0.000892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:01:45 | INFO | Epoch 230  train_mse(std): 0.138407  val_mse(std): 0.120424  val_ema: 0.138407  last l2: 0.001375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 230  train_mse(std): 0.138407  val_mse(std): 0.120424  val_ema: 0.138407  last l2: 0.001375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:02:32 | INFO | Epoch 231  train_mse(std): 0.138078  val_mse(std): 0.120908  val_ema: 0.138078  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 231  train_mse(std): 0.138078  val_mse(std): 0.120908  val_ema: 0.138078  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:03:20 | INFO | Epoch 232  train_mse(std): 0.138088  val_mse(std): 0.120554  val_ema: 0.138088  last l2: 0.000473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 232  train_mse(std): 0.138088  val_mse(std): 0.120554  val_ema: 0.138088  last l2: 0.000473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:04:08 | INFO | Epoch 233  train_mse(std): 0.138257  val_mse(std): 0.121214  val_ema: 0.138257  last l2: 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 233  train_mse(std): 0.138257  val_mse(std): 0.121214  val_ema: 0.138257  last l2: 0.000896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:04:58 | INFO | Epoch 234  train_mse(std): 0.138127  val_mse(std): 0.121052  val_ema: 0.138127  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 234  train_mse(std): 0.138127  val_mse(std): 0.121052  val_ema: 0.138127  last l2: 0.000623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:05:47 | INFO | Epoch 235  train_mse(std): 0.138138  val_mse(std): 0.120174  val_ema: 0.138138  last l2: 0.000809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 235  train_mse(std): 0.138138  val_mse(std): 0.120174  val_ema: 0.138138  last l2: 0.000809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:06:36 | INFO | Epoch 236  train_mse(std): 0.138128  val_mse(std): 0.121043  val_ema: 0.138128  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 236  train_mse(std): 0.138128  val_mse(std): 0.121043  val_ema: 0.138128  last l2: 0.000777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:07:24 | INFO | Epoch 237  train_mse(std): 0.138556  val_mse(std): 0.121389  val_ema: 0.138556  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 237  train_mse(std): 0.138556  val_mse(std): 0.121389  val_ema: 0.138556  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:08:12 | INFO | Epoch 238  train_mse(std): 0.138244  val_mse(std): 0.120523  val_ema: 0.138244  last l2: 0.000648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 238  train_mse(std): 0.138244  val_mse(std): 0.120523  val_ema: 0.138244  last l2: 0.000648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:00 | INFO | Epoch 239  train_mse(std): 0.138204  val_mse(std): 0.120725  val_ema: 0.138204  last l2: 0.000533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 239  train_mse(std): 0.138204  val_mse(std): 0.120725  val_ema: 0.138204  last l2: 0.000533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:48 | INFO | Epoch 240  train_mse(std): 0.137991  val_mse(std): 0.120795  val_ema: 0.137991  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 240  train_mse(std): 0.137991  val_mse(std): 0.120795  val_ema: 0.137991  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:09:48 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:10:36 | INFO | Epoch 241  train_mse(std): 0.138252  val_mse(std): 0.121225  val_ema: 0.138252  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 241  train_mse(std): 0.138252  val_mse(std): 0.121225  val_ema: 0.138252  last l2: 0.000884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:11:24 | INFO | Epoch 242  train_mse(std): 0.138118  val_mse(std): 0.120965  val_ema: 0.138118  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 242  train_mse(std): 0.138118  val_mse(std): 0.120965  val_ema: 0.138118  last l2: 0.000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:12:13 | INFO | Epoch 243  train_mse(std): 0.138066  val_mse(std): 0.121674  val_ema: 0.138066  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 243  train_mse(std): 0.138066  val_mse(std): 0.121674  val_ema: 0.138066  last l2: 0.000990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:13:00 | INFO | Epoch 244  train_mse(std): 0.138169  val_mse(std): 0.121353  val_ema: 0.138169  last l2: 0.000655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 244  train_mse(std): 0.138169  val_mse(std): 0.121353  val_ema: 0.138169  last l2: 0.000655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:13:49 | INFO | Epoch 245  train_mse(std): 0.138424  val_mse(std): 0.122700  val_ema: 0.138424  last l2: 0.000907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 245  train_mse(std): 0.138424  val_mse(std): 0.122700  val_ema: 0.138424  last l2: 0.000907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:14:37 | INFO | Epoch 246  train_mse(std): 0.138246  val_mse(std): 0.121545  val_ema: 0.138246  last l2: 0.000488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 246  train_mse(std): 0.138246  val_mse(std): 0.121545  val_ema: 0.138246  last l2: 0.000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:15:25 | INFO | Epoch 247  train_mse(std): 0.138222  val_mse(std): 0.121743  val_ema: 0.138222  last l2: 0.000831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 247  train_mse(std): 0.138222  val_mse(std): 0.121743  val_ema: 0.138222  last l2: 0.000831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:16:14 | INFO | Epoch 248  train_mse(std): 0.138068  val_mse(std): 0.120805  val_ema: 0.138068  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 248  train_mse(std): 0.138068  val_mse(std): 0.120805  val_ema: 0.138068  last l2: 0.000677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:17:02 | INFO | Epoch 249  train_mse(std): 0.138018  val_mse(std): 0.122027  val_ema: 0.138018  last l2: 0.000704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 249  train_mse(std): 0.138018  val_mse(std): 0.122027  val_ema: 0.138018  last l2: 0.000704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:17:51 | INFO | Epoch 250  train_mse(std): 0.138047  val_mse(std): 0.120897  val_ema: 0.138047  last l2: 0.000899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 250  train_mse(std): 0.138047  val_mse(std): 0.120897  val_ema: 0.138047  last l2: 0.000899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:18:39 | INFO | Epoch 251  train_mse(std): 0.138166  val_mse(std): 0.121249  val_ema: 0.138166  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 251  train_mse(std): 0.138166  val_mse(std): 0.121249  val_ema: 0.138166  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:19:28 | INFO | Epoch 252  train_mse(std): 0.138055  val_mse(std): 0.121589  val_ema: 0.138055  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 252  train_mse(std): 0.138055  val_mse(std): 0.121589  val_ema: 0.138055  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:20:16 | INFO | Epoch 253  train_mse(std): 0.138272  val_mse(std): 0.122592  val_ema: 0.138272  last l2: 0.000680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 253  train_mse(std): 0.138272  val_mse(std): 0.122592  val_ema: 0.138272  last l2: 0.000680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:21:04 | INFO | Epoch 254  train_mse(std): 0.138105  val_mse(std): 0.121085  val_ema: 0.138105  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 254  train_mse(std): 0.138105  val_mse(std): 0.121085  val_ema: 0.138105  last l2: 0.000806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:21:52 | INFO | Epoch 255  train_mse(std): 0.138018  val_mse(std): 0.121514  val_ema: 0.138018  last l2: 0.001299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 255  train_mse(std): 0.138018  val_mse(std): 0.121514  val_ema: 0.138018  last l2: 0.001299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:22:41 | INFO | Epoch 256  train_mse(std): 0.137966  val_mse(std): 0.121934  val_ema: 0.137966  last l2: 0.000753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 256  train_mse(std): 0.137966  val_mse(std): 0.121934  val_ema: 0.137966  last l2: 0.000753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:23:31 | INFO | Epoch 257  train_mse(std): 0.138069  val_mse(std): 0.121955  val_ema: 0.138069  last l2: 0.000813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 257  train_mse(std): 0.138069  val_mse(std): 0.121955  val_ema: 0.138069  last l2: 0.000813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:24:21 | INFO | Epoch 258  train_mse(std): 0.138015  val_mse(std): 0.121635  val_ema: 0.138015  last l2: 0.000591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 258  train_mse(std): 0.138015  val_mse(std): 0.121635  val_ema: 0.138015  last l2: 0.000591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:09 | INFO | Epoch 259  train_mse(std): 0.138554  val_mse(std): 0.121705  val_ema: 0.138554  last l2: 0.000870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 259  train_mse(std): 0.138554  val_mse(std): 0.121705  val_ema: 0.138554  last l2: 0.000870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:59 | INFO | Epoch 260  train_mse(std): 0.137869  val_mse(std): 0.122090  val_ema: 0.137869  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 260  train_mse(std): 0.137869  val_mse(std): 0.122090  val_ema: 0.137869  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:25:59 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:26:48 | INFO | Epoch 261  train_mse(std): 0.137931  val_mse(std): 0.122396  val_ema: 0.137931  last l2: 0.000972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 261  train_mse(std): 0.137931  val_mse(std): 0.122396  val_ema: 0.137931  last l2: 0.000972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:27:37 | INFO | Epoch 262  train_mse(std): 0.138004  val_mse(std): 0.121088  val_ema: 0.138004  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 262  train_mse(std): 0.138004  val_mse(std): 0.121088  val_ema: 0.138004  last l2: 0.000666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:28:26 | INFO | Epoch 263  train_mse(std): 0.137930  val_mse(std): 0.124228  val_ema: 0.137930  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 263  train_mse(std): 0.137930  val_mse(std): 0.124228  val_ema: 0.137930  last l2: 0.000854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:29:15 | INFO | Epoch 264  train_mse(std): 0.138297  val_mse(std): 0.122051  val_ema: 0.138297  last l2: 0.000863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 264  train_mse(std): 0.138297  val_mse(std): 0.122051  val_ema: 0.138297  last l2: 0.000863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:30:04 | INFO | Epoch 265  train_mse(std): 0.137868  val_mse(std): 0.122383  val_ema: 0.137868  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 265  train_mse(std): 0.137868  val_mse(std): 0.122383  val_ema: 0.137868  last l2: 0.000784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:30:53 | INFO | Epoch 266  train_mse(std): 0.137945  val_mse(std): 0.122297  val_ema: 0.137945  last l2: 0.001044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 266  train_mse(std): 0.137945  val_mse(std): 0.122297  val_ema: 0.137945  last l2: 0.001044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:31:42 | INFO | Epoch 267  train_mse(std): 0.137919  val_mse(std): 0.122395  val_ema: 0.137919  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 267  train_mse(std): 0.137919  val_mse(std): 0.122395  val_ema: 0.137919  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:32:31 | INFO | Epoch 268  train_mse(std): 0.138147  val_mse(std): 0.121861  val_ema: 0.138147  last l2: 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 268  train_mse(std): 0.138147  val_mse(std): 0.121861  val_ema: 0.138147  last l2: 0.000937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:33:20 | INFO | Epoch 269  train_mse(std): 0.137845  val_mse(std): 0.121558  val_ema: 0.137845  last l2: 0.000668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 269  train_mse(std): 0.137845  val_mse(std): 0.121558  val_ema: 0.137845  last l2: 0.000668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:34:09 | INFO | Epoch 270  train_mse(std): 0.138494  val_mse(std): 0.121792  val_ema: 0.138494  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 270  train_mse(std): 0.138494  val_mse(std): 0.121792  val_ema: 0.138494  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:34:58 | INFO | Epoch 271  train_mse(std): 0.137794  val_mse(std): 0.121319  val_ema: 0.137794  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 271  train_mse(std): 0.137794  val_mse(std): 0.121319  val_ema: 0.137794  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:35:47 | INFO | Epoch 272  train_mse(std): 0.137931  val_mse(std): 0.121942  val_ema: 0.137931  last l2: 0.000605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 272  train_mse(std): 0.137931  val_mse(std): 0.121942  val_ema: 0.137931  last l2: 0.000605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:36:36 | INFO | Epoch 273  train_mse(std): 0.138032  val_mse(std): 0.122323  val_ema: 0.138032  last l2: 0.000692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 273  train_mse(std): 0.138032  val_mse(std): 0.122323  val_ema: 0.138032  last l2: 0.000692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:37:25 | INFO | Epoch 274  train_mse(std): 0.137880  val_mse(std): 0.122288  val_ema: 0.137880  last l2: 0.000786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 274  train_mse(std): 0.137880  val_mse(std): 0.122288  val_ema: 0.137880  last l2: 0.000786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:38:14 | INFO | Epoch 275  train_mse(std): 0.137916  val_mse(std): 0.122158  val_ema: 0.137916  last l2: 0.000935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 275  train_mse(std): 0.137916  val_mse(std): 0.122158  val_ema: 0.137916  last l2: 0.000935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:39:03 | INFO | Epoch 276  train_mse(std): 0.138292  val_mse(std): 0.122577  val_ema: 0.138292  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 276  train_mse(std): 0.138292  val_mse(std): 0.122577  val_ema: 0.138292  last l2: 0.000866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:39:52 | INFO | Epoch 277  train_mse(std): 0.138009  val_mse(std): 0.122673  val_ema: 0.138009  last l2: 0.001026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 277  train_mse(std): 0.138009  val_mse(std): 0.122673  val_ema: 0.138009  last l2: 0.001026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:40:41 | INFO | Epoch 278  train_mse(std): 0.137895  val_mse(std): 0.122164  val_ema: 0.137895  last l2: 0.000825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 278  train_mse(std): 0.137895  val_mse(std): 0.122164  val_ema: 0.137895  last l2: 0.000825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:41:30 | INFO | Epoch 279  train_mse(std): 0.137938  val_mse(std): 0.123192  val_ema: 0.137938  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 279  train_mse(std): 0.137938  val_mse(std): 0.123192  val_ema: 0.137938  last l2: 0.000739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:42:19 | INFO | Epoch 280  train_mse(std): 0.137896  val_mse(std): 0.121636  val_ema: 0.137896  last l2: 0.001258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 280  train_mse(std): 0.137896  val_mse(std): 0.121636  val_ema: 0.137896  last l2: 0.001258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:43:08 | INFO | Epoch 281  train_mse(std): 0.138228  val_mse(std): 0.122452  val_ema: 0.138228  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 281  train_mse(std): 0.138228  val_mse(std): 0.122452  val_ema: 0.138228  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:43:57 | INFO | Epoch 282  train_mse(std): 0.137788  val_mse(std): 0.122152  val_ema: 0.137788  last l2: 0.000878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 282  train_mse(std): 0.137788  val_mse(std): 0.122152  val_ema: 0.137788  last l2: 0.000878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:44:45 | INFO | Epoch 283  train_mse(std): 0.137917  val_mse(std): 0.122772  val_ema: 0.137917  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 283  train_mse(std): 0.137917  val_mse(std): 0.122772  val_ema: 0.137917  last l2: 0.000891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:45:35 | INFO | Epoch 284  train_mse(std): 0.138063  val_mse(std): 0.124819  val_ema: 0.138063  last l2: 0.001078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 284  train_mse(std): 0.138063  val_mse(std): 0.124819  val_ema: 0.138063  last l2: 0.001078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:46:24 | INFO | Epoch 285  train_mse(std): 0.137998  val_mse(std): 0.122166  val_ema: 0.137998  last l2: 0.000908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 285  train_mse(std): 0.137998  val_mse(std): 0.122166  val_ema: 0.137998  last l2: 0.000908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:47:13 | INFO | Epoch 286  train_mse(std): 0.137857  val_mse(std): 0.121530  val_ema: 0.137857  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 286  train_mse(std): 0.137857  val_mse(std): 0.121530  val_ema: 0.137857  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:03 | INFO | Epoch 287  train_mse(std): 0.137711  val_mse(std): 0.121819  val_ema: 0.137711  last l2: 0.000720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 287  train_mse(std): 0.137711  val_mse(std): 0.121819  val_ema: 0.137711  last l2: 0.000720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:03 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:48:52 | INFO | Epoch 288  train_mse(std): 0.138199  val_mse(std): 0.121426  val_ema: 0.138199  last l2: 0.000652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 288  train_mse(std): 0.138199  val_mse(std): 0.121426  val_ema: 0.138199  last l2: 0.000652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:49:41 | INFO | Epoch 289  train_mse(std): 0.137748  val_mse(std): 0.122732  val_ema: 0.137748  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 289  train_mse(std): 0.137748  val_mse(std): 0.122732  val_ema: 0.137748  last l2: 0.000864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:50:30 | INFO | Epoch 290  train_mse(std): 0.138075  val_mse(std): 0.123761  val_ema: 0.138075  last l2: 0.000883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 290  train_mse(std): 0.138075  val_mse(std): 0.123761  val_ema: 0.138075  last l2: 0.000883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:51:19 | INFO | Epoch 291  train_mse(std): 0.137958  val_mse(std): 0.121679  val_ema: 0.137958  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 291  train_mse(std): 0.137958  val_mse(std): 0.121679  val_ema: 0.137958  last l2: 0.000572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:52:08 | INFO | Epoch 292  train_mse(std): 0.137759  val_mse(std): 0.123421  val_ema: 0.137759  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 292  train_mse(std): 0.137759  val_mse(std): 0.123421  val_ema: 0.137759  last l2: 0.000701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:52:57 | INFO | Epoch 293  train_mse(std): 0.137790  val_mse(std): 0.122664  val_ema: 0.137790  last l2: 0.000917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 293  train_mse(std): 0.137790  val_mse(std): 0.122664  val_ema: 0.137790  last l2: 0.000917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:53:45 | INFO | Epoch 294  train_mse(std): 0.137776  val_mse(std): 0.122383  val_ema: 0.137776  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 294  train_mse(std): 0.137776  val_mse(std): 0.122383  val_ema: 0.137776  last l2: 0.000716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:54:33 | INFO | Epoch 295  train_mse(std): 0.138131  val_mse(std): 0.123313  val_ema: 0.138131  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 295  train_mse(std): 0.138131  val_mse(std): 0.123313  val_ema: 0.138131  last l2: 0.000726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:55:21 | INFO | Epoch 296  train_mse(std): 0.137700  val_mse(std): 0.122773  val_ema: 0.137700  last l2: 0.000781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 296  train_mse(std): 0.137700  val_mse(std): 0.122773  val_ema: 0.137700  last l2: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:56:09 | INFO | Epoch 297  train_mse(std): 0.138047  val_mse(std): 0.122764  val_ema: 0.138047  last l2: 0.000719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 297  train_mse(std): 0.138047  val_mse(std): 0.122764  val_ema: 0.138047  last l2: 0.000719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:56:58 | INFO | Epoch 298  train_mse(std): 0.137707  val_mse(std): 0.122599  val_ema: 0.137707  last l2: 0.000656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 298  train_mse(std): 0.137707  val_mse(std): 0.122599  val_ema: 0.137707  last l2: 0.000656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:57:47 | INFO | Epoch 299  train_mse(std): 0.137672  val_mse(std): 0.122467  val_ema: 0.137672  last l2: 0.000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 299  train_mse(std): 0.137672  val_mse(std): 0.122467  val_ema: 0.137672  last l2: 0.000886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:58:36 | INFO | Epoch 300  train_mse(std): 0.137953  val_mse(std): 0.123540  val_ema: 0.137953  last l2: 0.000707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 300  train_mse(std): 0.137953  val_mse(std): 0.123540  val_ema: 0.137953  last l2: 0.000707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 01:59:25 | INFO | Epoch 301  train_mse(std): 0.137967  val_mse(std): 0.122130  val_ema: 0.137967  last l2: 0.000590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 301  train_mse(std): 0.137967  val_mse(std): 0.122130  val_ema: 0.137967  last l2: 0.000590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:00:14 | INFO | Epoch 302  train_mse(std): 0.137610  val_mse(std): 0.123534  val_ema: 0.137610  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 302  train_mse(std): 0.137610  val_mse(std): 0.123534  val_ema: 0.137610  last l2: 0.000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:00:14 | INFO |    Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Saved new best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:01:02 | INFO | Epoch 303  train_mse(std): 0.137686  val_mse(std): 0.123148  val_ema: 0.137686  last l2: 0.000783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 303  train_mse(std): 0.137686  val_mse(std): 0.123148  val_ema: 0.137686  last l2: 0.000783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:01:52 | INFO | Epoch 304  train_mse(std): 0.137739  val_mse(std): 0.122032  val_ema: 0.137739  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 304  train_mse(std): 0.137739  val_mse(std): 0.122032  val_ema: 0.137739  last l2: 0.000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:02:42 | INFO | Epoch 305  train_mse(std): 0.137951  val_mse(std): 0.122521  val_ema: 0.137951  last l2: 0.000736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 305  train_mse(std): 0.137951  val_mse(std): 0.122521  val_ema: 0.137951  last l2: 0.000736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:03:31 | INFO | Epoch 306  train_mse(std): 0.137819  val_mse(std): 0.125034  val_ema: 0.137819  last l2: 0.000658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 306  train_mse(std): 0.137819  val_mse(std): 0.125034  val_ema: 0.137819  last l2: 0.000658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:04:20 | INFO | Epoch 307  train_mse(std): 0.137826  val_mse(std): 0.123475  val_ema: 0.137826  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 307  train_mse(std): 0.137826  val_mse(std): 0.123475  val_ema: 0.137826  last l2: 0.000766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:05:09 | INFO | Epoch 308  train_mse(std): 0.137935  val_mse(std): 0.123178  val_ema: 0.137935  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 308  train_mse(std): 0.137935  val_mse(std): 0.123178  val_ema: 0.137935  last l2: 0.000581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:05:58 | INFO | Epoch 309  train_mse(std): 0.137812  val_mse(std): 0.123229  val_ema: 0.137812  last l2: 0.000835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 309  train_mse(std): 0.137812  val_mse(std): 0.123229  val_ema: 0.137812  last l2: 0.000835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:06:46 | INFO | Epoch 310  train_mse(std): 0.137637  val_mse(std): 0.123131  val_ema: 0.137637  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 310  train_mse(std): 0.137637  val_mse(std): 0.123131  val_ema: 0.137637  last l2: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:07:35 | INFO | Epoch 311  train_mse(std): 0.137695  val_mse(std): 0.122824  val_ema: 0.137695  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 311  train_mse(std): 0.137695  val_mse(std): 0.122824  val_ema: 0.137695  last l2: 0.000715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:08:23 | INFO | Epoch 312  train_mse(std): 0.137974  val_mse(std): 0.122279  val_ema: 0.137974  last l2: 0.000754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 312  train_mse(std): 0.137974  val_mse(std): 0.122279  val_ema: 0.137974  last l2: 0.000754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:09:11 | INFO | Epoch 313  train_mse(std): 0.137608  val_mse(std): 0.123396  val_ema: 0.137608  last l2: 0.000796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 313  train_mse(std): 0.137608  val_mse(std): 0.123396  val_ema: 0.137608  last l2: 0.000796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:10:00 | INFO | Epoch 314  train_mse(std): 0.137869  val_mse(std): 0.123718  val_ema: 0.137869  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 314  train_mse(std): 0.137869  val_mse(std): 0.123718  val_ema: 0.137869  last l2: 0.000765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:10:48 | INFO | Epoch 315  train_mse(std): 0.137745  val_mse(std): 0.122907  val_ema: 0.137745  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 315  train_mse(std): 0.137745  val_mse(std): 0.122907  val_ema: 0.137745  last l2: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:11:37 | INFO | Epoch 316  train_mse(std): 0.137621  val_mse(std): 0.123264  val_ema: 0.137621  last l2: 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 316  train_mse(std): 0.137621  val_mse(std): 0.123264  val_ema: 0.137621  last l2: 0.000913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:12:25 | INFO | Epoch 317  train_mse(std): 0.137606  val_mse(std): 0.123764  val_ema: 0.137606  last l2: 0.000563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 317  train_mse(std): 0.137606  val_mse(std): 0.123764  val_ema: 0.137606  last l2: 0.000563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:13:14 | INFO | Epoch 318  train_mse(std): 0.137722  val_mse(std): 0.122842  val_ema: 0.137722  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 318  train_mse(std): 0.137722  val_mse(std): 0.122842  val_ema: 0.137722  last l2: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:14:02 | INFO | Epoch 319  train_mse(std): 0.137673  val_mse(std): 0.122469  val_ema: 0.137673  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 319  train_mse(std): 0.137673  val_mse(std): 0.122469  val_ema: 0.137673  last l2: 0.000744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:14:51 | INFO | Epoch 320  train_mse(std): 0.137731  val_mse(std): 0.121959  val_ema: 0.137731  last l2: 0.001035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 320  train_mse(std): 0.137731  val_mse(std): 0.121959  val_ema: 0.137731  last l2: 0.001035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:15:39 | INFO | Epoch 321  train_mse(std): 0.137914  val_mse(std): 0.122854  val_ema: 0.137914  last l2: 0.000482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 321  train_mse(std): 0.137914  val_mse(std): 0.122854  val_ema: 0.137914  last l2: 0.000482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:16:28 | INFO | Epoch 322  train_mse(std): 0.137546  val_mse(std): 0.124235  val_ema: 0.137546  last l2: 0.000945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 322  train_mse(std): 0.137546  val_mse(std): 0.124235  val_ema: 0.137546  last l2: 0.000945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:17:17 | INFO | Epoch 323  train_mse(std): 0.138038  val_mse(std): 0.124308  val_ema: 0.138038  last l2: 0.000689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 323  train_mse(std): 0.138038  val_mse(std): 0.124308  val_ema: 0.138038  last l2: 0.000689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:18:05 | INFO | Epoch 324  train_mse(std): 0.137752  val_mse(std): 0.123099  val_ema: 0.137752  last l2: 0.000873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 324  train_mse(std): 0.137752  val_mse(std): 0.123099  val_ema: 0.137752  last l2: 0.000873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:18:54 | INFO | Epoch 325  train_mse(std): 0.137567  val_mse(std): 0.122898  val_ema: 0.137567  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 325  train_mse(std): 0.137567  val_mse(std): 0.122898  val_ema: 0.137567  last l2: 0.000912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:19:43 | INFO | Epoch 326  train_mse(std): 0.137621  val_mse(std): 0.124089  val_ema: 0.137621  last l2: 0.001074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 326  train_mse(std): 0.137621  val_mse(std): 0.124089  val_ema: 0.137621  last l2: 0.001074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:20:33 | INFO | Epoch 327  train_mse(std): 0.137619  val_mse(std): 0.124051  val_ema: 0.137619  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 327  train_mse(std): 0.137619  val_mse(std): 0.124051  val_ema: 0.137619  last l2: 0.000821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:21:22 | INFO | Epoch 328  train_mse(std): 0.137587  val_mse(std): 0.123962  val_ema: 0.137587  last l2: 0.000696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 328  train_mse(std): 0.137587  val_mse(std): 0.123962  val_ema: 0.137587  last l2: 0.000696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:22:11 | INFO | Epoch 329  train_mse(std): 0.137979  val_mse(std): 0.123727  val_ema: 0.137979  last l2: 0.000512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 329  train_mse(std): 0.137979  val_mse(std): 0.123727  val_ema: 0.137979  last l2: 0.000512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:22:59 | INFO | Epoch 330  train_mse(std): 0.137667  val_mse(std): 0.123019  val_ema: 0.137667  last l2: 0.000807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 330  train_mse(std): 0.137667  val_mse(std): 0.123019  val_ema: 0.137667  last l2: 0.000807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:23:48 | INFO | Epoch 331  train_mse(std): 0.137621  val_mse(std): 0.123012  val_ema: 0.137621  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 331  train_mse(std): 0.137621  val_mse(std): 0.123012  val_ema: 0.137621  last l2: 0.000801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:24:36 | INFO | Epoch 332  train_mse(std): 0.137860  val_mse(std): 0.123342  val_ema: 0.137860  last l2: 0.000665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Epoch 332  train_mse(std): 0.137860  val_mse(std): 0.123342  val_ema: 0.137860  last l2: 0.000665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:24:36 | INFO |    Early stopping after 30 epochs without meaningful improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:   Early stopping after 30 epochs without meaningful improvement.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path  = \"./models/best_model_tod_3.pth\"\n",
    "# ---- compute train-only stats once ----\n",
    "feat_mean, feat_std = estimate_feature_stats(train_loader, DEVICE)\n",
    "feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "\n",
    "# -------------------- TRAIN LOOP (MSE / Huber + optional adaptive L2) --------\n",
    "USE_HUBER      = False      # set True to use Huber instead of MSE\n",
    "# before training loop\n",
    "L2_COEFF       = 0.1      # <- your fixed coefficient\n",
    "warmup_epochs  = 30       # same as before (or 0 to disable warmup)\n",
    "\n",
    "use_amp        = (DEVICE.type == \"cuda\")\n",
    "scaler         = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "from contextlib import nullcontext\n",
    "amp_ctx = (lambda: torch.amp.autocast('cuda', dtype=torch.float16)) if use_amp else (lambda: nullcontext())\n",
    "\n",
    "best_val, epochs_no_improve = float(\"inf\"), 0\n",
    "min_delta, patience = 1e-4, 30\n",
    "ema_alpha, val_ema  = 0.2, None\n",
    "max_grad = 1.0  # set to 0 to disable clipping\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    train_sse, train_n, last_l2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, _, _ in train_loader:\n",
    "        x, pad_mask, obs_mask = x.to(DEVICE), pad_mask.to(DEVICE).bool(), obs_mask.to(DEVICE).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with amp_ctx():\n",
    "            recon, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "            # reconstruction loss in standardized space\n",
    "            recon_loss = masked_huber(recon, x_std_tgt, pad_mask, obs_mask, delta=1.0) if USE_HUBER \\\n",
    "                         else masked_mse  (recon, x_std_tgt, pad_mask, obs_mask)\n",
    "\n",
    "            # optional adaptive latent L2: keeps l2  TARGET_L2_RATIO * recon\n",
    "            eps = 1e-8\n",
    "            # inside the training step, after you computed recon_loss and z\n",
    "            latent_l2 = z.pow(2).sum(dim=1).mean()        # E[||z||^2] over the batch\n",
    "            warm      = min(1.0, (epoch + 1) / max(1, warmup_epochs))\n",
    "            l2_loss   = L2_COEFF * warm * latent_l2\n",
    "            \n",
    "            loss = recon_loss + l2_loss\n",
    "\n",
    "            # for logging standardized MSE\n",
    "            valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "            diff  = (recon - x_std_tgt)[valid]\n",
    "            sse   = (diff * diff).sum()\n",
    "            nvalid= valid.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if max_grad and max_grad > 0:\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        train_sse += float(sse.item())\n",
    "        train_n   += float(nvalid.item())\n",
    "        last_l2    = float(l2_loss.detach().item())\n",
    "\n",
    "    scheduler.step()\n",
    "    train_mse = train_sse / max(1.0, train_n)\n",
    "    val_mse   = evaluate(model, val_loader, DEVICE, feat_mean, feat_std)\n",
    "\n",
    "    # EMA smoothing + early stop\n",
    "    val_ema = train_mse if val_ema is None else (1-ema_alpha)*train_mse + ema_alpha*train_mse\n",
    "    improved = (best_val - val_ema) > min_delta\n",
    "    logger.info(f\"Epoch {epoch:03d}  train_mse(std): {train_mse:.6f}  val_mse(std): {val_mse:.6f}  \"\n",
    "          f\"val_ema: {val_ema:.6f}  last l2: {last_l2:.6f}\")\n",
    "\n",
    "    if improved:\n",
    "        best_val = val_ema\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch':                epoch,\n",
    "            'model_state_dict':     model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_mse':         float(val_mse),\n",
    "            'feat_mean':            feat_mean,\n",
    "            'feat_std':             feat_std,\n",
    "        }, checkpoint_path)\n",
    "        logger.info(\"   Saved new best model.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(f\"   Early stopping after {patience} epochs without meaningful improvement.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96000b9f-4193-40c1-a19f-58ed27c84787",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path  = \"./models/best_model_tod_finetune_2_simulation.pth\"\n",
    "# ---- compute train-only stats once ----\n",
    "feat_mean, feat_std = estimate_feature_stats(ttrain_loader, DEVICE)\n",
    "feat_mean, feat_std = feat_mean.to(DEVICE), feat_std.to(DEVICE)\n",
    "\n",
    "\n",
    "# -------------------- TRAIN LOOP (MSE / Huber + optional adaptive L2) --------\n",
    "USE_HUBER      = False      # set True to use Huber instead of MSE\n",
    "# before training loop\n",
    "L2_COEFF       = 0.0      # <- your fixed coefficient\n",
    "warmup_epochs  = 0       # same as before (or 0 to disable warmup)\n",
    "\n",
    "use_amp        = (DEVICE.type == \"cuda\")\n",
    "scaler         = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "from contextlib import nullcontext\n",
    "amp_ctx = (lambda: torch.amp.autocast('cuda', dtype=torch.float16)) if use_amp else (lambda: nullcontext())\n",
    "\n",
    "best_val, epochs_no_improve = float(\"inf\"), 0\n",
    "min_delta, patience = 1e-4, 100\n",
    "ema_alpha, val_ema  = 0.2, None\n",
    "max_grad = 1.0  # set to 0 to disable clipping\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    train_sse, train_n, last_l2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, _, _ in train_loader:\n",
    "        x, pad_mask, obs_mask = x.to(DEVICE), pad_mask.to(DEVICE).bool(), obs_mask.to(DEVICE).bool()\n",
    "        x_in, x_std_tgt = standardize_batch(x, obs_mask, feat_mean, feat_std, pad_mask)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with amp_ctx():\n",
    "            recon, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "            # reconstruction loss in standardized space\n",
    "            recon_loss = masked_huber(recon, x_std_tgt, pad_mask, obs_mask, delta=1.0) if USE_HUBER \\\n",
    "                         else masked_mse  (recon, x_std_tgt, pad_mask, obs_mask)\n",
    "\n",
    "            # optional adaptive latent L2: keeps l2  TARGET_L2_RATIO * recon\n",
    "            eps = 1e-8\n",
    "            # inside the training step, after you computed recon_loss and z\n",
    "            latent_l2 = z.pow(2).sum(dim=1).mean()        # E[||z||^2] over the batch\n",
    "            warm      = min(1.0, (epoch + 1) / max(1, warmup_epochs))\n",
    "            l2_loss   = L2_COEFF * warm * latent_l2\n",
    "            \n",
    "            loss = recon_loss + l2_loss\n",
    "\n",
    "            # for logging standardized MSE\n",
    "            valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "            diff  = (recon - x_std_tgt)[valid]\n",
    "            sse   = (diff * diff).sum()\n",
    "            nvalid= valid.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if max_grad and max_grad > 0:\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        train_sse += float(sse.item())\n",
    "        train_n   += float(nvalid.item())\n",
    "        last_l2    = float(l2_loss.detach().item())\n",
    "\n",
    "    scheduler.step()\n",
    "    train_mse = train_sse / max(1.0, train_n)\n",
    "    val_mse   = evaluate(model, val_loader, DEVICE, feat_mean, feat_std)\n",
    "\n",
    "    # EMA smoothing + early stop\n",
    "    val_ema = val_mse if val_ema is None else (1-ema_alpha)*val_ema + ema_alpha*val_mse\n",
    "    improved = (best_val - val_ema) > min_delta\n",
    "    print(f\"Epoch {epoch:03d}  train_mse(std): {train_mse:.6f}  val_mse(std): {val_mse:.6f}  \"\n",
    "          f\"val_ema: {val_ema:.6f}  last l2: {last_l2:.6f}\")\n",
    "\n",
    "    if improved:\n",
    "        best_val = val_ema\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch':                epoch,\n",
    "            'model_state_dict':     model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_mse':         float(val_mse),\n",
    "            'feat_mean':            feat_mean,\n",
    "            'feat_std':             feat_std,\n",
    "        }, checkpoint_path)\n",
    "        print(\"   Saved new best model.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"   Early stopping after {patience} epochs without meaningful improvement.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f89ccb1a-394b-4824-ae1f-9ca3be4916c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m checkpoint_path  = \u001b[33m\"\u001b[39m\u001b[33m./models/best_model_tod_3.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model.load_state_dict(ckpt[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m feat_mean = ckpt.get(\u001b[33m'\u001b[39m\u001b[33mfeat_mean\u001b[39m\u001b[33m'\u001b[39m, feat_mean).to(DEVICE)\n\u001b[32m      6\u001b[39m feat_std  = ckpt.get(\u001b[33m'\u001b[39m\u001b[33mfeat_std\u001b[39m\u001b[33m'\u001b[39m,  feat_std ).to(DEVICE)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Pipeline' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "# -------------------- TEST --------------------\n",
    "checkpoint_path  = \"./models/best_model_tod_3.pth\"\n",
    "ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "feat_mean = ckpt.get('feat_mean', feat_mean).to(DEVICE)\n",
    "feat_std  = ckpt.get('feat_std',  feat_std ).to(DEVICE)\n",
    "\n",
    "test_mse_std = evaluate(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "test_mse_org = evaluate_original_scale(model, test_loader, DEVICE, feat_mean, feat_std)\n",
    "print(f\" Test MSE (std): {test_mse_std:.6f}   |  Test MSE (orig): {test_mse_org:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48ada3c6-48cb-4b15-9bb9-0f5d19d9c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traj 0be69199cbf323a60203877d040c6583c6bbb5c20c2189f1ea9f133dcaba3b4a ===\n",
      "z shape: (64,) | ||z||2=0.064 | mean|z|=0.0045\n",
      "Cosine per step (std space, masked)  avg=0.9596, median=0.9668, best=0.9691, worst=0.9255\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      "109    13     128 0.9255\n",
      "108    12     128 0.9357\n",
      " 51     3     128 0.9568\n",
      " 52     4     128 0.9569\n",
      "134    14     128 0.9614\n",
      " 19    19     128 0.9615\n",
      "116    20     128 0.9668\n",
      "117    21     128 0.9677\n",
      "119    23     128 0.9678\n",
      " 22    22     128 0.9678\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      "  8     8     128 0.9691\n",
      " 39    15     128 0.9690\n",
      "  9     9     128 0.9690\n",
      " 22    22     128 0.9678\n",
      "119    23     128 0.9678\n",
      "117    21     128 0.9677\n",
      "116    20     128 0.9668\n",
      " 19    19     128 0.9615\n",
      "134    14     128 0.9614\n",
      " 52     4     128 0.9569\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      96    4.0857                 56.5       13\n",
      "      79    5.6164                 52.5       13\n",
      "      24    0.1899                 44.3       13\n",
      "      29    0.1875                 43.7       13\n",
      "      98    3.4779                 42.7       13\n",
      "      18    0.1787                 41.3       13\n",
      "      23    0.1963                 41.2       13\n",
      "     123    3.3994                 39.9       13\n",
      "       5    0.1853                 38.5       13\n",
      "       0    0.1743                 38.3       13\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      97    0.3526                  7.7       13\n",
      "     102    1.3861                  8.5       13\n",
      "       4    0.0509                 10.8       13\n",
      "     105    1.1941                 11.2       13\n",
      "      35    0.0563                 11.4       13\n",
      "      84    1.4258                 11.6       13\n",
      "      25    0.0572                 11.6       13\n",
      "      69    1.3118                 11.7       13\n",
      "      60    0.0581                 12.1       13\n",
      "      17    0.0509                 12.1       13\n",
      "\n",
      "=== Traj 5625a5c6d8d568a375e391cd7b0ef43bc87b7ece25663712000259876a7cca9d ===\n",
      "z shape: (64,) | ||z||2=0.085 | mean|z|=0.0068\n",
      "Cosine per step (std space, masked)  avg=0.9463, median=0.9466, best=0.9526, worst=0.9196\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      " 93    21     128 0.9196\n",
      " 90    18     128 0.9301\n",
      " 86    14     128 0.9329\n",
      "116    20     128 0.9372\n",
      "109    13     128 0.9459\n",
      " 87    15     128 0.9461\n",
      " 56     8     128 0.9461\n",
      "107    11     128 0.9462\n",
      " 40    16     128 0.9463\n",
      " 36    12     128 0.9465\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      "  t  hour  n_dims cosine\n",
      " 30     6     128 0.9526\n",
      " 53     5     128 0.9526\n",
      " 28     4     128 0.9525\n",
      " 79     7     128 0.9524\n",
      "121     1     128 0.9523\n",
      " 99     3     128 0.9522\n",
      " 74     2     128 0.9522\n",
      "118    22     128 0.9522\n",
      " 71    23     128 0.9521\n",
      " 24     0     128 0.9520\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      55    0.3064                 66.3       23\n",
      "      30    0.2584                 60.3       23\n",
      "      27    0.2468                 56.4       23\n",
      "      53    0.2699                 55.9       23\n",
      "      79    5.9715                 55.8       23\n",
      "     110    5.2826                 55.7       23\n",
      "      78    4.0601                 55.3       23\n",
      "      46    0.2348                 50.4       23\n",
      "      67    6.2488                 50.0       23\n",
      "      35    0.2327                 47.3       23\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "     111    1.3870                  5.9       23\n",
      "      88    0.8719                  8.2       23\n",
      "      90    1.3994                 10.7       23\n",
      "     118    1.5150                 11.8       23\n",
      "      60    0.0571                 11.9       23\n",
      "     112    1.4060                 12.5       23\n",
      "      15    0.0597                 12.6       23\n",
      "     102    2.1044                 12.9       23\n",
      "      84    1.6048                 13.1       23\n",
      "     117    1.1685                 14.2       23\n",
      "\n",
      "=== Traj db8c1845f4c22fa37bd0779dd7f8a493e8c5e86c0461ba18c336d1ab003660b5 ===\n",
      "z shape: (64,) | ||z||2=0.036 | mean|z|=0.0033\n",
      "Cosine per step (std space, masked)  avg=0.9304, median=0.9286, best=0.9536, worst=0.9032\n",
      "\n",
      "Top-10 WORST time steps by cosine:\n",
      " t  hour  n_dims cosine\n",
      "81     9     128 0.9032\n",
      "85    13     128 0.9041\n",
      "19    19     128 0.9225\n",
      "95    23     128 0.9226\n",
      "42    18     128 0.9227\n",
      "44    20     128 0.9228\n",
      "65    17     128 0.9232\n",
      "38    14     128 0.9340\n",
      "22    22     128 0.9340\n",
      "21    21     128 0.9340\n",
      "\n",
      "Top-10 BEST time steps by cosine:\n",
      " t  hour  n_dims cosine\n",
      "82    10     128 0.9536\n",
      "80     8     128 0.9535\n",
      "39    15     128 0.9478\n",
      "40    16     128 0.9475\n",
      "21    21     128 0.9340\n",
      "22    22     128 0.9340\n",
      "38    14     128 0.9340\n",
      "65    17     128 0.9232\n",
      "44    20     128 0.9228\n",
      "42    18     128 0.9227\n",
      "\n",
      "Top-10 WORST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "     123    6.7340                 79.0       14\n",
      "     110    6.3882                 67.3       14\n",
      "      59    0.2777                 62.5       14\n",
      "     115    5.8927                 62.4       14\n",
      "     122    3.9380                 58.0       14\n",
      "      46    0.2638                 56.6       14\n",
      "      47    0.2535                 56.3       14\n",
      "       3    0.2632                 55.6       14\n",
      "      57    0.2452                 53.8       14\n",
      "      74    5.1560                 52.8       14\n",
      "\n",
      "Top-10 BEST features by % of train std:\n",
      " feature RMSE_orig NRMSE_%_of_train_std  n_valid\n",
      "      98    0.7943                  9.7       14\n",
      "       4    0.0504                 10.7       14\n",
      "      31    0.0553                 12.0       14\n",
      "      90    1.6783                 12.9       14\n",
      "     109    2.1532                 13.5       14\n",
      "      64    1.7853                 13.9       14\n",
      "      39    0.0681                 14.4       14\n",
      "     104    0.8313                 14.9       14\n",
      "      17    0.0631                 15.1       14\n",
      "      89    2.4264                 16.0       14\n",
      "\n",
      "=== Dataset cosine summary (std space, masked) ===\n",
      "mean=0.9352  median=0.9415  p05=0.8792  p95=0.9731  n=168981\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_examples(model, loader, device, feat_mean, feat_std, k=5, which=\"first\", top_k=10):\n",
    "    \"\"\"\n",
    "    For k trajectories: prints latent stats, per-feature RMSE (orig scale),\n",
    "    and per-time-step cosine similarity (std space, masked).\n",
    "    which: \"first\" | \"random\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    shown, rng = 0, np.random.default_rng(0)\n",
    "\n",
    "    for x, pad_mask, obs_mask, hours, idxs, traj_ids in loader:\n",
    "        x        = x.to(device)                 # (B,L,D) raw\n",
    "        pad_mask = pad_mask.to(device).bool()   # (B,L)\n",
    "        obs_mask = obs_mask.to(device).bool()   # (B,L,D)\n",
    "        hours    = hours.to(device).long()      # (B,L)\n",
    "\n",
    "        # standardize inputs as in training\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        x_in  = x_std.masked_fill(~obs_mask, 0.0).masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "\n",
    "        recon_std, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        # for reporting RMSE in original scale\n",
    "        recon = recon_std * feat_std.view(1,1,-1) + feat_mean.view(1,1,-1)\n",
    "\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)      # (B,L,D)\n",
    "        B, L, D = x.shape\n",
    "\n",
    "        order = list(range(B))\n",
    "        if which == \"random\":\n",
    "            rng.shuffle(order)\n",
    "\n",
    "        for b in order:\n",
    "            vb = valid[b]  # (L,D)\n",
    "            if not vb.any():\n",
    "                continue\n",
    "\n",
    "            # ---- per-feature RMSE on ORIGINAL scale ----\n",
    "            se_feat = torch.zeros(D, device=device)\n",
    "            n_feat  = torch.zeros(D, device=device)\n",
    "            for t in range(L):\n",
    "                vtd = vb[t]                            # (D,)\n",
    "                if vtd.any():\n",
    "                    dtd = (recon[b, t] - x[b, t])[vtd]\n",
    "                    se_feat[vtd] += dtd.pow(2)\n",
    "                    n_feat[vtd]  += 1\n",
    "            rmse_feat = (se_feat / n_feat.clamp_min(1)).sqrt().cpu().numpy()  # (D,)\n",
    "            feat_std_np = feat_std.cpu().numpy()\n",
    "            nrmse_pct = 100.0 * (rmse_feat / np.maximum(feat_std_np, 1e-8))\n",
    "\n",
    "            df_feat = pd.DataFrame({\n",
    "                \"feature\": np.arange(D),\n",
    "                \"RMSE_orig\": rmse_feat,\n",
    "                \"NRMSE_%_of_train_std\": nrmse_pct,\n",
    "                \"n_valid\": n_feat.cpu().numpy().astype(int)\n",
    "            })\n",
    "            worst_feat = df_feat.sort_values(\"NRMSE_%_of_train_std\", ascending=False).head(top_k)\n",
    "            best_feat  = df_feat.sort_values(\"NRMSE_%_of_train_std\", ascending=True ).head(top_k)\n",
    "\n",
    "            # ---- per-time-step cosine similarity (STANDARDIZED) ----\n",
    "            cos_list, n_dim_list, hour_list, tidx_list = [], [], [], []\n",
    "            for t in range(L):\n",
    "                vtd = vb[t]  # valid dims at time t\n",
    "                if vtd.any():\n",
    "                    xt = x_std[b, t][vtd]\n",
    "                    rt = recon_std[b, t][vtd]\n",
    "                    # cosine with masking\n",
    "                    denom = (xt.norm() * rt.norm()).clamp_min(1e-12)\n",
    "                    cos_t = float((xt * rt).sum() / denom)\n",
    "                    cos_list.append(cos_t)\n",
    "                    n_dim_list.append(int(vtd.sum().item()))\n",
    "                    hour_list.append(int(hours[b, t].item()))\n",
    "                    tidx_list.append(t)\n",
    "\n",
    "            if len(cos_list) == 0:\n",
    "                avg_cos, med_cos = float(\"nan\"), float(\"nan\")\n",
    "                best_steps = worst_steps = pd.DataFrame()\n",
    "            else:\n",
    "                cos_arr = np.array(cos_list)\n",
    "                avg_cos = float(np.mean(cos_arr))\n",
    "                med_cos = float(np.median(cos_arr))\n",
    "                df_time = pd.DataFrame({\n",
    "                    \"t\": tidx_list,\n",
    "                    \"hour\": hour_list,\n",
    "                    \"n_dims\": n_dim_list,\n",
    "                    \"cosine\": cos_arr\n",
    "                })\n",
    "                best_steps  = df_time.sort_values(\"cosine\", ascending=False).head(top_k)\n",
    "                worst_steps = df_time.sort_values(\"cosine\", ascending=True ).head(top_k)\n",
    "\n",
    "            # ---- print summary ----\n",
    "            z_np = z[b].cpu().numpy()\n",
    "            print(f\"\\n=== Traj {traj_ids[b]} ===\")\n",
    "            print(f\"z shape: {z_np.shape} | ||z||2={np.linalg.norm(z_np):.3f} | mean|z|={np.abs(z_np).mean():.4f}\")\n",
    "            print(f\"Cosine per step (std space, masked)  avg={avg_cos:.4f}, median={med_cos:.4f}, \"\n",
    "                  f\"best={np.max(cos_list) if cos_list else float('nan'):.4f}, \"\n",
    "                  f\"worst={np.min(cos_list) if cos_list else float('nan'):.4f}\")\n",
    "\n",
    "            print(\"\\nTop-10 WORST time steps by cosine:\")\n",
    "            if len(cos_list):\n",
    "                print(worst_steps.to_string(index=False, formatters={\n",
    "                    \"cosine\": lambda v: f\"{v:.4f}\"\n",
    "                }))\n",
    "            else:\n",
    "                print(\"  (no valid steps)\")\n",
    "\n",
    "            print(\"\\nTop-10 BEST time steps by cosine:\")\n",
    "            if len(cos_list):\n",
    "                print(best_steps.to_string(index=False, formatters={\n",
    "                    \"cosine\": lambda v: f\"{v:.4f}\"\n",
    "                }))\n",
    "            else:\n",
    "                print(\"  (no valid steps)\")\n",
    "\n",
    "            print(\"\\nTop-10 WORST features by % of train std:\")\n",
    "            print(worst_feat.to_string(index=False, formatters={\n",
    "                \"RMSE_orig\": lambda v: f\"{v:.4f}\",\n",
    "                \"NRMSE_%_of_train_std\": lambda v: f\"{v:.1f}\"\n",
    "            }))\n",
    "            print(\"\\nTop-10 BEST features by % of train std:\")\n",
    "            print(best_feat.to_string(index=False, formatters={\n",
    "                \"RMSE_orig\": lambda v: f\"{v:.4f}\",\n",
    "                \"NRMSE_%_of_train_std\": lambda v: f\"{v:.1f}\"\n",
    "            }))\n",
    "\n",
    "            shown += 1\n",
    "            if shown >= k:\n",
    "                return\n",
    "\n",
    "    if shown == 0:\n",
    "        print(\"No valid examples found (all entries missing?)\")\n",
    "\n",
    "\n",
    "# ---------- Optional: dataset-level cosine summary ----------\n",
    "@torch.no_grad()\n",
    "def summarize_cosine(model, loader, device, feat_mean, feat_std):\n",
    "    \"\"\"Aggregate cosine per time step across the whole loader.\"\"\"\n",
    "    model.eval()\n",
    "    cos_vals = []\n",
    "    for x, pad_mask, obs_mask, hours, *_ in loader:\n",
    "        x        = x.to(device)\n",
    "        pad_mask = pad_mask.to(device).bool()\n",
    "        obs_mask = obs_mask.to(device).bool()\n",
    "        x_std = (x - feat_mean.view(1,1,-1)) / feat_std.view(1,1,-1)\n",
    "        x_in  = x_std.masked_fill(~obs_mask, 0.0).masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "        recon_std, _ = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "        valid = obs_mask & (~pad_mask).unsqueeze(-1)\n",
    "        B, L, D = x.shape\n",
    "        for b in range(B):\n",
    "            for t in range(L):\n",
    "                vtd = valid[b, t]\n",
    "                if vtd.any():\n",
    "                    xt = x_std[b, t][vtd]\n",
    "                    rt = recon_std[b, t][vtd]\n",
    "                    denom = (xt.norm() * rt.norm()).clamp_min(1e-12)\n",
    "                    cos_vals.append(float((xt * rt).sum() / denom))\n",
    "    if not cos_vals:\n",
    "        print(\"No valid steps for cosine.\")\n",
    "        return\n",
    "    arr = np.array(cos_vals)\n",
    "    print(\"\\n=== Dataset cosine summary (std space, masked) ===\")\n",
    "    print(f\"mean={arr.mean():.4f}  median={np.median(arr):.4f}  \"\n",
    "          f\"p05={np.percentile(arr,5):.4f}  p95={np.percentile(arr,95):.4f}  n={arr.size}\")\n",
    "\n",
    "# ---- Example usage ----\n",
    "# Non-shuffled loader for inspection\n",
    "test_inspect_loader = DataLoader(\n",
    "    test_ds, batch_size=32, shuffle=False,\n",
    "    collate_fn=collate_fn, pin_memory=(DEVICE.type=='cuda')\n",
    ")\n",
    "\n",
    "analyze_examples(model, test_inspect_loader, DEVICE, feat_mean, feat_std, k=3, which=\"first\", top_k=10)\n",
    "summarize_cosine(model, test_inspect_loader, DEVICE, feat_mean, feat_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fa57ca5-5e3a-4cdb-b127-d80fd7aa972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def collect_latents(model, loader, device, feat_mean, feat_std):\n",
    "    model.eval()\n",
    "    Z_chunks, ids = [], []\n",
    "    for x, pad_mask, obs_mask, hours, _, traj_ids in loader:\n",
    "        x        = x.to(device)\n",
    "        pad_mask = pad_mask.to(device).bool()\n",
    "        obs_mask = obs_mask.to(device).bool()\n",
    "\n",
    "        # same standardization you used for training\n",
    "        x_in, _ = standardize_batch(x, obs_mask, feat_mean, feat_std)  # or pass pad_mask if your fn supports it\n",
    "        _, z = model(x_in, src_key_padding_mask=pad_mask, start_hour=0)\n",
    "\n",
    "        Z_chunks.append(z.cpu())      # (B, d_model)\n",
    "        ids.extend(traj_ids)          # keep exact mapping\n",
    "    Z = torch.cat(Z_chunks, dim=0).numpy()  # (N_traj, d_model)\n",
    "    return Z, ids\n",
    "\n",
    "# Build a NON-shuffled loader over the set you want to cluster (train/val/test/full)\n",
    "full_loader = DataLoader(\n",
    "    dataset,                      # or train_ds / val_ds / test_ds\n",
    "    batch_size=128,\n",
    "    shuffle=False,                # IMPORTANT for reproducible ordering (we still collect ids anyway)\n",
    "    collate_fn=collate_fn,        # your make_collate_fn_time(...)\n",
    "    pin_memory=(DEVICE.type=='cuda'),\n",
    ")\n",
    "\n",
    "Z, ids = collect_latents(model, full_loader, DEVICE, feat_mean, feat_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c71642e5-ce53-4d18-95e9-a7f9abc1838a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95410, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a275fc8e-c7a2-4fce-bc11-ee036876f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./latent.npy', Z)\n",
    "np.save('./ids.npy', ids)\n",
    "#loaded_data = np.load('my_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "07ecb973-9c1e-4dc3-823f-c1f958017b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95410,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_gdf.traj_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095d2e7-6b31-49a0-bf93-3464aee70b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means_constrained import KMeansConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cc88e-ce64-4aae-aa86-6bf911175298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "Zs = StandardScaler().fit_transform(Z) \n",
    "kmeans = KMeansConstrained(\n",
    "    n_clusters=4,\n",
    "    size_min=10,\n",
    "    size_max=30,\n",
    "    random_state=42\n",
    ")\n",
    "kmeans.fit_predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9ab76-5e23-4de2-9c3b-abc911ad2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ground_t.pickle\", 'rb') as f:\n",
    "    y_true_str = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137c1d0-dddb-4398-9b3c-6ac221170e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_str = [y_true_str[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af74479-436d-451c-9ee6-d96e84035cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def per_category_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute per-category accuracy (recall) using optimal clusterlabel mapping.\n",
    "    Returns:\n",
    "      per_class_df, mapping_dict, overall_acc, confmat_df\n",
    "    \"\"\"\n",
    "    # Encode true labels to stable ints\n",
    "    le = LabelEncoder().fit(y_true)\n",
    "    yt = le.transform(y_true)\n",
    "    yp = np.asarray(y_pred)\n",
    "\n",
    "    # Build confusion matrix (rows=true, cols=pred)\n",
    "    true_classes = np.arange(len(le.classes_))\n",
    "    pred_classes = np.unique(yp)\n",
    "    C = confusion_matrix(yt, yp, labels=true_classes)\n",
    "\n",
    "    # If #pred  #true, pad to square for Hungarian\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:\n",
    "        C_pad = np.pad(C, ((0,0),(0, nT-nP)), mode='constant')\n",
    "    elif nP > nT:\n",
    "        C_pad = np.pad(C, ((0, nP-nT),(0,0)), mode='constant')\n",
    "    else:\n",
    "        C_pad = C\n",
    "\n",
    "    # Hungarian to maximize trace\n",
    "    r_idx, c_idx = linear_sum_assignment(-C_pad)\n",
    "    # Build mapping from pred cluster -> true class index (only valid ones)\n",
    "    mapping = {}\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:  # ignore padded region\n",
    "            mapping[pred_classes[c]] = true_classes[r]\n",
    "\n",
    "    # Apply mapping to predictions (unmapped preds remain unmapped -> will count as wrong)\n",
    "    yp_mapped_true_idx = np.array([mapping.get(p, -9999) for p in yp])\n",
    "\n",
    "    # Overall accuracy (micro)\n",
    "    overall_acc = float(np.mean(yp_mapped_true_idx == yt))\n",
    "\n",
    "    # Per-class stats\n",
    "    rows = []\n",
    "    for k, name in enumerate(le.classes_):\n",
    "        support = int(np.sum(yt == k))\n",
    "        correct = int(np.sum((yt == k) & (yp_mapped_true_idx == k)))\n",
    "        # predicted positives for this class (precision denom)\n",
    "        pred_pos = int(np.sum(yp_mapped_true_idx == k))\n",
    "        recall = (correct / support) if support else np.nan\n",
    "        precision = (correct / pred_pos) if pred_pos else np.nan\n",
    "        f1 = (2*precision*recall / (precision+recall)) if (precision and recall) else np.nan\n",
    "        rows.append(dict(category=name, support=support, correct=correct,\n",
    "                         accuracy_recall=recall, precision=precision, f1=f1))\n",
    "    per_class_df = pd.DataFrame(rows).sort_values(\"category\").reset_index(drop=True)\n",
    "\n",
    "    # Nice confusion matrix with mapped columns renamed to true labels (for reference)\n",
    "    confmat_df = pd.DataFrame(C, index=[f\"true:{c}\" for c in le.classes_],\n",
    "                                 columns=[f\"pred:{p}\" for p in pred_classes])\n",
    "\n",
    "    return per_class_df, {k: le.classes_[v] for k, v in mapping.items()}, overall_acc, confmat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1519f-4ba8-40d5-8bc7-af42377ea8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "for i in tqdm(range(1000)):\n",
    "\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=4,\n",
    "        size_min=5,\n",
    "        size_max=35,\n",
    "        random_state=i\n",
    "    )\n",
    "    kmeans.fit_predict(X)\n",
    "    \n",
    "    #print(\"Cluster labels:\", kmeans.labels_)\n",
    "    #print(\"Cluster centers:\", kmeans.cluster_centers_)# whiten latents\n",
    "    #kmeans = KMeans(n_clusters=4, n_init=20, random_state=0)\n",
    "    labels = kmeans.fit_predict(Zs)\n",
    "    sil = silhouette_score(Zs, labels)\n",
    "    \n",
    "    cluster_df = pd.DataFrame({\"traj_id\": ids, \"cluster\": labels})\n",
    "    \n",
    "    labels  = cluster_df.cluster.to_list()\n",
    "    per_class, mapping, acc_overall, cm = per_category_accuracy(y_true_str, labels)\n",
    "    if acc_overall<= best:\n",
    "        pass\n",
    "    else:\n",
    "        best = acc_overall\n",
    "        best_model = kmeans\n",
    "        best_df = cluster_df\n",
    "        print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abd7f6-2828-49b3-b2ca-cadacdec8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3-class sweep with KMeansConstrained (drop 'evac_short_in_zone') ---\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Inputs you already have:\n",
    "#   Zs          -> standardized features for ALL rows (np.array, shape [N, d])\n",
    "#   y_true_str  -> ground-truth strings of length N\n",
    "#   ids         -> traj ids of length N\n",
    "\n",
    "# 1) keep only the 3 classes we care about\n",
    "keep = pd.Series(y_true_str).isin([\"evac_out_of_zone\", \"sip_home_grocery\", \"sip_hospital\"]).to_numpy()\n",
    "Zs3   = Zs[keep]\n",
    "y3    = pd.Series(y_true_str)[keep].astype(str).reset_index(drop=True)\n",
    "ids3  = pd.Series(ids)[keep].reset_index(drop=True)\n",
    "\n",
    "print(f\"Using {keep.sum()} rows; dropped {(~keep).sum()} 'evac_short_in_zone'.\")\n",
    "\n",
    "# 2) label-safe evaluator (works for any #clusters; here it will be 3)\n",
    "def per_category_accuracy_3(y_true, y_pred):\n",
    "    yt = pd.Series(list(map(str, y_true)), name=\"true\")\n",
    "    yp = pd.Series(list(y_pred), name=\"pred\")\n",
    "\n",
    "    cm = pd.crosstab(yt, yp, dropna=False)              # rows=true names, cols=cluster ids\n",
    "    true_names = cm.index.tolist()\n",
    "    pred_ids   = cm.columns.tolist()\n",
    "    C = cm.to_numpy()\n",
    "\n",
    "    # pad to square for Hungarian\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:   Cpad = np.pad(C, ((0,0),(0,nT-nP)), 'constant')\n",
    "    elif nP > nT: Cpad = np.pad(C, ((0,nP-nT),(0,0)), 'constant')\n",
    "    else:         Cpad = C\n",
    "\n",
    "    r_idx, c_idx = linear_sum_assignment(-Cpad)\n",
    "    mapping = {}\n",
    "    correct = 0\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:\n",
    "            mapping[pred_ids[c]] = true_names[r]\n",
    "            correct += C[r, c]\n",
    "    acc = correct / len(yt)\n",
    "\n",
    "    # per-class recall/precision/F1\n",
    "    yp_named = yp.map(mapping)\n",
    "    rows = []\n",
    "    for name in true_names:\n",
    "        m_true  = (yt == name)\n",
    "        support = int(m_true.sum())\n",
    "        correct = int(((yt == name) & (yp_named == name)).sum())\n",
    "        predpos = int((yp_named == name).sum())\n",
    "        recall = correct / support if support else np.nan\n",
    "        prec   = correct / predpos if predpos else np.nan\n",
    "        f1     = 2*prec*recall/(prec+recall) if (prec and recall) else np.nan\n",
    "        rows.append(dict(category=name, support=support, correct=correct,\n",
    "                         accuracy_recall=recall, precision=prec, f1=f1))\n",
    "    per_class = pd.DataFrame(rows).sort_values(\"category\").reset_index(drop=True)\n",
    "    return per_class, mapping, acc, cm\n",
    "\n",
    "# 3) sweep random seeds with 3 clusters\n",
    "best_acc = -1.0\n",
    "best_model = None\n",
    "best_df = None\n",
    "best_mapping = None\n",
    "best_per_class = None\n",
    "best_sil = None\n",
    "\n",
    "N3 = len(Zs3)\n",
    "# sensible size bounds for 3 clusters (near-equal but flexible)\n",
    "approx = N3 // 3\n",
    "size_min = max(5, approx - 10)\n",
    "size_max = approx + 10\n",
    "\n",
    "for i in tqdm(range(2000), desc=\"K=3 constrained sweeps\"):\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=3,\n",
    "        size_min=size_min,\n",
    "        size_max=size_max,\n",
    "        random_state=i\n",
    "    )\n",
    "    labels = kmeans.fit_predict(Zs3)\n",
    "\n",
    "    sil = np.nan\n",
    "    try:\n",
    "        sil = silhouette_score(Zs3, labels)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cluster_df = pd.DataFrame({\"traj_id\": ids3, \"cluster\": labels})\n",
    "    per_class, mapping, acc_overall, cm = per_category_accuracy_3(y3, cluster_df.cluster.to_list())\n",
    "\n",
    "    if acc_overall > best_acc:\n",
    "        best_acc = acc_overall\n",
    "        best_model = kmeans\n",
    "        best_df = cluster_df.copy()\n",
    "        best_mapping = mapping\n",
    "        best_per_class = per_class.copy()\n",
    "        best_sil = sil\n",
    "        print(f\"new best acc={best_acc:.3f}\" )\n",
    "\n",
    "print(\"\\n=== BEST (3-class, no 'evac_short_in_zone') ===\")\n",
    "print(\"Overall accuracy:\", round(best_acc, 3))\n",
    "print(\"Cluster  label mapping:\", best_mapping)\n",
    "display(best_per_class)\n",
    "# best_df contains traj_id + cluster for the 3-class subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a66a4b-c51b-4432-ad25-8def77b14302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true_str: array-like of ground-truth strings (e.g., 'sip_home_grocery', ...)\n",
    "# labels:     predicted cluster ids (ints) from your chosen method/run\n",
    "labels  = best_df.cluster.to_list()\n",
    "per_class, mapping, acc_overall, cm = per_category_accuracy(y3, labels)\n",
    "print(\"Overall accuracy (after mapping):\", round(acc_overall, 3))\n",
    "print(\"Clusterlabel mapping:\", mapping)\n",
    "display(per_class)\n",
    "# Optional: display(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22edae8-266b-445e-9800-9595efd71ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ee6ae-c552-4a54-9000-fce856375e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "# y3: ground-truth strings for the kept rows (len N3)\n",
    "# labels (or best_df['cluster']): predicted cluster IDs for the same rows (len N3)\n",
    "# mapping: dict {cluster_id -> class_name} from your Hungarian step on the 3-class subset\n",
    "\n",
    "gt = pd.Series(y3).astype(str).reset_index(drop=True)\n",
    "\n",
    "# predicted clusters aligned with y3\n",
    "if 'labels' in locals() and len(labels) == len(gt):\n",
    "    pred_clusters = pd.Series(labels).reset_index(drop=True)\n",
    "elif 'best_df' in locals() and len(best_df) == len(gt):\n",
    "    pred_clusters = best_df['cluster'].reset_index(drop=True)\n",
    "else:\n",
    "    raise ValueError(\"Provide 'labels' (np.array/list) aligned with y3, or 'best_df[\\\"cluster\\\"]'.\")\n",
    "\n",
    "mapping3 = mapping  # your clusterclass mapping returned earlier\n",
    "\n",
    "# map predicted cluster IDs -> 3-class names\n",
    "y_pred_names = pred_clusters.map(mapping3)\n",
    "\n",
    "# safety: ensure all clusters are mapped\n",
    "if y_pred_names.isna().any():\n",
    "    missing = sorted(pred_clusters[y_pred_names.isna()].unique().tolist())\n",
    "    raise ValueError(f\"Unmapped cluster IDs in mapping: {missing}\")\n",
    "\n",
    "# collapse to binary: 1=EVAC, 0=SIP\n",
    "to_bin = lambda s: 1 if str(s).lower().startswith(\"evac\") else 0\n",
    "y_true_bin = gt.map(to_bin).to_numpy()\n",
    "y_pred_bin = y_pred_names.map(to_bin).to_numpy()\n",
    "\n",
    "# confusion matrix & metrics\n",
    "C = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])\n",
    "cm_df = pd.DataFrame(C, index=[\"true:SIP(0)\",\"true:EVAC(1)\"], columns=[\"pred:SIP(0)\",\"pred:EVAC(1)\"])\n",
    "tn, fp, fn, tp = C.ravel()\n",
    "acc     = (tp + tn) / C.sum()\n",
    "bal_acc = balanced_accuracy_score(y_true_bin, y_pred_bin)\n",
    "mcc     = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
    "report  = classification_report(y_true_bin, y_pred_bin,\n",
    "                                labels=[0,1], target_names=[\"SIP(0)\",\"EVAC(1)\"],\n",
    "                                output_dict=True, zero_division=0)\n",
    "\n",
    "print(\"Clusterclass mapping used:\", mapping3)\n",
    "display(cm_df)\n",
    "print(f\"Overall accuracy:    {acc:.3f}\")\n",
    "print(f\"Balanced accuracy:   {bal_acc:.3f}\")\n",
    "print(f\"Matthews corr (MCC): {mcc:.3f}\")\n",
    "print(f\"SIP   P:{report['SIP(0)']['precision']:.3f}  R:{report['SIP(0)']['recall']:.3f}  F1:{report['SIP(0)']['f1-score']:.3f}  (n={int(report['SIP(0)']['support'])})\")\n",
    "print(f\"EVAC  P:{report['EVAC(1)']['precision']:.3f}  R:{report['EVAC(1)']['recall']:.3f}  F1:{report['EVAC(1)']['f1-score']:.3f}  (n={int(report['EVAC(1)']['support'])})\")\n",
    "\n",
    "# Optional: attach to your table\n",
    "# best_df['gt_binary']   = y_true_bin\n",
    "# best_df['pred_binary'] = y_pred_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a82e44-5e73-4545-962d-1941ddcc8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from math import sqrt\n",
    "from scipy.stats import fisher_exact, chi2_contingency, binomtest\n",
    "\n",
    "# Inputs already computed above:\n",
    "# C            -> 2x2 confusion matrix with order [[TN, FP],[FN, TP]]\n",
    "# y_true_bin   -> 0=SIP, 1=EVAC\n",
    "# y_pred_bin   -> 0=SIP, 1=EVAC\n",
    "\n",
    "tn, fp, fn, tp = C.ravel()\n",
    "N = C.sum()\n",
    "acc = (tp + tn) / N\n",
    "sens = tp / (tp + fn) if (tp + fn) else np.nan  # EVAC recall\n",
    "spec = tn / (tn + fp) if (tn + fp) else np.nan  # SIP recall\n",
    "prev1 = (y_true_bin == 1).mean()\n",
    "prev0 = 1 - prev1\n",
    "maj_base = max(prev0, prev1)  # majority-class baseline accuracy\n",
    "\n",
    "def wilson(successes, n, alpha=0.05):\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    z = 1.959963984540054  # ~ N(0,1) 97.5% for 95% CI\n",
    "    p = successes / n\n",
    "    denom = 1 + z**2 / n\n",
    "    center = (p + z**2/(2*n)) / denom\n",
    "    half = (z * sqrt((p*(1-p) + z**2/(4*n)) / n)) / denom\n",
    "    return center - half, center + half\n",
    "\n",
    "acc_ci = wilson(tp + tn, N)\n",
    "sens_ci = wilson(tp, tp + fn) if np.isfinite(sens) else (np.nan, np.nan)\n",
    "spec_ci = wilson(tn, tn + fp) if np.isfinite(spec) else (np.nan, np.nan)\n",
    "\n",
    "# 1) Fisher's exact test (association)\n",
    "odds_ratio, p_fisher = fisher_exact([[tn, fp],[fn, tp]], alternative=\"two-sided\")\n",
    "\n",
    "# 2) Chi-square test of independence\n",
    "chi2, p_chi, dof, expected = chi2_contingency([[tn, fp],[fn, tp]], correction=False)\n",
    "\n",
    "# 3) Exact binomial tests on accuracy\n",
    "p_binom_vs_majority = binomtest(k=int(tp+tn), n=int(N), p=float(maj_base), alternative=\"greater\").pvalue\n",
    "p_binom_vs_half     = binomtest(k=int(tp+tn), n=int(N), p=0.5,             alternative=\"greater\").pvalue\n",
    "\n",
    "# 4) McNemar's test (exact, two-sided) on disagreements b=FP, c=FN\n",
    "b, c = fp, fn\n",
    "if (b + c) > 0:\n",
    "    # exact McNemar p-value via binomial\n",
    "    k = min(b, c)\n",
    "    from scipy.stats import binom\n",
    "    p_mcnemar = 2 * binom.cdf(k, b + c, 0.5)\n",
    "    p_mcnemar = min(1.0, p_mcnemar)\n",
    "else:\n",
    "    p_mcnemar = np.nan\n",
    "\n",
    "# ---- Print a tidy summary ----\n",
    "print(\"Counts:  TN={}, FP={}, FN={}, TP={}, N={}\".format(tn, fp, fn, tp, N))\n",
    "print(f\"Accuracy = {acc:.3f}  (95% CI {acc_ci[0]:.3f}{acc_ci[1]:.3f})\")\n",
    "print(f\"Sensitivity (EVAC recall) = {sens:.3f}  (95% CI {sens_ci[0]:.3f}{sens_ci[1]:.3f})\")\n",
    "print(f\"Specificity (SIP recall)  = {spec:.3f}  (95% CI {spec_ci[0]:.3f}{spec_ci[1]:.3f})\\n\")\n",
    "\n",
    "print(f\"Fishers exact:  odds ratio={odds_ratio:.3g},  p={p_fisher:.4g}\")\n",
    "print(f\"Chi-square(1):   chi2={chi2:.3f},  p={p_chi:.4g}\")\n",
    "print(f\"Binomial test (acc > majority={maj_base:.3f}):  p={p_binom_vs_majority:.4g}\")\n",
    "print(f\"Binomial test (acc > 0.5):                     p={p_binom_vs_half:.4g}\")\n",
    "print(f\"McNemars exact (FP vs FN symmetry):           p={p_mcnemar:.4g}\")\n",
    "\n",
    "# Optional: a small DataFrame of the p-values\n",
    "pv = pd.DataFrame({\n",
    "    \"test\": [\"Fisher exact\", \"Chi-square\", \"Binomial vs majority\", \"Binomial vs 0.5\", \"McNemar exact\"],\n",
    "    \"p_value\": [p_fisher, p_chi, p_binom_vs_majority, p_binom_vs_half, p_mcnemar]\n",
    "})\n",
    "display(pv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d7dd5-d801-4fb0-9085-8d8e7477f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= BEST MODEL SELECTION ON BINARY (EVAC vs SIP) =========\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, matthews_corrcoef, silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats import fisher_exact, chi2_contingency, binom, binomtest\n",
    "\n",
    "# ---------- Inputs expected ----------\n",
    "#   y_true_str : GT strings for all rows (e.g., 'sip_home_grocery','evac_out_of_zone',...)\n",
    "#   Zs         : standardized features for all rows  (shape [N, d]); if you only have Z, do Zs = StandardScaler().fit_transform(Z)\n",
    "#   ids        : trajectory IDs aligned with rows\n",
    "#\n",
    "# If you already filtered to 3 classes earlier (y3, Zs3, ids3), set USE_SUBSET=True.\n",
    "USE_SUBSET  = True   # set False if you want to keep all 4 classes\n",
    "N_CLASSES   = 3      # 3 if you dropped 'evac_short_in_zone'; else 4\n",
    "KEEP_NAMES  = [\"evac_out_of_zone\", \"sip_home_grocery\", \"sip_hospital\"] if N_CLASSES==3 else None\n",
    "\n",
    "# ---------- Prep subset if requested ----------\n",
    "if USE_SUBSET:\n",
    "    keep = pd.Series(y_true_str).isin(KEEP_NAMES).to_numpy()\n",
    "    gt_names = pd.Series(y_true_str)[keep].astype(str).reset_index(drop=True)\n",
    "    X = np.asarray(Zs)[keep]\n",
    "    ids_used = pd.Series(ids)[keep].reset_index(drop=True)\n",
    "else:\n",
    "    gt_names = pd.Series(y_true_str).astype(str).reset_index(drop=True)\n",
    "    X = np.asarray(Zs)\n",
    "    ids_used = pd.Series(ids).reset_index(drop=True)\n",
    "\n",
    "N = len(gt_names)\n",
    "assert X.shape[0] == N, \"Feature rows must match y_true\"\n",
    "\n",
    "# Reasonable size bounds for constrained KMeans\n",
    "approx = N // N_CLASSES\n",
    "size_min = max(5, approx - 10)\n",
    "size_max = approx + 10\n",
    "\n",
    "# Binary collapse helper\n",
    "to_bin = lambda s: 1 if str(s).lower().startswith(\"evac\") else 0\n",
    "y_true_bin = gt_names.map(to_bin).to_numpy()\n",
    "\n",
    "# ---------- Sweep seeds and pick best by binary objective ----------\n",
    "best_tuple   = None   # lexicographic: (MCC, bal_acc, acc, -p_binom_vs_majority, sil)\n",
    "best_model   = None\n",
    "best_df      = None\n",
    "best_mapping = None\n",
    "best_cm_bin  = None\n",
    "best_report  = None\n",
    "best_stats   = None\n",
    "\n",
    "for seed in tqdm(range(5000), desc=f\"K={N_CLASSES} constrained sweeps (binary selection)\"):\n",
    "    # 1) fit constrained K-means\n",
    "    kmeans = KMeansConstrained(\n",
    "        n_clusters=N_CLASSES,\n",
    "        size_min=20,\n",
    "        size_max=70,\n",
    "        random_state=seed\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # 2) Hungarian map: clusters -> class names (label-safe on crosstab)\n",
    "    cm_full = pd.crosstab(gt_names, pd.Series(labels, name=\"pred\"), dropna=False)\n",
    "    true_names = cm_full.index.tolist()\n",
    "    pred_ids   = cm_full.columns.tolist()\n",
    "    C = cm_full.to_numpy()\n",
    "\n",
    "    # pad to square\n",
    "    nT, nP = C.shape\n",
    "    if nT > nP:\n",
    "        Cpad = np.pad(C, ((0,0),(0,nT-nP)), 'constant')\n",
    "    elif nP > nT:\n",
    "        Cpad = np.pad(C, ((0,nP-nT),(0,0)), 'constant')\n",
    "    else:\n",
    "        Cpad = C\n",
    "\n",
    "    r_idx, c_idx = linear_sum_assignment(-Cpad)\n",
    "    mapping = {}\n",
    "    for r, c in zip(r_idx, c_idx):\n",
    "        if r < nT and c < nP:\n",
    "            mapping[pred_ids[c]] = true_names[r]\n",
    "\n",
    "    # 3) Map predictions to names, then to binary\n",
    "    y_pred_names = pd.Series(labels).map(mapping)\n",
    "    # if any unmapped cluster sneaks in, treat as SIP (conservative)\n",
    "    y_pred_names = y_pred_names.fillna(\"sip_unknown\")\n",
    "    y_pred_bin = y_pred_names.map(to_bin).to_numpy()\n",
    "\n",
    "    # 4) Binary confusion & metrics\n",
    "    C2 = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])\n",
    "    tn, fp, fn, tp = C2.ravel()\n",
    "    N2 = C2.sum()\n",
    "    acc = (tp + tn) / N2\n",
    "    bal_acc = balanced_accuracy_score(y_true_bin, y_pred_bin)\n",
    "    mcc = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
    "\n",
    "    # p-values\n",
    "    # Fisher / Chi-square on 2x2\n",
    "    try:\n",
    "        _, p_fisher = fisher_exact([[tn, fp],[fn, tp]], alternative=\"two-sided\")\n",
    "    except Exception:\n",
    "        p_fisher = np.nan\n",
    "    try:\n",
    "        _, p_chi, _, _ = chi2_contingency([[tn, fp],[fn, tp]], correction=False)\n",
    "    except Exception:\n",
    "        p_chi = np.nan\n",
    "\n",
    "    # Binomial test vs majority baseline\n",
    "    prev1 = (y_true_bin == 1).mean()\n",
    "    prev0 = 1 - prev1\n",
    "    maj_base = float(max(prev0, prev1))\n",
    "    p_binom_vs_maj = binomtest(k=int(tp+tn), n=int(N2), p=maj_base, alternative=\"greater\").pvalue\n",
    "\n",
    "    # McNemar exact\n",
    "    b, c = fp, fn\n",
    "    if (b + c) > 0:\n",
    "        p_mcnemar = 2 * binom.cdf(min(b, c), b + c, 0.5)\n",
    "        p_mcnemar = float(min(1.0, p_mcnemar))\n",
    "    else:\n",
    "        p_mcnemar = np.nan\n",
    "\n",
    "    # silhouette (can fail with degenerate splits)\n",
    "    try:\n",
    "        sil = float(silhouette_score(X, labels))\n",
    "    except Exception:\n",
    "        sil = float(\"nan\")\n",
    "\n",
    "    # objective tuple (maximize first elements, minimize p-value via negative)\n",
    "    score_tuple = (float(mcc), float(bal_acc), float(acc), -float(p_binom_vs_maj), float(sil))\n",
    "\n",
    "    if (best_tuple is None) or (score_tuple > best_tuple):\n",
    "        best_tuple   = score_tuple\n",
    "        best_model   = kmeans\n",
    "        best_df      = pd.DataFrame({\"traj_id\": ids_used, \"cluster\": labels, \"pred_name\": y_pred_names})\n",
    "        best_mapping = mapping.copy()\n",
    "        best_cm_bin  = pd.DataFrame(C2, index=[\"true:SIP(0)\",\"true:EVAC(1)\"], columns=[\"pred:SIP(0)\",\"pred:EVAC(1)\"])\n",
    "        # build a small report dict\n",
    "        best_stats = {\n",
    "            \"acc\": acc, \"balanced_acc\": bal_acc, \"mcc\": mcc,\n",
    "            \"p_fisher\": p_fisher, \"p_chi\": p_chi,\n",
    "            \"p_binom_vs_majority\": p_binom_vs_maj,\n",
    "            \"p_mcnemar\": p_mcnemar,\n",
    "            \"silhouette\": sil,\n",
    "            \"objective_tuple\": score_tuple,\n",
    "        }\n",
    "        print(f\"new BEST  MCC={mcc:.3f}, bal_acc={bal_acc:.3f}, acc={acc:.3f}, p(bin>maj)={p_binom_vs_maj:.2e}, sil={sil:.3f}\")\n",
    "\n",
    "# ---------- Summary ----------\n",
    "print(\"\\n=== BEST MODEL (binary selection) ===\")\n",
    "print(\"Cluster  class mapping:\", best_mapping)\n",
    "display(best_cm_bin)\n",
    "print(\"Metrics:\", {k: (round(v,3) if isinstance(v, (int,float)) and np.isfinite(v) else v) for k,v in best_stats.items()})\n",
    "# best_model     -> the fitted KMeansConstrained instance\n",
    "# best_df        -> DataFrame with traj_id, cluster, and mapped class name for the kept rows\n",
    "# best_mapping   -> dict {cluster_id: class_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d82ac-aeeb-42d3-a003-d8088a95057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_distribution = cluster_df.merge(\n",
    "    clean_joined,            # the table with your new columns\n",
    "    on=\"traj_id\",          # column to join on\n",
    "    how=\"right\",          # keep all rows in clean_joined\n",
    "    #validate=\"1:1\"       # optional: check that df_final.GEOID is unique\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e7a8a-0e4e-4287-af99-6ce92b66626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of the min pt_idx for each traj_id\n",
    "idx = ses_distribution.groupby(\"traj_id\")[\"pt_idx\"].idxmin()\n",
    "\n",
    "# select only those rows\n",
    "ses_first_pts = ses_distribution.loc[idx].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40b3ba-8614-4466-bc23-508e5ee958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = ses_distribution.groupby(\"traj_id\")\n",
    "\n",
    "# mean income\n",
    "mean_inc = grp[\"med_income\"].mean()\n",
    "\n",
    "# mode income (mostfrequent); take the first mode if theres a tie\n",
    "mode_inc = grp[\"med_income\"] \\\n",
    "    .agg(lambda x: x.mode().iat[0] if not x.mode().empty else x.iloc[0])\n",
    "\n",
    "# cluster label (each traj has a single cluster)\n",
    "cluster_lbl = grp[\"cluster\"].first()\n",
    "\n",
    "# assemble\n",
    "df_traj = pd.DataFrame({\n",
    "    \"cluster\": cluster_lbl,\n",
    "    \"mean_income\": mean_inc,\n",
    "    \"mode_income\": mode_inc\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb5c92-e130-4385-bfb5-7991a6c40296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for cl in sorted(df_traj[\"cluster\"].unique()):\n",
    "    vals = df_traj.loc[df_traj[\"cluster\"] == cl, \"mean_income\"]\n",
    "    plt.hist(vals, bins=100, density=True, alpha=0.5, label=f\"Cluster {cl}\")\n",
    "\n",
    "plt.xlabel(\"Average Median Income per Trajectory\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Mean Income by Cluster\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a1df8-d0fd-459e-abb5-78a1e8da8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for cl in sorted(df_traj[\"cluster\"].unique()):\n",
    "    vals = df_traj.loc[df_traj[\"cluster\"] == cl, \"mode_income\"]\n",
    "    plt.hist(vals, bins=100, density=True, alpha=0.5, label=f\"Cluster {cl}\")\n",
    "\n",
    "plt.xlabel(\"Modal Median Income per Trajectory\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Mode Income by Cluster\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874eb89-3ce5-4fd4-8481-4b826ababb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Assuming df_traj exists with columns 'cluster', 'mean_income', 'mode_income'\n",
    "clusters = sorted(df_traj['cluster'].unique())\n",
    "\n",
    "# 1. KDE plot for mean_income\n",
    "x_mean = df_traj['mean_income']\n",
    "x_min, x_max = x_mean.min(), x_mean.max()\n",
    "x_grid = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in clusters:\n",
    "    data = df_traj.loc[df_traj['cluster'] == cl, 'mean_income']\n",
    "    kde = gaussian_kde(data)\n",
    "    plt.plot(x_grid, kde(x_grid), label=f'Cluster {cl}')\n",
    "\n",
    "plt.xlabel('Average Median Income per Trajectory')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KDE of Mean Income by Cluster')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. KDE plot for mode_income\n",
    "x_mode = df_traj['mode_income']\n",
    "x_min, x_max = x_mode.min(), x_mode.max()\n",
    "x_grid = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in clusters:\n",
    "    data = df_traj.loc[df_traj['cluster'] == cl, 'mode_income']\n",
    "    kde = gaussian_kde(data)\n",
    "    plt.plot(x_grid, kde(x_grid), label=f'Cluster {cl}')\n",
    "\n",
    "plt.xlabel('Modal Median Income per Trajectory')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KDE of Mode Income by Cluster')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a157cb-ac4e-467c-a260-d5633fd25be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_first_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233c3fa-e053-4693-aa57-f6c40aba59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e0941-1ebf-455d-91bb-6aa7f28c3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_first_pts['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789ecef-735e-4e42-ab69-e59d350d12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your GeoDataFrame with first points is named `ses_first_pts`\n",
    "# and contains columns 'cluster' and 'med_income'.\n",
    "colors = [\"green\",\"blue\",\"yellow\",\"red\",\"purple\",\"orange\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cl in sorted(ses_first_pts['cluster'].unique()):\n",
    "    plt.hist(\n",
    "        ses_first_pts.loc[ses_first_pts['cluster'] == cl, 'med_income'],\n",
    "        bins=90,\n",
    "        alpha=0.9,\n",
    "        density = True,\n",
    "        label=f'Cluster {cl}',\n",
    "        color=colors[cl]\n",
    "    )\n",
    "\n",
    "plt.xlabel('Median Household Income')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Median Income by Cluster')\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c2735-fb5d-44fb-9d8b-c48886eb8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import LineString\n",
    "import random\n",
    "centroids_aea = gpd.GeoSeries(\n",
    "    clean_joined['centroid'].values,\n",
    ")\n",
    "\n",
    "# 2) Reproject that GeoSeries to EPSG:4326\n",
    "centroids_wgs = centroids_aea.to_crs(epsg=4326)\n",
    "\n",
    "# 3) Overwrite the old column (or make a new one)\n",
    "clean_joined['centroid'] = centroids_wgs.values\n",
    "\n",
    "centroids_aea = gpd.GeoSeries(\n",
    "    ses_gdf['centroid'].values,\n",
    ")\n",
    "\n",
    "# 2) Reproject that GeoSeries to EPSG:4326\n",
    "centroids_wgs = centroids_aea.to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "ses_gdf['centroid'] = centroids_wgs.values\n",
    "# 4) If you also want your polygons in 4326, do that too:\n",
    "clean_joined = clean_joined.to_crs(epsg=4326)\n",
    "#  2) Randomly sample N trajectories \n",
    "N = 50\n",
    "all_ids    = clean_joined['traj_id'].unique().tolist()\n",
    "sample_ids = random.sample(all_ids, k=N)\n",
    "\n",
    "#  3) Build the sample_gdf \n",
    "sample_lines = []\n",
    "for tid in sample_ids:\n",
    "    sub = (\n",
    "        clean_joined[ clean_joined['traj_id'] == tid ]\n",
    "          .sort_values('pt_idx')\n",
    "    )\n",
    "    pts = [\n",
    "        ses_gdf.at[int(h), 'centroid']\n",
    "        for h in sub['index_right'].dropna().astype(int)\n",
    "    ]\n",
    "    if len(pts) > 1:\n",
    "        sample_lines.append({\n",
    "            'traj_id': tid,\n",
    "            'geometry': LineString(pts)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816ce34-a873-41a9-aba1-cea81187d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5b6ce-f07f-4341-b73b-2d10075abfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcf31a-4709-494e-ac13-32f9615aee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "states = gpd.read_file('cb_2018_us_state_500k.shp')\n",
    "df = clean_joined.copy()\n",
    "\n",
    "#  0) Utility to pick topm trajectories per cluster by proximity in Z-space\n",
    "def find_representative_trajectories(Z, labels, traj_ids, centers, m=50):\n",
    "    reps = {}\n",
    "    K = centers.shape[0]\n",
    "\n",
    "    for c in tqdm(range(K)):\n",
    "        idx_c = np.where(labels == c)[0]          # positions in Z for cluster c\n",
    "        Zc    = Z[idx_c]\n",
    "        dists = np.linalg.norm(Zc - centers[c], axis=1)\n",
    "        order = np.argsort(dists)[: min(m, len(dists))]\n",
    "\n",
    "        # use .iloc to get by *position*\n",
    "        reps[c] = traj_ids.iloc[idx_c[order]].tolist()\n",
    "\n",
    "    return reps\n",
    "m = 100\n",
    "#  1) Compute representatives (50 per cluster)\n",
    "#    MAKE SURE Z, labels, ds.ids, and kmeans.cluster_centers_ are in scope\n",
    "representatives = find_representative_trajectories(\n",
    "    Z, labels, clean_joined.traj_id, kmeans.cluster_centers_, m\n",
    ")\n",
    "\n",
    "#  2) Merge cluster labels into your pointlevel table\n",
    "joined = df.merge(cluster_df, on=\"traj_id\", how=\"left\")\n",
    "\n",
    "#  3) Build LineStrings for the representative traj_ids\n",
    "traj_lines = []\n",
    "for cl, tid_list in tqdm(representatives.items()):\n",
    "    for tid in tqdm(tid_list):\n",
    "        sub = joined[joined[\"traj_id\"] == tid].sort_values(\"pt_idx\")\n",
    "        pts = [\n",
    "            ses_gdf.at[int(h), \"centroid\"]\n",
    "            for h in sub[\"index_right\"].dropna().astype(int)\n",
    "        ]\n",
    "        if len(pts) >= 2:\n",
    "            traj_lines.append({\n",
    "                \"traj_id\": tid,\n",
    "                \"cluster\": cl,\n",
    "                \"geometry\": LineString(pts)\n",
    "            })\n",
    "\n",
    "traj_lines_gdf = gpd.GeoDataFrame(\n",
    "    traj_lines,\n",
    "    geometry=\"geometry\",\n",
    "    crs=ses_gdf.crs\n",
    ")\n",
    "\n",
    "#  4) Prepare output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f181a4-59e3-4365-8eac-171cb0a76f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined['vec_weighted_avg'] = clean_joined['vec_weighted_avg'].apply(fill_vec)\n",
    "cj = (\n",
    "    clean_joined\n",
    "      .merge(\n",
    "         traj_lines_gdf[['traj_id','cluster']],\n",
    "         on='traj_id',\n",
    "         how='left'\n",
    "  )\n",
    ")\n",
    "cj\n",
    "# 2) Now pick your cluster i and timestep t\n",
    "cluster_i = 2\n",
    "time_t    = 143\n",
    "\n",
    "sub = cj[\n",
    "    (cj['cluster'] == cluster_i) &\n",
    "    (cj['pt_idx']   == time_t)\n",
    "]\n",
    "\n",
    "vectors_by_t = {}\n",
    "for t in sorted(cj['pt_idx'].unique()):\n",
    "    part = cj[(cj['cluster']==cluster_i)&(cj['pt_idx']==t)]\n",
    "    vectors_by_t[t] = (\n",
    "        np.vstack(part['vec_weighted_avg'].tolist())\n",
    "        if not part.empty\n",
    "        else np.zeros((0, emb_dim))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c43d28-317d-433c-97a3-51fd6eeeace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#  CONFIGURATION \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "k      = 10       # number of logits to sum\n",
    "T      = 2.0      # temperature (unused if =1)\n",
    "K      = 3        # number of clusters\n",
    "\n",
    "# outputs\n",
    "df_counts_by_cluster     = {}\n",
    "df_counts_cat_by_cluster = {}\n",
    "\n",
    "#  MAIN LOOP \n",
    "for cluster_i in range(K):\n",
    "    # 1) select all POIs in this cluster\n",
    "    cluster_data = cj[cj['cluster'] == cluster_i]\n",
    "    counts_by_t  = {}\n",
    "\n",
    "    # 2) no grads needed\n",
    "    with torch.no_grad():\n",
    "        # 3) loop over each distinct timestep\n",
    "        for t in sorted(cluster_data['pt_idx'].unique()):\n",
    "            sub = cluster_data[cluster_data['pt_idx'] == t]\n",
    "            if sub.empty:\n",
    "                counts_by_t[t] = {}   # empty hour\n",
    "                continue\n",
    "\n",
    "            # 4) stack embeddings and push to device\n",
    "            arr = np.stack(sub['vec_weighted_avg'].values).astype(np.float32)  # (n_traj, D)\n",
    "            X   = torch.from_numpy(arr).to(device)\n",
    "\n",
    "            # 5) run only the head to get logits\n",
    "            logits = bottleneck_model.head(X)  # (n_traj, n_classes)\n",
    "            if t%100 == 0:\n",
    "                print(logits.shape)\n",
    "            probs = torch.softmax(logits,axis=1)\n",
    "\n",
    "            # 6) pick the top-k logits per POI\n",
    "            topk_vals, topk_idx = probs.topk(k, dim=1)  # both are (n_traj, k)\n",
    "            topk_vals = topk_vals.cpu().numpy()\n",
    "            topk_idx  = topk_idx.cpu().numpy()\n",
    "\n",
    "            # 7) sum those logits into a per-class accumulator\n",
    "            agg = {}\n",
    "            for idx_row, val_row in zip(topk_idx, topk_vals):\n",
    "                for cls, score in zip(idx_row, val_row):\n",
    "                    agg[cls] = agg.get(cls, 0.0) + float(score)\n",
    "\n",
    "            counts_by_t[t] = agg\n",
    "\n",
    "    #  Build DataFrame of raw sums \n",
    "    df_counts = (\n",
    "        pd.DataFrame.from_dict(counts_by_t, orient='index')\n",
    "          .fillna(0.0)\n",
    "    )\n",
    "    df_counts.index.name = 'pt_idx'\n",
    "\n",
    "    # rename numeric classindices  the string labels\n",
    "    df_counts.columns = [classes[int(c)] for c in df_counts.columns]\n",
    "\n",
    "    #  Collapse subcategories to toplevel categories \n",
    "    col2cat = df_counts.columns.map(lambda s: s.split('[sep]')[0])\n",
    "    df_counts_cat = df_counts.groupby(col2cat, axis=1).sum()\n",
    "\n",
    "    #  Store for later use \n",
    "    df_counts_by_cluster[cluster_i]     = df_counts\n",
    "    df_counts_cat_by_cluster[cluster_i] = df_counts_cat\n",
    "\n",
    "#  Now df_counts_by_cluster[i] is the raw summed-logit table for cluster i\n",
    "#     and df_counts_cat_by_cluster[i] is the same collapsed to categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da279-603e-48ee-a1ea-8d0608fec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "global_counts = reduce(\n",
    "    lambda a, b: a.add(b, fill_value=0),\n",
    "    df_counts_cat_by_cluster.values()\n",
    ")\n",
    "\n",
    "# 2. (Optional) fill any NaNs just in case\n",
    "global_counts = global_counts.fillna(0)\n",
    "\n",
    "# 3. If you want the baseline **proportions** (summing across categories at each time step):\n",
    "global_df = global_counts.div(global_counts.sum(axis=1).replace(0, 1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185eeb1-13c1-491e-aa79-b04ef40c6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm, ListedColormap\n",
    "from functools import reduce\n",
    "\n",
    "# --- Prepare colormap & cluster list ---\n",
    "base_cmap     = plt.cm.get_cmap('bwr', 256)\n",
    "base_colors   = base_cmap(np.linspace(0, 1, 256))\n",
    "base_colors[len(base_colors)//2] = [1,1,1,1]          # white at zero\n",
    "cmap_white_center = ListedColormap(base_colors)\n",
    "\n",
    "clusters      = sorted(df_counts_cat_by_cluster.keys())  # e.g. [0,1,2]\n",
    "\n",
    "# pick the same top-categories for all\n",
    "df0     = df_counts_cat_by_cluster[clusters[0]]\n",
    "top6    = df0.sum(axis=0).nlargest(6).index.tolist()\n",
    "_, top5 = top6[0], top6[1:]  # drop the first if desired\n",
    "\n",
    "# --- Make a 31 grid, figsize 109 ---\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=4, ncols=1,\n",
    "    figsize=(8, 5),\n",
    "    sharex=True,       # align time axis\n",
    "    sharey=False,      # each subplot draws its own ylabels\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "all_im = None\n",
    "for ax, cluster_i in zip(axes, clusters):\n",
    "    # compute % for this cluster\n",
    "    df_cat      = df_counts_cat_by_cluster[cluster_i][top5].sort_index()\n",
    "    df_norm     = df_cat.div(df_cat.sum(axis=1).replace(0,1), axis=0)\n",
    "    glob_sel    = global_df[top5]\n",
    "    global_norm = glob_sel.div(glob_sel.sum(axis=1).replace(0,1), axis=0)\n",
    "\n",
    "    df_diff = (df_norm - global_norm) * 100\n",
    "    mx      = np.abs(df_diff.values).max()\n",
    "    norm    = TwoSlopeNorm(vmin=-mx, vcenter=0, vmax=mx)\n",
    "\n",
    "    im = ax.imshow(\n",
    "        df_diff.T.values,\n",
    "        cmap=cmap_white_center,\n",
    "        norm=norm,\n",
    "        aspect='auto',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    all_im = im\n",
    "\n",
    "    # **always** draw ylabels\n",
    "    ax.set_yticks(np.arange(len(top5)))\n",
    "    ax.set_yticklabels(top5, fontsize=6,)\n",
    "\n",
    "    # xaxis ticks only on bottom subplot\n",
    "    ax.set_xticks(np.arange(len(df_diff.index))[::10])\n",
    "    ax.set_xticklabels(df_diff.index[::10], rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.grid(False)\n",
    "    ax.set_title(f\"Cluster {cluster_i}\", fontsize=12)\n",
    "\n",
    "# common xlabel\n",
    "axes[-1].set_xlabel(\"Time Step\", fontsize=10)\n",
    "\n",
    "# shared colorbar on the right\n",
    "cbar = fig.colorbar(\n",
    "    all_im,\n",
    "    ax=axes,\n",
    "    orientation='vertical',\n",
    "    fraction=0.02,\n",
    "    pad=0.03\n",
    ")\n",
    "cbar.set_label(\"% (Cluster  Global)\", fontsize=10)\n",
    "\n",
    "plt.savefig(\"./cluster_results/SES_combined_heatmaps_3x1_with_ylab.png\", dpi=200)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60449bf-6b80-4f6a-9ac6-910d6c4eb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def find_representative_trajectories_as_arrays(Z, labels, centers, m=750):\n",
    "    \"\"\"\n",
    "    Finds the top 'm' representative trajectories from each cluster and returns\n",
    "    their embeddings and labels as NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        Z (np.ndarray): The full array of latent embeddings.\n",
    "        labels (np.ndarray): The cluster assignment for each embedding in Z.\n",
    "        centers (np.ndarray): The cluster centroid vectors from KMeans.\n",
    "        m (int): The number of representative trajectories to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (Z_representatives, labels_representatives)\n",
    "               - Z_representatives: A NumPy array of the stacked representative embeddings.\n",
    "               - labels_representatives: A NumPy array of the corresponding cluster labels.\n",
    "    \"\"\"\n",
    "    representative_vectors_list = []\n",
    "    representative_labels_list = []\n",
    "    \n",
    "    K = centers.shape[0] # Total number of clusters\n",
    "\n",
    "    for c in tqdm(range(K), desc=\"Finding Representatives per Cluster\"):\n",
    "        # Find the original indices of all members belonging to the current cluster 'c'\n",
    "        original_indices_for_cluster_c = np.where(labels == c)[0]\n",
    "        \n",
    "        # If the cluster is empty, skip it\n",
    "        if len(original_indices_for_cluster_c) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get the latent vectors for this cluster\n",
    "        Zc = Z[original_indices_for_cluster_c]\n",
    "        \n",
    "        # Calculate the Euclidean distance of each member to the cluster's centroid\n",
    "        dists = np.linalg.norm(Zc - centers[c], axis=1)\n",
    "        \n",
    "        # Get the indices of the 'm' closest members *within this cluster*\n",
    "        num_to_select = min(m, len(dists))\n",
    "        closest_indices_within_cluster = np.argsort(dists)[:num_to_select]\n",
    "        \n",
    "        # Use these local indices to find the original indices in the global Z array\n",
    "        original_indices_of_reps = original_indices_for_cluster_c[closest_indices_within_cluster]\n",
    "        \n",
    "        # Select the representative vectors from the original Z array\n",
    "        representative_vectors = Z[original_indices_of_reps]\n",
    "        \n",
    "        # Create the corresponding labels for these representatives\n",
    "        representative_labels = np.full(num_to_select, c)\n",
    "        \n",
    "        # Append the results to our lists\n",
    "        representative_vectors_list.append(representative_vectors)\n",
    "        representative_labels_list.append(representative_labels)\n",
    "        \n",
    "    # Concatenate all the collected vectors and labels into single NumPy arrays\n",
    "    if not representative_vectors_list:\n",
    "        # Handle case where no representatives were found (e.g., all clusters were empty)\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    Z_representatives = np.vstack(representative_vectors_list)\n",
    "    labels_representatives = np.concatenate(representative_labels_list)\n",
    "    \n",
    "    return Z_representatives, labels_representatives\n",
    "\n",
    "# --- How to use the new function ---\n",
    "\n",
    "# Assume Z, labels, and kmeans.cluster_centers_ are already defined from your clustering\n",
    "# Z = Full embedding matrix\n",
    "# labels = Full labels array from KMeans\n",
    "# kmeans = your fitted KMeans model object\n",
    "\n",
    "m = 500\n",
    "print(f\"Selecting top {m} representative trajectories from each cluster...\")\n",
    "\n",
    "# Call the new function to get the data in the desired format\n",
    "Z_reps, labels_reps = find_representative_trajectories_as_arrays(\n",
    "    Z, \n",
    "    labels, \n",
    "    kmeans.cluster_centers_, \n",
    "    m=m\n",
    ")\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n--- Conversion Complete ---\")\n",
    "print(f\"Shape of Z_reps (representative embeddings): {Z_reps.shape}\")\n",
    "print(f\"Shape of labels_reps (representative labels): {labels_reps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00993-d6c5-477a-9d41-c92fdaf7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans # For generating sample data\n",
    "from sklearn.datasets import make_blobs # For generating sample data\n",
    "\n",
    "# --- For Demonstration: Create Sample Data ---\n",
    "# In your actual code, you will use your real 'Z' and 'labels' from KMeans.\n",
    "# Z = a NumPy array of your latent embeddings, shape (n_samples, n_features)\n",
    "# labels = the result of km.labels_, shape (n_samples,)\n",
    "print(\"Generating sample data for demonstration...\")\n",
    "\n",
    "print(\"Sample data generated.\")\n",
    "# Replace Z_sample and labels_sample with your actual data below\n",
    "# --- End of Sample Data Generation ---\n",
    "\n",
    "\n",
    "# 1. Run t-SNE to reduce dimensions\n",
    "# Perplexity is a key hyperparameter; typical values are between 5 and 50.\n",
    "# It's related to the number of nearest neighbors considered for each point.\n",
    "print(\"Running t-SNE... (this may take a moment)\")\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=20,\n",
    "    n_iter=5000,\n",
    "    random_state=42,\n",
    "    init='pca',\n",
    "    learning_rate='auto'\n",
    ")\n",
    "tsne_results = tsne.fit_transform(Z_reps)\n",
    "print(\"t-SNE finished.\")\n",
    "\n",
    "# 2. Create a DataFrame for easy plotting with Seaborn\n",
    "tsne_df = pd.DataFrame({\n",
    "    'tsne_1': tsne_results[:, 0],\n",
    "    'tsne_2': tsne_results[:, 1],\n",
    "    'cluster': labels_reps # Add the cluster labels from your KMeans result\n",
    "})\n",
    "# Make cluster labels categorical for better legend labels\n",
    "tsne_df['cluster'] = tsne_df['cluster'].astype('category')\n",
    "\n",
    "# 3. Plot the results using Seaborn\n",
    "print(\"Generating plot...\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tsne_df,\n",
    "    x='tsne_1',\n",
    "    y='tsne_2',\n",
    "    hue='cluster', # Color points by their assigned cluster\n",
    "    palette=sns.color_palette(\"deep\", n_colors=4), # Use a distinct color palette\n",
    "    s=50,          # Marker size\n",
    "    alpha=0.6,     # Marker transparency\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Customize the plot for clarity\n",
    "#ax.set_title('t-SNE Visualization of Trajectory Clusters', fontsize=20, pad=15)\n",
    "ax.set_xlabel('t-SNE Dimension 1', fontsize=14)\n",
    "ax.set_ylabel('t-SNE Dimension 2', fontsize=14)\n",
    "ax.legend(title='Cluster', fontsize=12, title_fontsize=14)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure in high resolution\n",
    "output_filename = \"tsne_cluster_visualization_3_flat.png\"\n",
    "plt.savefig(output_filename, dpi=300)\n",
    "print(f\"Plot saved successfully to {output_filename}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13362556-d40d-48e7-86ed-aa30fb2bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for x, mask, _ in tqdm(train_loader):\n",
    "        # x: (B, T, F); mask: (B, T) with 1=data, 0=noise\n",
    "        x = x.cuda()\n",
    "        mask = mask.cuda()\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # no need to clamp lengthsmask tells us directly\n",
    "        Lmax = int(mask.sum(dim=1).max().item())  # longest real seq in this batch\n",
    "\n",
    "        # get latent dim D by a quick forward on just t=0\n",
    "        _, z0 = model(x[:, :1, :], torch.ones(B, dtype=torch.long).cuda())\n",
    "        D = z0.shape[1]\n",
    "\n",
    "        Z_batch = torch.zeros(B, D, T, device=\"cpu\")\n",
    "\n",
    "        for t in tqdm(range(Lmax)):\n",
    "            # which trajectories are alive at time t?\n",
    "            active = (mask[:, t] == 1).nonzero(as_tuple=True)[0]\n",
    "            if len(active) == 0:\n",
    "                break\n",
    "\n",
    "            # mask-out future steps for just the active ones\n",
    "            x_sub = x[active].clone()\n",
    "            if t+1 < T:\n",
    "                x_sub[:, t+1:, :] = 0\n",
    "\n",
    "            # compute true lengths up to t for pack_padded_sequence\n",
    "            lengths_sub = mask[active, : t+1].sum(dim=1)\n",
    "\n",
    "            # forward only that subset\n",
    "            _, z_sub = model(x_sub, lengths_sub)\n",
    "            Z_batch[active.cpu(), :, t] = z_sub.cpu()\n",
    "\n",
    "        zs.append(Z_batch)\n",
    "\n",
    "# stitch batches  (num_traj, D, T)\n",
    "Z3 = torch.cat(zs, dim=0).numpy()\n",
    "print(\"Z3 shape:\", Z3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864fb74-4b9f-4152-8d9e-4d562d788541",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"GEOID_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d1fc3-0743-4a9b-a4e3-2286e67ba247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely.wkb\n",
    "import geopandas as gpd\n",
    "clean_joined = pd.read_parquet(\"GEOID_SES_point.parquet\")\n",
    "df = clean_joined.copy()\n",
    "df['geometry'] = df['geometry'].apply(lambda wkb: shapely.wkb.loads(wkb))\n",
    "clean_joined = gpd.GeoDataFrame(df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344a31b-474f-4b8c-902c-f4023827b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"GEOID_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bd89f-ce40-43cb-8a11-a20d3c429d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f50c5-4fed-4293-a39c-b6fda2498794",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[9176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad8c4b-2011-448d-9fe8-d678e4fd81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bf616-49ae-4a53-b7bd-7f8802225f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#64 Dimension Latent Space vector <-> label (SES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5b52f-b022-4c36-816f-d485103dc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"POI_encoded_embeddings.parquet\").isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e65c1-3bce-44d1-ae04-3bad7ba5611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"feature_dict.pkl\", 'rb') as f:\n",
    "    feature_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b64dd2-d708-4390-8173-150897c6778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict['0000a204849023cd902b8c7dd9edc37b8bbc222edbe6620b26b852a3e24b317c'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8d67c-0062-4a10-adc7-9709e2a9e703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44655227-6bbf-4696-98ba-8dd8dbb0f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('hurricane_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50389b-8f08-4750-ac40-9faf89b64492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9be805-9a1c-43d5-8187-db0e6e7171e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load your hurricane matrix and set the ID column as index\n",
    "df = pd.read_csv(\"hurricane_matrix.csv\")\n",
    "df = df.set_index(\"Unnamed: 0\")   # now df.index are the POIIDs\n",
    "\n",
    "# 3) Replace coordinates with embeddings, in place\n",
    "for poi_id, emb in feature_dict.items():\n",
    "    # emb has shape (n_steps, 128)\n",
    "    if poi_id not in df.index:\n",
    "        # safety check\n",
    "        continue\n",
    "\n",
    "    row = df.loc[poi_id]\n",
    "    # Which columns have actual coordinates?\n",
    "    valid_cols = row.index[row.notna()]     # Index of columns where row[col] != NaN\n",
    "\n",
    "    # Sanity check\n",
    "    assert emb.shape[0] == len(valid_cols), (\n",
    "        f\"POI {poi_id}: found {len(valid_cols)} data columns, \"\n",
    "        f\"but embedding has {emb.shape[0]} rows\"\n",
    "    )\n",
    "\n",
    "    # Overwrite each nonNaN cell with the corresponding embedding vector\n",
    "    for i, col in enumerate(valid_cols):\n",
    "        df.at[poi_id, col] = emb[i]    # emb[i] is a length128 numpy array\n",
    "\n",
    "# Now dfs cells are either NaN or a length128 ndarray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e1191-5ff3-405f-bdc5-a506bcf53105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"POI_embedding_matrix_missing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f527514-ab7f-4afe-b29e-b182cbd9e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8e612-7924-49ba-978f-ea58bddff8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = missing_count.dropna().astype(int)     # convert to int if needed\n",
    "uniques = np.sort(data.unique())\n",
    "\n",
    "# create edges that center each integer in its own bin\n",
    "edges = np.concatenate([uniques - 0.5, [uniques[-1] + 0.5]])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data, bins=edges, rwidth=0.8)\n",
    "plt.xticks(uniques)               # show one tick per unique value\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram with One Bin per Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa0628-6973-482a-8f1c-fce87e7b42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = missing_count.dropna().value_counts()\n",
    "\n",
    "# 2. Bar plot\n",
    "ax = counts.plot(kind=\"bar\", width=0.8)\n",
    "ax.set_xlabel(\"Value\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Frequency of Each Unique Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b49749-f770-42b0-99d2-43950e33554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"POI_embedding_matrix_missing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a616ae-edf9-4d6f-ad71-4907c086a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df.isna().sum()/95000, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4756a-86a5-4e27-8e40-6c0e8a175bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"geometry\"]= gpd.GeoSeries.from_wkb(df_final[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc6984-284a-4442-b2a7-0728af0ea488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589709-344a-464b-bd4d-95004ee44ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traj_latent = pd.read_parquet(\"Full_latent_emb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2cbea-8e5a-49f8-a72d-53cb447048b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traj_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794180fb-f435-475b-bd53-8764e9a7d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Traj_latent.drop(columns=\"cluster\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a982754-ccd6-4c9a-a489-9d3868bd3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689dcfa6-fe21-4e06-b8fe-0a9a3e748a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d95dc-f41e-46c5-90ca-6f728bb3a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_buffer = point_gdf.to_crs(epsg=5070)\n",
    "ses_buffer = ses_gdf.to_crs(epsg=5070)\n",
    "ses_buffer[\"centroid\"] = ses_buffer.centroid\n",
    "ses_gdf = ses_buffer.to_crs(epsg=4326)\n",
    "\n",
    "joined_nearest_ll = gpd.sjoin_nearest(\n",
    "    point_buffer[[\"traj_id\", \"pt_idx\", \"geometry\"]],  # keep only the columns we care about\n",
    "    ses_buffer[[\"geometry\",\"centroid\"]],  \n",
    "    how=\"left\"           # keep all points; hex attributes will be NaN if a point is unmatche\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb9d5a-b528-4bb0-970a-56669632004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nearest = joined_nearest_ll.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dc088-0844-4192-92f4-07ce5d49d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_joined = joined_nearest.drop_duplicates(subset=[\"traj_id\", \"pt_idx\"])\n",
    "print(clean_joined.crs)\n",
    "\n",
    "print(clean_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92590ed-080d-4f9b-9425-71fcb21c82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = clean_joined.groupby(\"traj_id\")[\"pt_idx\"].idxmin()\n",
    "\n",
    "# select only those rows\n",
    "ses_first_pts = clean_joined.loc[idx].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebecf1-577e-4f46-b55d-a79a92684051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abb53f-8057-428b-a065-7bea94480282",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf3d8c-c1f4-409f-a1c9-526b06bace2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df_full = ses_first_pts.merge(Traj_latent, on = \"traj_id\", how = \"inner\")\n",
    "latent_df_full.rename(columns={\"index_right\":\"hex_id\"},inplace=True)\n",
    "complete_latent_ses_df = latent_df_full.merge(df_final, on =\"hex_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56164841-ae24-4c1b-ae0d-bee01ed9c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df = complete_latent_ses_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22366d77-c6b5-427d-a5c7-2758b854815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df.columns[74:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f53c0-7fcd-462d-b47f-a40b9fc73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_latent_ses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142973b4-fe8f-4ed8-ade1-90fa83b33b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254208d4-8d36-42a0-aef0-7509cfa93949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) (Optional) Keep only true numeric columns and drop any rows with NaNs\n",
    "df_num = complete_latent_ses_df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# 2) Slice out y (cols 568) and x (cols 74end)\n",
    "y = df_num.iloc[:, 2:66]\n",
    "x = df_num.iloc[:, 66:]\n",
    "\n",
    "# 3) Compute the full correlation matrix, then take the y vs x block\n",
    "full_corr = pd.concat([y, x], axis=1).corr()\n",
    "corr_yx = full_corr.loc[y.columns, x.columns]\n",
    "\n",
    "# 4) (Optional) Flatten to long form and sort by absolute correlation\n",
    "pairs = (\n",
    "    corr_yx\n",
    "      .abs()                    # comment this out if you want signed values\n",
    "      .stack()                  # turns into a Series with MultiIndex (y, x)\n",
    "      .reset_index()            # makes columns ['level_0','level_1',0]\n",
    "      .rename(columns={\n",
    "          'level_0':'y',\n",
    "          'level_1':'x',\n",
    "          0:'corr'\n",
    "      })\n",
    "      .sort_values('corr', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Results:\n",
    "print(\"Crosscorr matrix (y vs x):\")\n",
    "print(corr_yx)\n",
    "\n",
    "print(\"\\nLong form sorted by |corr|:\")\n",
    "print(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9baec-8ea4-41be-b939-a5321f036d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.iloc[:,2:(2+64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df4c08-455a-4ad2-8ba3-c9e6aef7f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffcb96-ad9b-4b33-8037-b474dc4b9384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# assume df_num has 90k rows, columns: pt_idx, hex_id, z_0z_63, and 300 xfeatures\n",
    "id_cols = [\"pt_idx\",\"hex_id\"]\n",
    "z_cols  = [f\"z_{i}\" for i in range(64)]\n",
    "x_cols  = [c for c in df_num.columns if c not in id_cols+z_cols]\n",
    "\n",
    "# Prepend a constant column for the intercept\n",
    "X_full = sm.add_constant(X_uncorr)\n",
    "\n",
    "# Dictionary to store summary stats\n",
    "results = {}\n",
    "\n",
    "for z in z_cols:\n",
    "    y = df_num[z]\n",
    "    model = sm.OLS(y, X_full).fit()\n",
    "    \n",
    "    # extract the key statistics\n",
    "    stats = {\n",
    "        \"R2\":        model.rsquared,\n",
    "        \"Adj R2\":    model.rsquared_adj,\n",
    "        \"F-stat\":    model.fvalue,\n",
    "        \"F pvalue\": model.f_pvalue,\n",
    "    }\n",
    "    results[z] = stats\n",
    "    \n",
    "    # Print a brief summary for this target\n",
    "    print(f\"=== {z} ===\")\n",
    "    print(f\" R={stats['R2']:.4f},  AdjR={stats['Adj R2']:.4f}\")\n",
    "    print(f\" F={stats['F-stat']:.2f},  p(F)={stats['F pvalue']:.2e}\")\n",
    "    print(f\" Top 5 predictors by |t|:\")\n",
    "    print(model.summary2().tables[1]\n",
    "             .sort_values(\"t\")  # sorts by tstat ascending\n",
    "             .abs()\n",
    "             .loc[:, [\"Coef.\", \"Std.Err.\", \"t\", \"P>|t|\"]]\n",
    "             .head(5))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae8e32-6b46-4722-a0ea-f9a6a98bca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pick two targets\n",
    "for zcol in [\"z_0\",\"z_31\"]:\n",
    "    # 1) extract data\n",
    "    y_true = df_num[zcol].values\n",
    "    X       = X_full\n",
    "    y_pred  = model.predict(X)\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    # 2) Pred vs Actual\n",
    "    plt.figure()  # new figure for each plot\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    mn, mx = np.min(y_true), np.max(y_true)\n",
    "    plt.plot([mn, mx], [mn, mx])  # identity line\n",
    "    plt.xlabel(\"Actual \" + zcol)\n",
    "    plt.ylabel(\"Predicted \" + zcol)\n",
    "    plt.title(f\"Predicted vs Actual for {zcol}\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residual histogram\n",
    "    plt.figure()\n",
    "    plt.hist(residuals, bins=30)\n",
    "    plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "    plt.title(f\"Residual Histogram for {zcol}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d6220-bbdb-4bbb-92c1-f9d110a2c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "# 1) Prepare your data\n",
    "X = df_num[x_cols].values       # shape (n_samples, n_features)\n",
    "rf_models = {}                  # to hold the fitted forest for each z\n",
    "r2_scores  = {}                 # to hold in-sample R for each z\n",
    "\n",
    "# 2) Loop over every target\n",
    "for z in tqdm(z_cols):\n",
    "    y = df_num[z].values        # shape (n_samples,)\n",
    "\n",
    "    # a) instantiate\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # b) fit\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # c) score (in-sample R)\n",
    "    r2 = rf.score(X, y)\n",
    "\n",
    "    # d) store & print\n",
    "    rf_models[z] = rf\n",
    "    r2_scores[z]  = r2\n",
    "    print(f\"{z:>5}  R = {r2:.4f}\")\n",
    "\n",
    "# 3) (Optional) Collate all Rs into a DataFrame for easy viewing/sorting\n",
    "r2_df = pd.Series(r2_scores, name=\"R2\").to_frame()\n",
    "print(\"\\nAll targets sorted by R:\")\n",
    "print(r2_df.sort_values(\"R2\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc5fc4-410f-4de9-b7a6-51cad3f8fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open('/storage1/fs1/nlin/Active/shared_data/rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff8eff-ee7f-410d-8f68-37ae2c6ce58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Choose folder and make sure it exists\n",
    "out_dir = \"model_plots\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 2. Pick how many topR targets you want\n",
    "top_k = 3\n",
    "top = sorted(r2_scores.items(), key=lambda kv: kv[1], reverse=True)[:top_k]\n",
    "top_zs = [z for z, _ in top]\n",
    "\n",
    "# 3. Loop and save\n",
    "for z in top_zs:\n",
    "    y_true   = df_num[z].values\n",
    "    y_pred   = rf_models[z].predict(df_num[x_cols].values)\n",
    "    residual = y_true - y_pred\n",
    "    r2       = r2_scores[z]\n",
    "\n",
    "    # a) Pred vs Actual\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
    "    mn, mx = y_true.min(), y_true.max()\n",
    "    plt.plot([mn, mx], [mn, mx], 'k--', lw=1)\n",
    "    plt.xlabel(f\"Actual {z}\")\n",
    "    plt.ylabel(f\"Predicted {z}\")\n",
    "    plt.title(f\"{z}  Pred vs Actual (R={r2:.3f})\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{z}_pred_vs_actual.png\"))\n",
    "    plt.close(fig)   # close to free memory\n",
    "\n",
    "    # b) Residuals histogram\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    plt.hist(residual, bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.xlabel(\"Residual (Actual  Predicted)\")\n",
    "    plt.title(f\"{z}  Residuals\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{z}_residuals.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved plots for {top_zs} into ./{out_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05877-eede-4114-8b9a-ed551c83dc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "def max_uncorrelated_features(df: pd.DataFrame,\n",
    "                              threshold: float = 0.9\n",
    "                             ) -> list[str]:\n",
    "    \"\"\"\n",
    "    Greedily select a maximal set of columns from df such that\n",
    "    no pair has abs(corr) > threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame, shape (n_samples, p_features)\n",
    "      Only the feature columns (no IDs, no targets).\n",
    "    threshold : float\n",
    "      Drop pairs with |corr| > threshold.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keep : list of column names\n",
    "      Subset of df.columns with no highcorr pairs.\n",
    "    \"\"\"\n",
    "    # 1) compute absolute correlation matrix\n",
    "    corr = df.corr().abs()\n",
    "    \n",
    "    # 2) build list of conflicting edges\n",
    "    feats = set(df.columns)\n",
    "    edges = [(i, j)\n",
    "             for i, j in combinations(df.columns, 2)\n",
    "             if corr.at[i, j] > threshold]\n",
    "    epoch = 0\n",
    "    # 3) greedy removal\n",
    "    while edges:\n",
    "        epoch +=1\n",
    "        print(f\"Epoch {epoch} started, \")\n",
    "        # compute degrees\n",
    "        deg = {f: 0 for f in feats}\n",
    "        for i, j in edges:\n",
    "            deg[i] += 1\n",
    "            deg[j] += 1\n",
    "        \n",
    "        # pick feature with highest degree\n",
    "        worst = max(deg, key=deg.get)\n",
    "        feats.remove(worst)\n",
    "        \n",
    "        # drop edges incident to that feature\n",
    "        edges = [(i, j) for i, j in edges if i in feats and j in feats]\n",
    "        print(f\"Epoch {epoch} started, edges number : {len(edges)}\")\n",
    "    \n",
    "    # remaining features are noncollinear\n",
    "    return list(feats)\n",
    "\n",
    "# --- Usage on your X_mat DataFrame ---\n",
    "# X_mat = df_num[x_cols]   # shape (95337, 301)\n",
    "\n",
    "keep = max_uncorrelated_features(X_mat, threshold=0.8)\n",
    "print(f\"Kept {len(keep)}/{X_mat.shape[1]} features:\", keep)\n",
    "\n",
    "# Subset your matrix:\n",
    "X_uncorr = X_mat[keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340933e6-09c4-46b5-867f-40733aea9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# y and X as before; model is your fitted Pipeline\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 1. R\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"R: {r2:.4f}\")\n",
    "\n",
    "# 2. Adjusted R\n",
    "n, p = X.shape\n",
    "r2_adj = 1 - (1 - r2)*(n - 1)/(n - p - 1)\n",
    "print(f\"Adjusted R: {r2_adj:.4f}\")\n",
    "\n",
    "# 3. MSE & RMSE\n",
    "mse  = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MSE: {mse:.4g},  RMSE: {rmse:.4g}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
